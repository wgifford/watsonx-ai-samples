{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b5a632",
   "metadata": {},
   "source": [
    "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
    "\n",
    "# Use watsonx to run `generate_batch` job using AI service\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26112be8",
   "metadata": {},
   "source": [
    "#### Disclaimers\n",
    "\n",
    "- Use only Projects and Spaces that are available in watsonx context.\n",
    "\n",
    "## Notebook content\n",
    "\n",
    "This notebook provides a detailed demonstration of the steps and code required to showcase support for watsonx.ai AI service.\n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
    "\n",
    "## Learning goal\n",
    "\n",
    "The primary objective of this notebook is to illustrate how to utilize watsonx.ai AI services to execute a `generate_batch` job, facilitating the ingestion of documents into a Milvus vector database.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "- [Setup](#setup)\n",
    "- [Set up VectorStore with Milvus credentials](#vectorstore)\n",
    "- [References to input data](#input_data)\n",
    "- [Create AI service](#ai_service)\n",
    "- [Testing AI service's function locally](#testing)\n",
    "- [Deploy AI service](#deploy)\n",
    "- [Example of Executing an AI service](#example)\n",
    "- [Cleanup](#cleanup)\n",
    "- [Summary and next steps](#summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe3ec13",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "\n",
    "## Set up the environment\n",
    "\n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
    "\n",
    "- Create a <a href=\"https://cloud.ibm.com/catalog/services/watsonxai-runtime\" target=\"_blank\" rel=\"noopener no referrer\">watsonx.ai Runtime Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/wml-plans.html?context=wx&audience=wdp\" target=\"_blank\" rel=\"noopener no referrer\">here</a>).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3525c2",
   "metadata": {},
   "source": [
    "### Install required packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8662f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langchain_community | tail -n 1\n",
    "%pip install -U \"ibm_watsonx_ai>=1.3.20\" | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c2e2a1",
   "metadata": {},
   "source": [
    "### Define the watsonx.ai credentials\n",
    "\n",
    "Use the code cell below to define the watsonx.ai credentials that are required to work with watsonx Foundation Model inferencing.\n",
    "\n",
    "**Action:** Provide the IBM Cloud user API key. For details, see <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\" rel=\"noopener no referrer\">Managing user API keys</a>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f63b2f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "from ibm_watsonx_ai import Credentials\n",
    "\n",
    "credentials = Credentials(\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    api_key=getpass.getpass(\"Enter your watsonx.ai api key and hit enter: \"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a49878",
   "metadata": {},
   "source": [
    "### Working with spaces\n",
    "\n",
    "You need to create a space that will be used for your work. If you do not have a space, you can use [Deployment Spaces Dashboard](https://dataplatform.cloud.ibm.com/ml-runtime/spaces?context=wx) to create one.\n",
    "\n",
    "- Click **New Deployment Space**\n",
    "- Create an empty space\n",
    "- Select Cloud Object Storage\n",
    "- Select watsonx.ai Runtime instance and press **Create**\n",
    "- Go to **Manage** tab\n",
    "- Copy `Space GUID` and paste it below\n",
    "\n",
    "**Tip**: You can also use SDK to prepare the space for your work. More information can be found [here](https://github.com/IBM/watson-machine-learning-samples/blob/master/cloud/notebooks/python_sdk/instance-management/Space%20management.ipynb).\n",
    "\n",
    "**Action**: assign space ID below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ead0265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    space_id = os.environ[\"SPACE_ID\"]\n",
    "except KeyError:\n",
    "    space_id = input(\"Please enter your space_id (hit enter): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0db8b5",
   "metadata": {},
   "source": [
    "Create an instance of APIClient with authentication details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7317126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai import APIClient\n",
    "\n",
    "api_client = APIClient(credentials=credentials, space_id=space_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d86021",
   "metadata": {},
   "source": [
    "### Create an embedding function for VectorStore\n",
    "\n",
    "Note that you can feed a custom embedding function to be used by Milvus. The performance of Milvus may differ depending on the embedding model used.\n",
    "\n",
    "**Note**: To list available embedding models use:\n",
    "\n",
    "```python\n",
    "api_client.foundation_models.EmbeddingModels.show()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde6e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.foundation_models import Embeddings\n",
    "\n",
    "embedding_model_id = \"ibm/slate-125m-english-rtrvr-v2\"\n",
    "\n",
    "embeddings = Embeddings(model_id=embedding_model_id, api_client=api_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa4cc05",
   "metadata": {},
   "source": [
    "### Set up connectivity information to Milvus\n",
    "\n",
    "<b>This notebook focuses on a self-managed Milvus cluster using <a href=\"https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-adding-milvus-service\" target=\"_blank\" rel=\"noopener no referrer\">IBM watsonx.data.</a></b>\n",
    "\n",
    "The following cell retrieves the Milvus username, password, host, and port from the environment (if available) and prompts you to provide them manually in case of failure.\n",
    "\n",
    "You can provide a connection asset ID to read all required connection data from it. Before doing so, make sure that a connection asset was created in your space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f259cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "milvus_connection_id = (\n",
    "    input(\n",
    "        \"Provide connection asset ID in your space. Skip this, if you wish to type credentials by hand and hit enter: \"\n",
    "    )\n",
    "    or None\n",
    ")\n",
    "\n",
    "if milvus_connection_id is None:\n",
    "    try:\n",
    "        username = os.environ[\"USERNAME\"]\n",
    "    except KeyError:\n",
    "        username = input(\"Please enter your Milvus user name and hit enter: \")\n",
    "    try:\n",
    "        password = os.environ[\"PASSWORD\"]\n",
    "    except KeyError:\n",
    "        password = getpass.getpass(\"Please enter your Milvus password and hit enter: \")\n",
    "    try:\n",
    "        host = os.environ[\"HOST\"]\n",
    "    except KeyError:\n",
    "        host = input(\"Please enter your Milvus hostname and hit enter: \")\n",
    "    try:\n",
    "        port = os.environ[\"PORT\"]\n",
    "    except KeyError:\n",
    "        port = input(\"Please enter your Milvus port number and hit enter: \")\n",
    "    try:\n",
    "        ssl = os.environ[\"SSL\"]\n",
    "    except:\n",
    "        ssl = bool(\n",
    "            input(\n",
    "                \"Please enter ('y'/anything) if your Milvus instance has SSL enabled. Skip if it is not: \"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Create connection\n",
    "    milvus_data_source_type_id = api_client.connections.get_datasource_type_uid_by_name(\n",
    "        \"milvus\"\n",
    "    )\n",
    "    details = api_client.connections.create(\n",
    "        {\n",
    "            api_client.connections.ConfigurationMetaNames.NAME: \"Milvus Connection\",\n",
    "            api_client.connections.ConfigurationMetaNames.DESCRIPTION: \"Connection created by the sample notebook\",\n",
    "            api_client.connections.ConfigurationMetaNames.DATASOURCE_TYPE: milvus_data_source_type_id,\n",
    "            api_client.connections.ConfigurationMetaNames.PROPERTIES: {\n",
    "                \"host\": host,\n",
    "                \"port\": port,\n",
    "                \"username\": username,\n",
    "                \"password\": password,\n",
    "                \"ssl\": ssl,\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "\n",
    "    milvus_connection_id = api_client.connections.get_id(details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efea633b",
   "metadata": {},
   "source": [
    "<a id=\"vectorstore\"></a>\n",
    "\n",
    "## Set up VectorStore with Milvus credentials\n",
    "\n",
    "Create a VectorStore class that automatically detects the database type (in our case it will be Milvus) and allows us to add, search and delete documents.\n",
    "\n",
    "It works as a wrapper for LangChain VectorStore classes. You can customize the settings as long as it is supported. Consult the LangChain documentation for more information about <a href=\"https://api.python.langchain.com/en/latest/vectorstores/langchain_community.vectorstores.milvus.Milvus.html\" target=\"_blank\" rel=\"noopener no referrer\">Milvus</a> connector.\n",
    "\n",
    "Provide the name of your Milvus index for subsequent operations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33f600d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_name='example_milvus_index_name'\n"
     ]
    }
   ],
   "source": [
    "index_name = input(\"Please enter Milvus index name and hit enter: \")\n",
    "\n",
    "print(f\"{index_name=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e4ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.foundation_models.extensions.rag.vector_stores import VectorStore\n",
    "\n",
    "vector_store = VectorStore(\n",
    "    api_client=api_client,\n",
    "    connection_id=milvus_connection_id,\n",
    "    index_name=index_name,\n",
    "    embeddings=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41474322",
   "metadata": {},
   "source": [
    "Verify if index in Milvus instance is empty.\n",
    "\n",
    "**Note**: If collection is not empty you can use `clear` method on `VectorStore` object:\n",
    "\n",
    "```python\n",
    "vector_store.clear()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81684c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483ec8fd",
   "metadata": {},
   "source": [
    "<a id=\"input_data\"></a>\n",
    "\n",
    "## References to input data\n",
    "\n",
    "This example uses the `ModelInference` description from the [`ibm_watsonx_ai`](https://ibm.github.io/watsonx-ai-python-sdk/fm_model_inference.html) documentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aee42b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "url = \"https://ibm.github.io/watsonx-ai-python-sdk/fm_model_inference.html\"\n",
    "\n",
    "docs = WebBaseLoader(url).load()\n",
    "model_inference_content = docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7e19a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "document_filename = \"ModelInference.txt\"\n",
    "\n",
    "if not os.path.isfile(document_filename):\n",
    "    with open(document_filename, \"w\") as file:\n",
    "        file.write(model_inference_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3b9052",
   "metadata": {},
   "source": [
    "Upload the input data to the space as a data asset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3995341c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data asset...\n",
      "SUCCESS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'45f7c1e3-0b04-439a-940e-c642e498213a'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_asset_details = api_client.data_assets.create(\n",
    "    name=document_filename, file_path=document_filename\n",
    ")\n",
    "\n",
    "document_asset_id = api_client.data_assets.get_id(document_asset_details)\n",
    "document_asset_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19188d0",
   "metadata": {},
   "source": [
    "Define a connection to the input data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af54a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.helpers import DataConnection\n",
    "\n",
    "data_connection = DataConnection(data_asset_id=document_asset_id)\n",
    "data_connection.set_client(api_client=api_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cf3587",
   "metadata": {},
   "source": [
    "Create `input_data_references` as a `dict` representation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be35cbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"type\": \"data_asset\",\n",
      "    \"location\": {\n",
      "      \"href\": \"/v2/assets/45f7c1e3-0b04-439a-940e-c642e498213a?space_id=9f44cc2b-b3d0-4472-824e-4941afb1617b\",\n",
      "      \"id\": \"45f7c1e3-0b04-439a-940e-c642e498213a\"\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "input_data_references = [data_connection.to_dict()]\n",
    "\n",
    "print(json.dumps(input_data_references, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516f16fd",
   "metadata": {},
   "source": [
    "<a id=\"ai_service\"></a>\n",
    "\n",
    "## Create AI service\n",
    "\n",
    "Prepare function which will be deployed using AI service.\n",
    "\n",
    "Please specify the default parameters that will be passed to the function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d62868cd23699d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:06:44.939085Z",
     "start_time": "2025-04-23T18:06:44.932153Z"
    }
   },
   "outputs": [],
   "source": [
    "def deployable_ai_service(\n",
    "    context,\n",
    "    url=None,\n",
    "    embedding_model_id=None,\n",
    "    milvus_connection_id=None,\n",
    "    index_name=None,\n",
    "):\n",
    "\n",
    "    from ibm_watsonx_ai import APIClient\n",
    "    from ibm_watsonx_ai import Credentials\n",
    "    from ibm_watsonx_ai.helpers import DataConnection\n",
    "    from ibm_watsonx_ai.foundation_models.embeddings import Embeddings\n",
    "    from ibm_watsonx_ai.foundation_models.extensions.rag.vector_stores import (\n",
    "        VectorStore,\n",
    "    )\n",
    "    from ibm_watsonx_ai.data_loaders.datasets.documents import DocumentsIterableDataset\n",
    "    from ibm_watsonx_ai.foundation_models.extensions.rag.chunker.langchain_chunker import (\n",
    "        LangChainChunker,\n",
    "    )\n",
    "\n",
    "    api_client = APIClient(\n",
    "        credentials=Credentials(url=url, token=context.generate_token()),\n",
    "        space_id=context.get_space_id(),\n",
    "    )\n",
    "    print(\"Successfully initialized APIClient\")\n",
    "\n",
    "    embeddings = Embeddings(model_id=embedding_model_id, api_client=api_client)\n",
    "    print(\"Successfully initialized Embeddings\")\n",
    "\n",
    "    def generate_batch(\n",
    "        input_data_references: list[dict], output_data_reference: dict | None = None\n",
    "    ) -> None:\n",
    "\n",
    "        vector_store = VectorStore(\n",
    "            api_client=api_client,\n",
    "            connection_id=milvus_connection_id,\n",
    "            index_name=index_name,\n",
    "            embeddings=embeddings,\n",
    "        )\n",
    "        print(\"Successfully initialized VectorStore\")\n",
    "\n",
    "        connections = []\n",
    "\n",
    "        for input_data_reference in input_data_references:\n",
    "            connections.append(DataConnection.from_dict(input_data_reference))\n",
    "\n",
    "        dataset = DocumentsIterableDataset(\n",
    "            connections=connections, enable_sampling=False, api_client=api_client\n",
    "        )\n",
    "        print(\"Successfully initialized DocumentsIterableDataset\")\n",
    "\n",
    "        chunker = LangChainChunker(\n",
    "            chunk_size=512,\n",
    "        )\n",
    "        print(\"Successfully initialized LangChainChunker\")\n",
    "\n",
    "        documents = chunker.split_documents(dataset)\n",
    "        print(\"Successfully splitted documents\")\n",
    "\n",
    "        vector_store.add_documents(documents)\n",
    "        print(\"Documents added\")\n",
    "\n",
    "        vector_store_count = vector_store.count()\n",
    "        print(f\"Vector Store count: {vector_store_count}\")\n",
    "\n",
    "    return generate_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7459cf",
   "metadata": {},
   "source": [
    "<a id=\"testing\"></a>\n",
    "\n",
    "## Testing AI service's function locally\n",
    "\n",
    "You can test AI service's function locally. Initialise `RuntimeContext` firstly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c8184e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initialized APIClient\n",
      "Successfully initialized Embeddings\n"
     ]
    }
   ],
   "source": [
    "from ibm_watsonx_ai.deployments import RuntimeContext\n",
    "\n",
    "context = RuntimeContext(api_client=api_client)\n",
    "\n",
    "generate_batch = deployable_ai_service(\n",
    "    context,\n",
    "    url=credentials[\"url\"],\n",
    "    embedding_model_id=embedding_model_id,\n",
    "    milvus_connection_id=milvus_connection_id,\n",
    "    index_name=index_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3780105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initialized VectorStore\n",
      "Successfully initialized DocumentsIterableDataset\n",
      "Successfully initialized LangChainChunker\n",
      "Successfully splitted documents\n",
      "Documents added\n",
      "Vector Store count: 82\n"
     ]
    }
   ],
   "source": [
    "generate_batch(input_data_references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0b1fad",
   "metadata": {},
   "source": [
    "Verify the total number of documents currently stored within the Milvus collection.\n",
    "\n",
    "**Note**: Due to the implementation specifics of Milvus, it is necessary to initialize a new VectorStore instance in order to accurately retrieve the count of indexed elements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254f3005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store = VectorStore(\n",
    "    api_client=api_client,\n",
    "    connection_id=milvus_connection_id,\n",
    "    index_name=index_name,\n",
    "    embeddings=embeddings,\n",
    ")\n",
    "\n",
    "vector_store.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a6e75a",
   "metadata": {},
   "source": [
    "Once the collection accurately reflects the expected number of items, proceed to clear its contents to prepare the environment for subsequent testing activities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f38e11ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.clear()\n",
    "vector_store.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e4987a",
   "metadata": {},
   "source": [
    "<a id=\"deploy\"></a>\n",
    "\n",
    "## Deploy AI service\n",
    "\n",
    "Store AI service with previous created custom software specifications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32a0f85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sw_spec_id='45f12dfe-aa78-5b8d-9f38-0ee223c47309'\n"
     ]
    }
   ],
   "source": [
    "sw_spec_id = api_client.software_specifications.get_id_by_name(\"runtime-24.1-py3.11\")\n",
    "print(f\"{sw_spec_id=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f287cbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"entity\": {\n",
      "    \"code_type\": \"python\",\n",
      "    \"software_spec\": {\n",
      "      \"id\": \"45f12dfe-aa78-5b8d-9f38-0ee223c47309\",\n",
      "      \"name\": \"runtime-24.1-py3.11\"\n",
      "    }\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"created_at\": \"2025-05-27T08:01:26.399Z\",\n",
      "    \"description\": \"Sample AI service with implemented generate_batch\",\n",
      "    \"id\": \"ea282d35-57d6-4e27-9cfa-e1c496832b56\",\n",
      "    \"modified_at\": \"2025-05-27T08:01:26.399Z\",\n",
      "    \"name\": \"AI service with generate_batch\",\n",
      "    \"owner\": \"IBMid-55000091VC\",\n",
      "    \"space_id\": \"9f44cc2b-b3d0-4472-824e-4941afb1617b\"\n",
      "  },\n",
      "  \"system\": {\n",
      "    \"warnings\": []\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "meta_props = {\n",
    "    api_client.repository.AIServiceMetaNames.NAME: \"AI service with generate_batch\",\n",
    "    api_client.repository.AIServiceMetaNames.DESCRIPTION: \"Sample AI service with implemented generate_batch\",\n",
    "    api_client.repository.AIServiceMetaNames.SOFTWARE_SPEC_ID: sw_spec_id,\n",
    "}\n",
    "stored_ai_service_details = api_client.repository.store_ai_service(\n",
    "    deployable_ai_service, meta_props\n",
    ")\n",
    "\n",
    "print(json.dumps(stored_ai_service_details, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03993a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai_service_id='ea282d35-57d6-4e27-9cfa-e1c496832b56'\n"
     ]
    }
   ],
   "source": [
    "ai_service_id = api_client.repository.get_ai_service_id(stored_ai_service_details)\n",
    "print(f\"{ai_service_id=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fb42f3",
   "metadata": {},
   "source": [
    "Create batch deployment of AI service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0af1e3039124ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "######################################################################################\n",
      "\n",
      "Synchronous deployment creation for id: 'ea282d35-57d6-4e27-9cfa-e1c496832b56' started\n",
      "\n",
      "######################################################################################\n",
      "\n",
      "\n",
      "ready.\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Successfully finished deployment creation, deployment_id='66820b23-48e2-4bde-9717-f6db689cc06e'\n",
      "-----------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "deployment_id='66820b23-48e2-4bde-9717-f6db689cc06e'\n"
     ]
    }
   ],
   "source": [
    "deployment_details = api_client.deployments.create(\n",
    "    artifact_id=ai_service_id,\n",
    "    meta_props={\n",
    "        api_client.deployments.ConfigurationMetaNames.NAME: \"Vector Store Batch Deployment\",\n",
    "        api_client.deployments.ConfigurationMetaNames.BATCH: {\n",
    "            \"parameters\": {\n",
    "                \"url\": credentials[\"url\"],\n",
    "                \"embedding_model_id\": embedding_model_id,\n",
    "                \"milvus_connection_id\": milvus_connection_id,\n",
    "                \"index_name\": index_name,\n",
    "            }\n",
    "        },\n",
    "        api_client.deployments.ConfigurationMetaNames.HARDWARE_SPEC: {\n",
    "            \"id\": api_client.hardware_specifications.get_id_by_name(\"L\")\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "deployment_id = api_client.deployments.get_id(deployment_details)\n",
    "print(f\"{deployment_id=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13520cda",
   "metadata": {},
   "source": [
    "<a id=\"example\"></a>\n",
    "\n",
    "## Example of executing an AI service\n",
    "\n",
    "Run the following cells to create and run a job with the deployed AI service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f72e1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poll_async_job(wml_client, job_id):\n",
    "    import time\n",
    "\n",
    "    while True:\n",
    "        job_status = wml_client.deployments.get_job_status(job_id)\n",
    "        print(job_status)\n",
    "        state = job_status[\"state\"]\n",
    "        if state == \"completed\" or \"fail\" in state:\n",
    "            return wml_client.deployments.get_job_details(job_id)\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d858b39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_id='f5337ad8-b78f-454b-a6e4-6e54be26dc1e'\n"
     ]
    }
   ],
   "source": [
    "batch_reference_payload = {\n",
    "    \"input_data_references\": input_data_references,\n",
    "}\n",
    "\n",
    "job_details = api_client.deployments.create_job(deployment_id, batch_reference_payload)\n",
    "job_id = api_client.deployments.get_job_id(job_details)\n",
    "print(f\"{job_id=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b887a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'completed_at': '', 'running_at': '', 'state': 'queued'}\n",
      "{'completed_at': '', 'running_at': '', 'state': 'queued'}\n",
      "{'completed_at': '', 'running_at': '', 'state': 'queued'}\n",
      "{'completed_at': '', 'running_at': '2025-05-27T08:02:24.619Z', 'state': 'running'}\n",
      "{'completed_at': '', 'running_at': '2025-05-27T08:02:24.619Z', 'state': 'running'}\n",
      "{'completed_at': '', 'running_at': '2025-05-27T08:02:24.619Z', 'state': 'running'}\n",
      "{'completed_at': '2025-05-27T08:02:44.115706Z', 'running_at': '2025-05-27T08:02:24.552221Z', 'state': 'completed'}\n"
     ]
    }
   ],
   "source": [
    "job_details = poll_async_job(api_client, job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847136af",
   "metadata": {},
   "source": [
    "Verify the total number of documents currently stored within the Milvus collection.\n",
    "\n",
    "**Note**: Due to the implementation specifics of Milvus, it is necessary to initialize a new VectorStore instance in order to accurately retrieve the count of indexed elements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff36856a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store = VectorStore(\n",
    "    api_client=api_client,\n",
    "    connection_id=milvus_connection_id,\n",
    "    index_name=index_name,\n",
    "    embeddings=embeddings,\n",
    ")\n",
    "\n",
    "vector_store.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57c0c31",
   "metadata": {},
   "source": [
    "<a id=\"cleanup\"></a>\n",
    "\n",
    "## Cleanup\n",
    "\n",
    "Please execute the following commands to clean up and decommission all resources provisioned during the execution of this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddc15729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete deployment job\n",
    "\n",
    "api_client.deployments.delete_job(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7571bc19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete batch deployment\n",
    "\n",
    "api_client.deployments.delete(deployment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c7308da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete AI service asset\n",
    "\n",
    "api_client.repository.delete(ai_service_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca31ea79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete `ModelInference.txt` asset\n",
    "\n",
    "api_client.data_assets.delete(document_asset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cca5915e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelInference.txt has been deleted.\n"
     ]
    }
   ],
   "source": [
    "# Delete `ModelInference.txt` file locally\n",
    "\n",
    "import os\n",
    "\n",
    "if os.path.exists(document_filename):\n",
    "    os.remove(document_filename)\n",
    "    print(f\"{document_filename} has been deleted.\")\n",
    "else:\n",
    "    print(f\"{document_filename} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687b81b2",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "\n",
    "## Summary and next steps\n",
    "\n",
    "You successfully completed this notebook!\n",
    "\n",
    "You have successfully learned how to design and deploy an AI service utilizing the `generate_batch` functionality, leveraging the capabilities of the `ibm_watsonx_ai` SDK.\n",
    "\n",
    "Check out our _<a href=\"https://ibm.github.io/watsonx-ai-python-sdk/samples.html\" target=\"_blank\" rel=\"noopener no referrer\">Online Documentation</a>_ for more samples, tutorials, documentation, how-tos, and blog posts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19249cc",
   "metadata": {},
   "source": [
    "### Author\n",
    "\n",
    "**Mateusz Szewczyk**, Software Engineer at watsonx.ai.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8072d0b",
   "metadata": {},
   "source": [
    "Copyright © 2025 IBM. This notebook and its source code are released under the terms of the MIT License.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
