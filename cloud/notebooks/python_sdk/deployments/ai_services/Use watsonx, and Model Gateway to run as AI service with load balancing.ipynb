{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
        "# Use watsonx, and Model Gateway to run as AI service with load balancing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### Disclaimers\n",
        "\n",
        "- Use only Projects and Spaces that are available in watsonx context.\n",
        "\n",
        "\n",
        "## Notebook content\n",
        "\n",
        "This notebook provides a detailed demonstration of the steps and code required to showcase support for watsonx.ai Model Gateway.\n",
        "\n",
        "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
        "\n",
        "\n",
        "## Learning goal\n",
        "\n",
        "The learning goal for your notebook is to leverage Model Gateway to create AI services using provided model from OpenAI compatible provider. You will also learn how to achieve model load balancing inside the AI service.\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "This notebook contains the following parts:\n",
        "\n",
        "- [Setup](#setup)\n",
        "- [Initialize and configure Model Gateway](#gateway-configuration)\n",
        "- [Create model and deploy it as AI service](#create-model-ai-service)\n",
        "- [Create models and deploy them as an AI service with load balancing](#create-models-ai-service-load-balancing)\n",
        "- [Summary](#summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"setup\"></a>\n",
        "## Set up the environment\n",
        "\n",
        "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
        "\n",
        "- Create a <a href=\"https://cloud.ibm.com/catalog/services/watsonxai-runtime\" target=\"_blank\" rel=\"noopener no referrer\">watsonx.ai Runtime Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/wml-plans.html?context=wx&audience=wdp\" target=\"_blank\" rel=\"noopener no referrer\">here</a>).\n",
        "\n",
        "**Note:** The example of model load balancing presented in this sample notebook may raise `Status Code 429 (Too Many Requests)` errors when using the free plan, due to lower maximum number of requests allowed per second."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Install dependencies\n",
        "**Note:** `ibm-watsonx-ai` documentation can be found <a href=\"https://ibm.github.io/watsonx-ai-python-sdk/index.html\" target=\"_blank\" rel=\"noopener no referrer\">here</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1A\u001b[2KSuccessfully installed anyio-4.9.0 certifi-2025.6.15 charset_normalizer-3.4.2 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 ibm-cos-sdk-2.14.2 ibm-cos-sdk-core-2.14.2 ibm-cos-sdk-s3transfer-2.14.2 ibm_watsonx_ai-1.3.26 idna-3.10 jmespath-1.0.1 lomond-0.3.3 numpy-2.3.1 pandas-2.2.3 pytz-2025.2 requests-2.32.4 sniffio-1.3.1 tabulate-0.9.0 tzdata-2025.2 urllib3-2.5.0\n"
          ]
        }
      ],
      "source": [
        "%pip install -U \"ibm_watsonx_ai>=1.3.25\" | tail -n 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Define the watsonx.ai credentials\n",
        "Use the code cell below to define the watsonx.ai credentials that are required to work with watsonx Foundation Model inferencing.\n",
        "\n",
        "**Action:** Provide the IBM Cloud user API key. For details, see <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\" rel=\"noopener no referrer\">Managing user API keys</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "from ibm_watsonx_ai import Credentials\n",
        "\n",
        "credentials = Credentials(\n",
        "    url=\"https://ca-tor.ml.cloud.ibm.com\",\n",
        "    api_key=getpass.getpass(\"Enter your watsonx.ai api key and hit enter: \"),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Working with projects\n",
        "\n",
        "First of all, you need to create a project that will be used for your work.  \n",
        "The project must have a watsonx.ai Runtime instance assigned to it for this notebook to work properly.  \n",
        "To assign an instance, follow the [documentation](https://www.ibm.com/docs/en/watsonx/saas?topic=projects-adding-associated-services).  \n",
        "\n",
        "If you do not have project already created, follow the steps below:\n",
        "- Open IBM Cloud Pak main page\n",
        "- Click all projects\n",
        "- Create an empty project\n",
        "- Assign the watsonx.ai Runtime instance\n",
        "- Copy `project_id` from url and paste it below\n",
        "\n",
        "**Action**: Assign project ID below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    project_id = os.environ[\"PROJECT_ID\"]\n",
        "except KeyError:\n",
        "    project_id = input(\"Please enter your project_id (hit enter): \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Working with spaces\n",
        "\n",
        "You need to create a space that will be used for your work. If you do not have a space, you can use [Deployment Spaces Dashboard](https://dataplatform.cloud.ibm.com/ml-runtime/spaces?context=wx) to create one.\n",
        "\n",
        "- Click **New Deployment Space**\n",
        "- Create an empty space\n",
        "- Select Cloud Object Storage\n",
        "- Select watsonx.ai Runtime instance and press **Create**\n",
        "- Go to **Manage** tab\n",
        "- Copy `Space GUID` and paste it below\n",
        "\n",
        "**Tip**: You can also use SDK to prepare the space for your work. More information can be found [here](https://github.com/IBM/watson-machine-learning-samples/blob/master/cloud/notebooks/python_sdk/instance-management/Space%20management.ipynb).\n",
        "\n",
        "**Action**: assign space ID below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    space_id = os.environ[\"SPACE_ID\"]\n",
        "except KeyError:\n",
        "    space_id = input(\"Please enter your space_id (hit enter): \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create `APIClient` instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai import APIClient\n",
        "\n",
        "client = APIClient(credentials=credentials, project_id=project_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define IBM Cloud Secrets Manager URL\n",
        "In order to store secrets for different model providers, you need to use the IBM Cloud Secrets Manager.\n",
        "\n",
        "**Note:** This notebook assumes that the IBM Cloud Secrets Manager instance is already configured. In order to configure the instance, follow [this chapter](https://www.ibm.com/docs/en/watsonx/saas?topic=models-using-model-gateway-preview#setting-up-authentication) in the documentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "secrets_manager_url = \"PASTE_YOUR_IBM_CLOUD_SECRETS_MANAGER_URL_HERE\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"gateway-configuration\"></a>\n",
        "## Initialize and configure Model Gateway\n",
        "In this section we will initialize the Model Gateway and configure its providers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize the Model Gateway\n",
        "Create `Gateway` instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.gateway import Gateway\n",
        "\n",
        "gateway = Gateway(api_client=client)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set your IBM Cloud Secrets Manager instance\n",
        "\n",
        "**Note:** This instance will store your provider credentials. The same credentials will later be used inside the AI service."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 'd6a9d735-dca3-5492-9161-62577c7bc575',\n",
              " 'name': 'Watsonx AI Model Gateway configuration'}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gateway.set_secrets_manager(secrets_manager_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "List available providers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>NAME</th>\n",
              "      <th>TYPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [ID, NAME, TYPE]\n",
              "Index: []"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gateway.providers.list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Work with watsonx.ai provider"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create provider"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'00fe7893-d792-4918-bcc8-b4e79093495f'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "watsonx_ai_provider_details = gateway.providers.create(\n",
        "    provider=\"watsonxai\",\n",
        "    name=\"watsonx-ai-provider\",\n",
        "    data={\n",
        "        \"apikey\": client.credentials.api_key,\n",
        "        \"auth_url\": client.service_instance._href_definitions.get_iam_token_url(),\n",
        "        \"base_url\": client.credentials.url,\n",
        "        \"project_id\": project_id,\n",
        "    },\n",
        ")\n",
        "\n",
        "watsonx_ai_provider_id = gateway.providers.get_id(watsonx_ai_provider_details)\n",
        "watsonx_ai_provider_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get provider details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'uuid': '00fe7893-d792-4918-bcc8-b4e79093495f',\n",
              " 'name': 'watsonx-ai-provider',\n",
              " 'type': 'watsonxai',\n",
              " 'data': {'apikey': '[secret]',\n",
              "  'auth_url': 'https://iam.cloud.ibm.com/oidc/token',\n",
              "  'base_url': 'https://ca-tor.ml.cloud.ibm.com',\n",
              "  'project_id': '6ea95df4-ef51-4a8f-b3d2-9a3349fbf6f8'}}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gateway.providers.get_details(watsonx_ai_provider_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "List available models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MODEL_ID</th>\n",
              "      <th>TYPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ibm/granite-3-8b-instruct</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ibm/granite-embedding-107m-multilingual</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ibm/granite-embedding-278m-multilingual</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ibm/slate-125m-english-rtrvr-v2</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ibm/slate-30m-english-rtrvr-v2</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>intfloat/multilingual-e5-large</td>\n",
              "      <td>intfloat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>meta-llama/llama-3-2-11b-vision-instruct</td>\n",
              "      <td>Meta:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>meta-llama/llama-3-3-70b-instruct</td>\n",
              "      <td>Meta:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>mistralai/mistral-large</td>\n",
              "      <td>Mistral AI:Mistral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>mistralai/pixtral-12b</td>\n",
              "      <td>Mistral AI:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>sentence-transformers/all-minilm-l12-v2</td>\n",
              "      <td>sentence-transformers</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    MODEL_ID                     TYPE\n",
              "0                  ibm/granite-3-8b-instruct                      IBM\n",
              "1    ibm/granite-embedding-107m-multilingual                      IBM\n",
              "2    ibm/granite-embedding-278m-multilingual                      IBM\n",
              "3            ibm/slate-125m-english-rtrvr-v2                      IBM\n",
              "4             ibm/slate-30m-english-rtrvr-v2                      IBM\n",
              "5             intfloat/multilingual-e5-large                 intfloat\n",
              "6   meta-llama/llama-3-2-11b-vision-instruct        Meta:Hugging Face\n",
              "7          meta-llama/llama-3-3-70b-instruct        Meta:Hugging Face\n",
              "8                    mistralai/mistral-large       Mistral AI:Mistral\n",
              "9                      mistralai/pixtral-12b  Mistral AI:Hugging Face\n",
              "10   sentence-transformers/all-minilm-l12-v2    sentence-transformers"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gateway.providers.list_available_models(watsonx_ai_provider_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"create-model-ai-service\"></a>\n",
        "\n",
        "## Create model and deploy it as AI service\n",
        "In this section we will create a model using Model Gateway and deploy it as an AI service."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create model using Model Gateway\n",
        "In this sample we will use the `ibm/granite-3-8b-instruct` model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = \"ibm/granite-3-8b-instruct\"\n",
        "\n",
        "model_details = gateway.models.create(\n",
        "    provider_id=watsonx_ai_provider_id,\n",
        "    model=model,\n",
        ")\n",
        "\n",
        "model_id = gateway.models.get_id(model_details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>NAME</th>\n",
              "      <th>TYPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00fe7893-d792-4918-bcc8-b4e79093495f</td>\n",
              "      <td>watsonx-ai-provider</td>\n",
              "      <td>watsonxai</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     ID                 NAME       TYPE\n",
              "0  00fe7893-d792-4918-bcc8-b4e79093495f  watsonx-ai-provider  watsonxai"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gateway.providers.list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create custom software specification containing a custom version of `ibm-watsonx-ai` SDK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Change client from project to space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsetting the project_id ...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'SUCCESS'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.set.default_space(space_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define `requirements.txt` file for package extension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "requirements_txt = \"ibm-watsonx-ai>=1.3.25\"\n",
        "\n",
        "with open(\"requirements.txt\", \"w\") as file:\n",
        "    file.write(requirements_txt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get the ID of base software specification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_software_specification_id = client.software_specifications.get_id_by_name(\n",
        "    \"runtime-24.1-py3.11\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Store the package extension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating package extensions\n",
            "SUCCESS\n"
          ]
        }
      ],
      "source": [
        "meta_props = {\n",
        "    client.package_extensions.ConfigurationMetaNames.NAME: \"Model Gateway extension\",\n",
        "    client.package_extensions.ConfigurationMetaNames.DESCRIPTION: \"Package extension with Model Gateway functionality enabled in ibm-watsonx-ai\",\n",
        "    client.package_extensions.ConfigurationMetaNames.TYPE: \"requirements_txt\",\n",
        "}\n",
        "\n",
        "package_extension_details = client.package_extensions.store(\n",
        "    meta_props, file_path=\"requirements.txt\"\n",
        ")\n",
        "package_extension_id = client.package_extensions.get_id(package_extension_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a new software specification with the created package extension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SUCCESS\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'SUCCESS'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "meta_props = {\n",
        "    client.software_specifications.ConfigurationMetaNames.NAME: \"Model Gateway software specification\",\n",
        "    client.software_specifications.ConfigurationMetaNames.DESCRIPTION: \"Software specification for Model Gateway\",\n",
        "    client.software_specifications.ConfigurationMetaNames.BASE_SOFTWARE_SPECIFICATION: {\n",
        "        \"guid\": base_software_specification_id\n",
        "    },\n",
        "}\n",
        "\n",
        "software_specification_details = client.software_specifications.store(meta_props)\n",
        "software_specification_id = client.software_specifications.get_id(\n",
        "    software_specification_details\n",
        ")\n",
        "\n",
        "client.software_specifications.add_package_extension(\n",
        "    software_specification_id, package_extension_id\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create AI service\n",
        "\n",
        "Prepare function which will be deployed using AI service."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def deployable_ai_service(context, url=credentials.url, model_id=model, **kwargs): # fmt: skip\n",
        "    from ibm_watsonx_ai import APIClient, Credentials\n",
        "    from ibm_watsonx_ai.gateway import Gateway\n",
        "\n",
        "    api_client = APIClient(\n",
        "        credentials=Credentials(url=url, token=context.generate_token()),\n",
        "        space_id=context.get_space_id(),\n",
        "    )\n",
        "\n",
        "    gateway = Gateway(api_client=api_client)\n",
        "\n",
        "    def generate(context) -> dict:\n",
        "        api_client.set_token(context.get_token())\n",
        "\n",
        "        payload = context.get_json()\n",
        "        prompt = payload[\"prompt\"]\n",
        "\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        response = gateway.chat.completions.create(model=model_id, messages=messages)\n",
        "\n",
        "        return {\"body\": response}\n",
        "\n",
        "    return generate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing AI service's function locally\n",
        "\n",
        "Create AI service function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.deployments import RuntimeContext\n",
        "\n",
        "context = RuntimeContext(api_client=client)\n",
        "local_function = deployable_ai_service(context=context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare request payload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "context.request_payload_json = {\"prompt\": \"What is a tram?\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Execute the function locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'body': {'id': 'chatcmpl-19058338132fe3118c0f218b7b7a0322---9eaffb7c-e27a-4417-9467-8c386b86c201',\n",
              "  'object': 'chat.completion',\n",
              "  'created': 1751439768,\n",
              "  'model': 'ibm/granite-3-8b-instruct',\n",
              "  'choices': [{'index': 0,\n",
              "    'message': {'role': 'assistant',\n",
              "     'content': 'A tram, also known as a streetcar or trolley, is a rail vehicle that operates on tracks embedded in city streets, providing urban transportation. It is commonly powered by electricity, either from overhead wires or through a third rail on the ground. Trams are typically smaller than light rail vehicles and are designed to navigate through dense city traffic. They offer a sustainable and accessible mode of transportation, serving many key destinations in an urban setting, and their route networks can evolve to meet changing city needs.\\n\\nTrams have a rich history, with the first streetcar lines appearing in the mid-19th century. Over time, they have evolved in design and technology. Modern trams are often low-floor vehicles, improving accessibility and ease of boarding for passengers with disabilities, strollers, and luggage. Additionally, numerous cities worldwide have recently introduced modern tram systems or expanded and upgraded existing lines, integrating them with other public transit modes, such as buses, trains, and bikesharing systems.\\n\\nTrams provide a variety of benefits for urban environments. They help reduce traffic congestion by offering an efficient alternative to cars, lower greenhouse gas emissions through their electric propulsion, and stimulate economic development along their routes. Furthermore, trams foster a vibrant street life, encouraging mixed-use development and human-scale urban design.\\n\\nIn summary, trams are an essential component of sustainable urban mobility, offering a green, accessible, and socio-economically beneficial transportation solution for modern cities.',\n",
              "     'refusal': '',\n",
              "     'tool_calls': None},\n",
              "    'finish_reason': 'stop',\n",
              "    'logprobs': None}],\n",
              "  'usage': {'prompt_tokens': 65,\n",
              "   'completion_tokens': 354,\n",
              "   'total_tokens': 419},\n",
              "  'service_tier': None,\n",
              "  'system_fingerprint': '',\n",
              "  'cached': False}}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resp = local_function(context)\n",
        "resp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deploy AI service"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Store AI service with previously created custom software specification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "meta_props = {\n",
        "    client.repository.AIServiceMetaNames.NAME: \"Model Gateway AI service with SDK\",\n",
        "    client.repository.AIServiceMetaNames.SOFTWARE_SPEC_ID: software_specification_id,\n",
        "}\n",
        "\n",
        "stored_ai_service_details = client.repository.store_ai_service(\n",
        "    deployable_ai_service, meta_props\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'06a453f4-d750-450d-8c37-21eaecc52025'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ai_service_id = client.repository.get_ai_service_id(stored_ai_service_details)\n",
        "ai_service_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create online deployment of AI service."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "######################################################################################\n",
            "\n",
            "Synchronous deployment creation for id: '06a453f4-d750-450d-8c37-21eaecc52025' started\n",
            "\n",
            "######################################################################################\n",
            "\n",
            "\n",
            "initializing\n",
            "Note: online_url and serving_urls are deprecated and will be removed in a future release. Use inference instead.\n",
            ".....\n",
            "ready\n",
            "\n",
            "\n",
            "-----------------------------------------------------------------------------------------------\n",
            "Successfully finished deployment creation, deployment_id='ed1fa174-a9e6-4eb6-8826-7a560d149a46'\n",
            "-----------------------------------------------------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "meta_props = {\n",
        "    client.deployments.ConfigurationMetaNames.NAME: \"AI service with SDK\",\n",
        "    client.deployments.ConfigurationMetaNames.ONLINE: {},\n",
        "}\n",
        "\n",
        "deployment_details = client.deployments.create(ai_service_id, meta_props)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Obtain the `deployment_id` of the previously created deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "deployment_id = client.deployments.get_id(deployment_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Execute the AI service"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "question = \"Summarize core values of IBM\"\n",
        "\n",
        "deployments_results = client.deployments.run_ai_service(\n",
        "    deployment_id, {\"prompt\": question}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"cached\": false,\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"IBM's core values revolve around five main principles:\\n\\n1. Dedication to the client: IBM is committed to providing exceptional service and solutions to its clients, exceeding their expectations and being accountable for delivering results.\\n\\n2. Innovation: Continuous innovation is essential to IBM, which strives to lead and shape the future through groundbreaking technology and ideas. They encourage creativity and stay at the forefront of emerging trends.\\n\\n3. Trust and personal integrity: At IBM, employees are entrusted with building lasting relationships with clients and partners based on honesty, transparency, and respect for others.\\n\\n4. Respect for the individual: IBM values diversity and fosters an inclusive environment where everyone is valued and empowered to contribute their unique perspectives and talents.\\n\\n5. Excellence and quality: IBM holds itself to the highest standards of quality, both in its products and services as well as its internal processes, continually seeking to improve and exceed expectations.\\n\\nIn addition to these values, IBM adheres to its guiding principles during its \\\"IBMBOSTON\\\" meetings and summits. These include: Balance of thought and action, Being open to new ideas, Seeking knowledge and understanding, Taking responsibility, Operational excellence, and Shared leadership.\\n\\nTogether, these core values and guiding principles help form the backbone of IBM's corporate culture, driving the company to success and maintaining its reputation as a responsible, innovative, and client-focused organization.\",\n",
            "        \"refusal\": \"\",\n",
            "        \"role\": \"assistant\",\n",
            "        \"tool_calls\": null\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1751439827,\n",
            "  \"id\": \"chatcmpl-0ca8737a5d6113cd2aa531244d1d86d1---8773a453-8c9a-4443-9d8b-3dc66c8d79d0\",\n",
            "  \"model\": \"ibm/granite-3-8b-instruct\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"service_tier\": null,\n",
            "  \"system_fingerprint\": \"\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 339,\n",
            "    \"prompt_tokens\": 66,\n",
            "    \"total_tokens\": 405\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "print(json.dumps(deployments_results, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"create-models-ai-service-load-balancing\"></a>\n",
        "\n",
        "## Create models and deploy them as an AI service with load balancing\n",
        "In this section we will create models with the same alias using Model Gateway and deploy them as an AI service in order to perform load balancing between them.\n",
        "\n",
        "**Note:** This sample notebook creates three providers using watsonx.ai. It's worth pointing out that Model Gateway can also load balance between other providers, such as AWS Bedrock or NVIDIA NIM, as well as between different datacenters. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create models using Model Gateway with the same alias on different providers\n",
        "In this sample we will use the `ibm/granite-3-8b-instruct`, `meta-llama/llama-3-2-11b-vision-instruct`, and `meta-llama/llama-3-3-70b-instruct` models in the same datacenter.\n",
        "\n",
        "**Tip:** It is also possible to perform load balancing across datacenters in different regions. In order to achieve it, when creating your providers you should use credentials for separate datacenters. See the example below:"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "watsonx_ai_provider_ca_tor_details = gateway.providers.create(\n",
        "    provider=\"watsonxai\",\n",
        "    name=\"watsonx-ai-provider-ca-tor\",\n",
        "    data={\n",
        "        \"apikey\": \"<ca-tor-api-key>\",\n",
        "        \"auth_url\": \"https://iam.cloud.ibm.com/oidc/token\",\n",
        "        \"base_url\": \"https://ca-tor.ml.cloud.ibm.com\",\n",
        "        \"project_id\": \"<ca-tor-project-id>\",\n",
        "    },\n",
        ")\n",
        "\n",
        "watsonx_ai_provider_au_syd_details = gateway.providers.create(\n",
        "    provider=\"watsonxai\",\n",
        "    name=\"watsonx-ai-provider-au-syd\",\n",
        "    data={\n",
        "        \"apikey\": \"<au-syd-api-key>\",\n",
        "        \"auth_url\": \"https://iam.cloud.ibm.com/oidc/token\",\n",
        "        \"base_url\": \"https://au-syd.ml.cloud.ibm.com\",\n",
        "        \"project_id\": \"<au-syd-project-id>\",\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_alias = \"load-balancing-llama-models\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create provider for `ibm/granite-3-8b-instruct` model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "granite_3_model = \"ibm/granite-3-8b-instruct\"\n",
        "\n",
        "watsonx_ai_provider_1_details = gateway.providers.create(\n",
        "    provider=\"watsonxai\",\n",
        "    name=\"watsonx-ai-provider-1\",\n",
        "    data={\n",
        "        \"apikey\": client.credentials.api_key,\n",
        "        \"auth_url\": client.service_instance._href_definitions.get_iam_token_url(),\n",
        "        \"base_url\": client.credentials.url,\n",
        "        \"project_id\": project_id,\n",
        "    },\n",
        ")\n",
        "\n",
        "watsonx_ai_provider_1_id = gateway.providers.get_id(watsonx_ai_provider_1_details)\n",
        "\n",
        "granite_3_model_details = gateway.models.create(\n",
        "    provider_id=watsonx_ai_provider_1_id,\n",
        "    model=granite_3_model,\n",
        "    alias=model_alias,\n",
        ")\n",
        "\n",
        "granite_3_model_id = gateway.models.get_id(granite_3_model_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create provider for `meta-llama/llama-3-2-11b-vision-instruct` model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "llama_3_2_model = \"meta-llama/llama-3-2-11b-vision-instruct\"\n",
        "\n",
        "watsonx_ai_provider_2_details = gateway.providers.create(\n",
        "    provider=\"watsonxai\",\n",
        "    name=\"watsonx-ai-provider-2\",\n",
        "    data={\n",
        "        \"apikey\": client.credentials.api_key,\n",
        "        \"auth_url\": client.service_instance._href_definitions.get_iam_token_url(),\n",
        "        \"base_url\": client.credentials.url,\n",
        "        \"project_id\": project_id,\n",
        "    },\n",
        ")\n",
        "\n",
        "watsonx_ai_provider_2_id = gateway.providers.get_id(watsonx_ai_provider_2_details)\n",
        "\n",
        "llama_3_2_model_details = gateway.models.create(\n",
        "    provider_id=watsonx_ai_provider_2_id,\n",
        "    model=llama_3_2_model,\n",
        "    alias=model_alias,\n",
        ")\n",
        "\n",
        "llama_3_2_model_id = gateway.models.get_id(llama_3_2_model_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create provider for `meta-llama/llama-3-3-70b-instruct` model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "llama_3_3_model = \"meta-llama/llama-3-3-70b-instruct\"\n",
        "\n",
        "watsonx_ai_provider_3_details = gateway.providers.create(\n",
        "    provider=\"watsonxai\",\n",
        "    name=\"watsonx-ai-provider-3\",\n",
        "    data={\n",
        "        \"apikey\": client.credentials.api_key,\n",
        "        \"auth_url\": client.service_instance._href_definitions.get_iam_token_url(),\n",
        "        \"base_url\": client.credentials.url,\n",
        "        \"project_id\": project_id,\n",
        "    },\n",
        ")\n",
        "\n",
        "watsonx_ai_provider_3_id = gateway.providers.get_id(watsonx_ai_provider_3_details)\n",
        "\n",
        "llama_3_3_model_details = gateway.models.create(\n",
        "    provider_id=watsonx_ai_provider_3_id,\n",
        "    model=llama_3_3_model,\n",
        "    alias=model_alias,\n",
        ")\n",
        "\n",
        "llama_3_3_model_id = gateway.models.get_id(llama_3_3_model_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### List available providers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>NAME</th>\n",
              "      <th>TYPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00fe7893-d792-4918-bcc8-b4e79093495f</td>\n",
              "      <td>watsonx-ai-provider</td>\n",
              "      <td>watsonxai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5db14f5d-a3fd-4035-bca2-ce3514262e57</td>\n",
              "      <td>watsonx-ai-provider-1</td>\n",
              "      <td>watsonxai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>02b67aa0-1f02-4055-b40b-bc693c4d2d91</td>\n",
              "      <td>watsonx-ai-provider-2</td>\n",
              "      <td>watsonxai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8f52b470-31d2-4684-bd38-dd4577487a09</td>\n",
              "      <td>watsonx-ai-provider-3</td>\n",
              "      <td>watsonxai</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     ID                   NAME       TYPE\n",
              "0  00fe7893-d792-4918-bcc8-b4e79093495f    watsonx-ai-provider  watsonxai\n",
              "1  5db14f5d-a3fd-4035-bca2-ce3514262e57  watsonx-ai-provider-1  watsonxai\n",
              "2  02b67aa0-1f02-4055-b40b-bc693c4d2d91  watsonx-ai-provider-2  watsonxai\n",
              "3  8f52b470-31d2-4684-bd38-dd4577487a09  watsonx-ai-provider-3  watsonxai"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gateway.providers.list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create AI service\n",
        "\n",
        "Prepare function which will be deployed using AI service. Please specify the default parameters that will be passed to the function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def deployable_load_balancing_ai_service(context, url=credentials.url, model_alias=model_alias, **kwargs): # fmt: skip\n",
        "    from ibm_watsonx_ai import APIClient, Credentials\n",
        "    from ibm_watsonx_ai.gateway import Gateway\n",
        "\n",
        "    api_client = APIClient(\n",
        "        credentials=Credentials(url=url, token=context.generate_token()),\n",
        "        space_id=context.get_space_id(),\n",
        "    )\n",
        "\n",
        "    gateway = Gateway(api_client=api_client)\n",
        "\n",
        "    def generate(context) -> dict:\n",
        "        api_client.set_token(context.get_token())\n",
        "\n",
        "        payload = context.get_json()\n",
        "        prompt = payload[\"prompt\"]\n",
        "\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        response = gateway.chat.completions.create(model=model_alias, messages=messages)\n",
        "\n",
        "        return {\"body\": response}\n",
        "\n",
        "    return generate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing AI service's function locally\n",
        "\n",
        "Create AI service function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.deployments import RuntimeContext\n",
        "\n",
        "context = RuntimeContext(api_client=client)\n",
        "local_load_balancing_function = deployable_load_balancing_ai_service(context=context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare request payload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "context.request_payload_json = {\"prompt\": \"Explain what IBM is\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Execute the function locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'ibm/granite-3-8b-instruct': 12,\n",
              "         'meta-llama/llama-3-2-11b-vision-instruct': 7,\n",
              "         'meta-llama/llama-3-3-70b-instruct': 6})"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import asyncio\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "async def send_requests(function, context):\n",
        "    tasks: list[asyncio.Future] = []\n",
        "    for _ in range(25):\n",
        "        task = asyncio.to_thread(function, context)\n",
        "        tasks.append(task)\n",
        "        await asyncio.sleep(0.2)\n",
        "\n",
        "    return await asyncio.gather(*tasks)\n",
        "\n",
        "\n",
        "loop = asyncio.get_event_loop()\n",
        "responses = await loop.create_task(\n",
        "    send_requests(function=local_load_balancing_function, context=context)\n",
        ")\n",
        "\n",
        "Counter(map(lambda x: x[\"body\"][\"model\"], responses))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As demonstrated, out of 25 requests sent to Model Gateway:\n",
        "- 12 of them were handled by `ibm/granite-3-8b-instruct`,\n",
        "- 7 of them were handled by `meta-llama/llama-3-2-11b-vision-instruct`,\n",
        "- 6 of them were handled by `meta-llama/llama-3-3-70b-instruct`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deploy AI service"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Store AI service with previously created custom software specification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "meta_props = {\n",
        "    client.repository.AIServiceMetaNames.NAME: \"Model Gateway load balancing AI service with SDK\",\n",
        "    client.repository.AIServiceMetaNames.SOFTWARE_SPEC_ID: software_specification_id,\n",
        "}\n",
        "\n",
        "stored_ai_service_details = client.repository.store_ai_service(\n",
        "    deployable_load_balancing_ai_service, meta_props\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'01981919-3ad2-4e02-8d25-d8ce2d2c8f14'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ai_service_id = client.repository.get_ai_service_id(stored_ai_service_details)\n",
        "ai_service_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create online deployment of AI service."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "######################################################################################\n",
            "\n",
            "Synchronous deployment creation for id: '01981919-3ad2-4e02-8d25-d8ce2d2c8f14' started\n",
            "\n",
            "######################################################################################\n",
            "\n",
            "\n",
            "initializing\n",
            "Note: online_url and serving_urls are deprecated and will be removed in a future release. Use inference instead.\n",
            ".....\n",
            "ready\n",
            "\n",
            "\n",
            "-----------------------------------------------------------------------------------------------\n",
            "Successfully finished deployment creation, deployment_id='a243efbb-1c7c-468a-918b-26fd1aa50dd7'\n",
            "-----------------------------------------------------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "meta_props = {\n",
        "    client.deployments.ConfigurationMetaNames.NAME: \"Load balancing AI service with SDK\",\n",
        "    client.deployments.ConfigurationMetaNames.ONLINE: {},\n",
        "}\n",
        "\n",
        "deployment_details = client.deployments.create(ai_service_id, meta_props)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Obtain the `deployment_id` of the previously created deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "deployment_id = client.deployments.get_id(deployment_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Execute the AI service\n",
        "In the following cell there are 25 requests send to the AI service in asynchronous mode. Between each request there is a 0.2 second delay in order to avoid `429 Too Many Requests` errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'ibm/granite-3-8b-instruct': 12,\n",
              "         'meta-llama/llama-3-2-11b-vision-instruct': 7,\n",
              "         'meta-llama/llama-3-3-70b-instruct': 6})"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "async def send_requests(question):\n",
        "    tasks: list[asyncio.Future] = []\n",
        "    for _ in range(25):\n",
        "        task = asyncio.to_thread(\n",
        "            client.deployments.run_ai_service, deployment_id, {\"prompt\": question}\n",
        "        )\n",
        "        tasks.append(task)\n",
        "        await asyncio.sleep(0.2)\n",
        "\n",
        "    return await asyncio.gather(*tasks)\n",
        "\n",
        "\n",
        "loop = asyncio.get_event_loop()\n",
        "responses = await loop.create_task(\n",
        "    send_requests(question=\"Explain to me what is a dog in cat language\")\n",
        ")\n",
        "\n",
        "Counter(map(lambda x: x[\"model\"], responses))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As demonstrated, out of 25 requests sent to AI Service:\n",
        "- 12 of them were handled by `ibm/granite-3-8b-instruct`,\n",
        "- 7 of them were handled by `meta-llama/llama-3-2-11b-vision-instruct`,\n",
        "- 6 of them were handled by `meta-llama/llama-3-3-70b-instruct`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"summary\"></a>\n",
        "## Summary and next steps\n",
        "\n",
        "You successfully completed this notebook!\n",
        "\n",
        "You learned how to create and deploy a load-balancing AI service with Model Gateway using `ibm_watsonx_ai` SDK.\n",
        "\n",
        "Check out our _<a href=\"https://ibm.github.io/watsonx-ai-python-sdk/samples.html\" target=\"_blank\" rel=\"noopener no referrer\">Online Documentation</a>_ for more samples, tutorials, documentation, how-tos, and blog posts. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Author\n",
        "\n",
        "**Rafa Chrzanowski**, Software Engineer Intern at watsonx.ai."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright  2025 IBM. This notebook and its source code are released under the terms of the MIT License."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "watsonx-ai-samples-py-311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
