{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
        "# Use watsonx, and Model Gateway to run as AI service with load balancing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### Disclaimers\n",
        "\n",
        "- Use only Projects and Spaces that are available in watsonx context.\n",
        "\n",
        "\n",
        "## Notebook content\n",
        "\n",
        "This notebook provides a detailed demonstration of the steps and code required to showcase support for watsonx.ai Model Gateway.\n",
        "\n",
        "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
        "\n",
        "\n",
        "## Learning goal\n",
        "\n",
        "The learning goal for your notebook is to leverage Model Gateway to create AI services using provided model from OpenAI compatible provider. You will also learn how to achieve model load balancing inside the AI service.\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "This notebook contains the following parts:\n",
        "\n",
        "- [Setup](#setup)\n",
        "- [Initialize and configure Model Gateway](#gateway-configuration)\n",
        "- [Create model and deploy it as AI service](#create-model-ai-service)\n",
        "- [Create models and deploy them as an AI service with load balancing](#create-models-ai-service-load-balancing)\n",
        "- [Summary](#summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"setup\"></a>\n",
        "## Set up the environment\n",
        "\n",
        "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
        "\n",
        "-  Create a <a href=\"https://cloud.ibm.com/catalog/services/watsonxai-runtime\" target=\"_blank\" rel=\"noopener no referrer\">watsonx.ai Runtime Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/wml-plans.html?context=wx&audience=wdp\" target=\"_blank\" rel=\"noopener no referrer\">here</a>)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Install dependencies\n",
        "**Note:** `ibm-watsonx-ai` documentation can be found <a href=\"https://ibm.github.io/watsonx-ai-python-sdk/index.html\" target=\"_blank\" rel=\"noopener no referrer\">here</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1A\u001b[2KSuccessfully installed anyio-4.9.0 certifi-2025.4.26 charset-normalizer-3.4.2 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 ibm-cos-sdk-2.14.1 ibm-cos-sdk-core-2.14.1 ibm-cos-sdk-s3transfer-2.14.1 ibm-watsonx-ai-1.3.25 idna-3.10 jmespath-1.0.1 lomond-0.3.3 numpy-2.2.6 pandas-2.2.3 pytz-2025.2 requests-2.32.2 sniffio-1.3.1 tabulate-0.9.0 typing_extensions-4.14.0 tzdata-2025.2 urllib3-2.4.0\n"
          ]
        }
      ],
      "source": [
        "%pip install -U \"ibm_watsonx_ai>=1.3.25\" | tail -n 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Define the watsonx.ai credentials\n",
        "Use the code cell below to define the watsonx.ai credentials that are required to work with watsonx Foundation Model inferencing.\n",
        "\n",
        "**Action:** Provide the IBM Cloud user API key. For details, see <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\" rel=\"noopener no referrer\">Managing user API keys</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "from ibm_watsonx_ai import Credentials\n",
        "\n",
        "credentials = Credentials(\n",
        "    url=\"https://ca-tor.ml.cloud.ibm.com\",\n",
        "    api_key=getpass.getpass(\"Enter your watsonx.ai api key and hit enter: \"),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Working with projects\n",
        "\n",
        "First of all, you need to create a project that will be used for your work. If you do not have project already created follow below steps.\n",
        "\n",
        "- Open IBM Cloud Pak main page\n",
        "- Click all projects\n",
        "- Create an empty project\n",
        "- Copy `project_id` from url and paste it below\n",
        "\n",
        "**Action**: Assign project ID below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    project_id = os.environ[\"PROJECT_ID\"]\n",
        "except KeyError:\n",
        "    project_id = input(\"Please enter your project_id (hit enter): \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Working with spaces\n",
        "\n",
        "You need to create a space that will be used for your work. If you do not have a space, you can use [Deployment Spaces Dashboard](https://dataplatform.cloud.ibm.com/ml-runtime/spaces?context=wx) to create one.\n",
        "\n",
        "- Click **New Deployment Space**\n",
        "- Create an empty space\n",
        "- Select Cloud Object Storage\n",
        "- Select watsonx.ai Runtime instance and press **Create**\n",
        "- Go to **Manage** tab\n",
        "- Copy `Space GUID` and paste it below\n",
        "\n",
        "**Tip**: You can also use SDK to prepare the space for your work. More information can be found [here](https://github.com/IBM/watson-machine-learning-samples/blob/master/cloud/notebooks/python_sdk/instance-management/Space%20management.ipynb).\n",
        "\n",
        "**Action**: assign space ID below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    space_id = os.environ[\"SPACE_ID\"]\n",
        "except KeyError:\n",
        "    space_id = input(\"Please enter your space_id (hit enter): \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create `APIClient` instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai import APIClient\n",
        "\n",
        "client = APIClient(credentials=credentials, project_id=project_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define IBM Cloud Secrets Manager URL\n",
        "In order to store secrets for different model providers, you need to use the IBM Cloud Secrets Manager."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "secrets_manager_url = \"PASTE_YOUR_IBM_CLOUD_SECRETS_MANAGER_URL_HERE\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"gateway-configuration\"></a>\n",
        "## Initialize and configure Model Gateway\n",
        "In this section we will initialize the Model Gateway and configure its providers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize the Model Gateway\n",
        "Create `Gateway` instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.gateway import Gateway\n",
        "\n",
        "gateway = Gateway(api_client=client)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set your IBM Cloud Secrets Manager instance\n",
        "\n",
        "**Note:** This instance will store your provider credentials. The same credentials will later be used inside the AI service."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': '73ff157e-f48e-5e19-8455-959edcb6109a',\n",
              " 'name': 'Watsonx AI Model Gateway configuration'}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gateway.set_secrets_manager(secrets_manager_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "List available providers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'object': 'list', 'data': []}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gateway.providers.get_details()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Work with watsonx.ai provider"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create provider"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'127b5d2b-8600-45c9-a14d-95b7dbb29946'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "watsonx_ai_provider_details = gateway.providers.create(\n",
        "    provider=\"watsonxai\",\n",
        "    name=\"watsonx-ai-provider\",\n",
        "    data={\n",
        "        \"apikey\": client.credentials.api_key,\n",
        "        \"auth_url\": client.service_instance._href_definitions.get_iam_token_url(),\n",
        "        \"base_url\": client.credentials.url,\n",
        "        \"project_id\": project_id,\n",
        "    },\n",
        ")\n",
        "\n",
        "watsonx_ai_provider_id = gateway.providers.get_id(watsonx_ai_provider_details)\n",
        "watsonx_ai_provider_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get provider details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gateway.providers.get_details(watsonx_ai_provider_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "List available models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MODEL_ID</th>\n",
              "      <th>TYPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>core42/jais-13b-chat</td>\n",
              "      <td>Core42:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>elyza/elyza-japanese-llama-2-7b-instruct</td>\n",
              "      <td>ELYZA:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>google/flan-t5-xl</td>\n",
              "      <td>Google:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>google/flan-t5-xxl</td>\n",
              "      <td>Google:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>google/flan-ul2</td>\n",
              "      <td>Google:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ibm/granite-13b-instruct-v2</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ibm/granite-20b-code-instruct</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ibm/granite-3-2-8b-instruct</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ibm/granite-3-2b-instruct</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ibm/granite-3-3-8b-instruct</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ibm/granite-3-8b-instruct</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ibm/granite-34b-code-instruct</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>ibm/granite-3b-code-instruct</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ibm/granite-8b-code-instruct</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>ibm/granite-8b-japanese</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>ibm/granite-embedding-107m-multilingual</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>ibm/granite-embedding-278m-multilingual</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>ibm/granite-guardian-3-2b</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>ibm/granite-guardian-3-8b</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>ibm/granite-speech-3-3-8b</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>ibm/granite-vision-3-2-2b</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>ibm/slate-125m-english-rtrvr</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>ibm/slate-125m-english-rtrvr-lm</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>ibm/slate-125m-english-rtrvr-v2</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>ibm/slate-30m-english-rtrvr</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>ibm/slate-30m-english-rtrvr-v2</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>intfloat/multilingual-e5-large</td>\n",
              "      <td>intfloat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>llava-hf/llava-next-video-7b-hf</td>\n",
              "      <td>Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>meta-llama/llama-2-13b-chat</td>\n",
              "      <td>Meta:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>meta-llama/llama-3-2-11b-vision-instruct</td>\n",
              "      <td>Meta:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>meta-llama/llama-3-2-1b-instruct</td>\n",
              "      <td>Meta:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>meta-llama/llama-3-2-3b-instruct</td>\n",
              "      <td>Meta:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>meta-llama/llama-3-2-90b-vision-instruct</td>\n",
              "      <td>Meta:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>meta-llama/llama-3-3-70b-instruct</td>\n",
              "      <td>Meta:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>meta-llama/llama-3-405b-instruct</td>\n",
              "      <td>Meta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>meta-llama/llama-4-maverick-17b-128e-instruct-fp8</td>\n",
              "      <td>Meta:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>meta-llama/llama-4-scout-17b-16e-instruct</td>\n",
              "      <td>Meta:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>meta-llama/llama-guard-3-11b-vision</td>\n",
              "      <td>Meta:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>mistralai/codestral-2501</td>\n",
              "      <td>Mistral AI:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>mistralai/mistral-large</td>\n",
              "      <td>Mistral AI:Mistral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>mistralai/mistral-medium-2505</td>\n",
              "      <td>Mistral AI:Mistral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>mistralai/mistral-small-24b-instruct-2501</td>\n",
              "      <td>Mistral AI:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>mistralai/mistral-small-3-1-24b-instruct-2503</td>\n",
              "      <td>Mistral AI:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>mistralai/mixtral-8x7b-instruct-v01</td>\n",
              "      <td>Mistral AI:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>mistralai/pixtral-12b</td>\n",
              "      <td>Mistral AI:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>redhatai/llama-3-2-90b-vision-instruct-fp8-dyn...</td>\n",
              "      <td>RedHatAI:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>sdaia/allam-1-13b-instruct</td>\n",
              "      <td>sdaia:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>sentence-transformers/all-minilm-l12-v2</td>\n",
              "      <td>sentence-transformers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>sentence-transformers/all-minilm-l12-v2-lm</td>\n",
              "      <td>sentence-transformers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>sentence-transformers/all-minilm-l6-v2</td>\n",
              "      <td>sentence-transformers</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             MODEL_ID                     TYPE\n",
              "0                                core42/jais-13b-chat      Core42:Hugging Face\n",
              "1            elyza/elyza-japanese-llama-2-7b-instruct       ELYZA:Hugging Face\n",
              "2                                   google/flan-t5-xl      Google:Hugging Face\n",
              "3                                  google/flan-t5-xxl      Google:Hugging Face\n",
              "4                                     google/flan-ul2      Google:Hugging Face\n",
              "5                         ibm/granite-13b-instruct-v2                      IBM\n",
              "6                       ibm/granite-20b-code-instruct                      IBM\n",
              "7                         ibm/granite-3-2-8b-instruct                      IBM\n",
              "8                           ibm/granite-3-2b-instruct                      IBM\n",
              "9                         ibm/granite-3-3-8b-instruct                      IBM\n",
              "10                          ibm/granite-3-8b-instruct                      IBM\n",
              "11                      ibm/granite-34b-code-instruct                      IBM\n",
              "12                       ibm/granite-3b-code-instruct                      IBM\n",
              "13                       ibm/granite-8b-code-instruct                      IBM\n",
              "14                            ibm/granite-8b-japanese                      IBM\n",
              "15            ibm/granite-embedding-107m-multilingual                      IBM\n",
              "16            ibm/granite-embedding-278m-multilingual                      IBM\n",
              "17                          ibm/granite-guardian-3-2b                      IBM\n",
              "18                          ibm/granite-guardian-3-8b                      IBM\n",
              "19                          ibm/granite-speech-3-3-8b                      IBM\n",
              "20                          ibm/granite-vision-3-2-2b                      IBM\n",
              "21                       ibm/slate-125m-english-rtrvr                      IBM\n",
              "22                    ibm/slate-125m-english-rtrvr-lm                      IBM\n",
              "23                    ibm/slate-125m-english-rtrvr-v2                      IBM\n",
              "24                        ibm/slate-30m-english-rtrvr                      IBM\n",
              "25                     ibm/slate-30m-english-rtrvr-v2                      IBM\n",
              "26                     intfloat/multilingual-e5-large                 intfloat\n",
              "27                    llava-hf/llava-next-video-7b-hf             Hugging Face\n",
              "28                        meta-llama/llama-2-13b-chat        Meta:Hugging Face\n",
              "29           meta-llama/llama-3-2-11b-vision-instruct        Meta:Hugging Face\n",
              "30                   meta-llama/llama-3-2-1b-instruct        Meta:Hugging Face\n",
              "31                   meta-llama/llama-3-2-3b-instruct        Meta:Hugging Face\n",
              "32           meta-llama/llama-3-2-90b-vision-instruct        Meta:Hugging Face\n",
              "33                  meta-llama/llama-3-3-70b-instruct        Meta:Hugging Face\n",
              "34                   meta-llama/llama-3-405b-instruct                     Meta\n",
              "35  meta-llama/llama-4-maverick-17b-128e-instruct-fp8        Meta:Hugging Face\n",
              "36          meta-llama/llama-4-scout-17b-16e-instruct        Meta:Hugging Face\n",
              "37                meta-llama/llama-guard-3-11b-vision        Meta:Hugging Face\n",
              "38                           mistralai/codestral-2501  Mistral AI:Hugging Face\n",
              "39                            mistralai/mistral-large       Mistral AI:Mistral\n",
              "40                      mistralai/mistral-medium-2505       Mistral AI:Mistral\n",
              "41          mistralai/mistral-small-24b-instruct-2501  Mistral AI:Hugging Face\n",
              "42      mistralai/mistral-small-3-1-24b-instruct-2503  Mistral AI:Hugging Face\n",
              "43                mistralai/mixtral-8x7b-instruct-v01  Mistral AI:Hugging Face\n",
              "44                              mistralai/pixtral-12b  Mistral AI:Hugging Face\n",
              "45  redhatai/llama-3-2-90b-vision-instruct-fp8-dyn...    RedHatAI:Hugging Face\n",
              "46                         sdaia/allam-1-13b-instruct       sdaia:Hugging Face\n",
              "47            sentence-transformers/all-minilm-l12-v2    sentence-transformers\n",
              "48         sentence-transformers/all-minilm-l12-v2-lm    sentence-transformers\n",
              "49             sentence-transformers/all-minilm-l6-v2    sentence-transformers"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gateway.providers.list_available_models(watsonx_ai_provider_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"create-model-ai-service\"></a>\n",
        "\n",
        "## Create model and deploy it as AI service\n",
        "In this section we will create a model using Model Gateway and deploy it as an AI service."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create model using Model Gateway\n",
        "In this sample we will use the `ibm/granite-3-3-8b-instruct` model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = \"ibm/granite-3-3-8b-instruct\"\n",
        "\n",
        "model_details = gateway.models.create(\n",
        "    provider_id=watsonx_ai_provider_id,\n",
        "    model=model,\n",
        ")\n",
        "\n",
        "model_id = gateway.models.get_id(model_details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>NAME</th>\n",
              "      <th>TYPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>127b5d2b-8600-45c9-a14d-95b7dbb29946</td>\n",
              "      <td>watsonx-ai-provider</td>\n",
              "      <td>watsonxai</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     ID                 NAME       TYPE\n",
              "0  127b5d2b-8600-45c9-a14d-95b7dbb29946  watsonx-ai-provider  watsonxai"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gateway.providers.list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create custom software specification containing the newest version of `ibm-watsonx-ai` SDK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Change client from project to space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsetting the project_id ...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'SUCCESS'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.set.default_space(space_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define `requirements.txt` file for package extension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "requirements_txt = \"ibm-watsonx-ai>=1.3.24\"\n",
        "\n",
        "with open(\"requirements.txt\", \"w\") as file:\n",
        "    file.write(requirements_txt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get the ID of base software specification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_software_specification_id = client.software_specifications.get_id_by_name(\n",
        "    \"runtime-24.1-py3.11\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Store the package extension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating package extensions\n",
            "SUCCESS\n"
          ]
        }
      ],
      "source": [
        "meta_props = {\n",
        "    client.package_extensions.ConfigurationMetaNames.NAME: \"Model Gateway extension\",\n",
        "    client.package_extensions.ConfigurationMetaNames.DESCRIPTION: \"Package extension with Model Gateway functionality enabled in ibm-watsonx-ai\",\n",
        "    client.package_extensions.ConfigurationMetaNames.TYPE: \"requirements_txt\",\n",
        "}\n",
        "\n",
        "package_extension_details = client.package_extensions.store(\n",
        "    meta_props, file_path=\"requirements.txt\"\n",
        ")\n",
        "package_extension_id = client.package_extensions.get_id(package_extension_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a new software specification with the created package extension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SUCCESS\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'SUCCESS'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "meta_props = {\n",
        "    client.software_specifications.ConfigurationMetaNames.NAME: \"Model Gateway software specification\",\n",
        "    client.software_specifications.ConfigurationMetaNames.DESCRIPTION: \"Software specification for Model Gateway\",\n",
        "    client.software_specifications.ConfigurationMetaNames.BASE_SOFTWARE_SPECIFICATION: {\n",
        "        \"guid\": base_software_specification_id\n",
        "    },\n",
        "}\n",
        "\n",
        "software_specification_details = client.software_specifications.store(meta_props)\n",
        "software_specification_id = client.software_specifications.get_id(\n",
        "    software_specification_details\n",
        ")\n",
        "\n",
        "client.software_specifications.add_package_extension(\n",
        "    software_specification_id, package_extension_id\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create AI service\n",
        "\n",
        "Prepare function which will be deployed using AI service."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def deployable_ai_service(context, url=credentials.url, model_id=model, **kwargs): # fmt: skip\n",
        "    from ibm_watsonx_ai import APIClient, Credentials\n",
        "    from ibm_watsonx_ai.gateway import Gateway\n",
        "\n",
        "    api_client = APIClient(\n",
        "        credentials=Credentials(url=url, token=context.generate_token()),\n",
        "        space_id=context.get_space_id(),\n",
        "    )\n",
        "\n",
        "    gateway = Gateway(api_client=api_client)\n",
        "\n",
        "    def generate(context) -> dict:\n",
        "        api_client.set_token(context.get_token())\n",
        "\n",
        "        payload = context.get_json()\n",
        "        prompt = payload[\"prompt\"]\n",
        "\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        response = gateway.chat.completions.create(model=model_id, messages=messages)\n",
        "\n",
        "        return {\"body\": response}\n",
        "\n",
        "    return generate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing AI service's function locally\n",
        "\n",
        "Create AI service function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.deployments import RuntimeContext\n",
        "\n",
        "context = RuntimeContext(api_client=client)\n",
        "local_function = deployable_ai_service(context=context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare request payload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "context.request_payload_json = {\"prompt\": \"What is a tram?\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Execute the function locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'body': {'id': 'chatcmpl-046814ed956b774ae1bdef23d6d72f99',\n",
              "  'object': 'chat.completion',\n",
              "  'created': 1749217806,\n",
              "  'model': 'ibm/granite-3-3-8b-instruct',\n",
              "  'choices': [{'index': 0,\n",
              "    'message': {'role': 'assistant',\n",
              "     'content': 'A tram, also known as a streetcar or trolley, is a rail vehicle operating on tracks along urban streets. Trams are typically smaller than conventional railway cars and occasionally called \"light rail vehicles.\" They are primarily used for transportation within cities and towns, providing service to both local and, increasingly, longer-distance routes. Tram systems are powered either by electricity from overhead lines or by batteries, with some also utilizing depot charging. They play a vital role in urban public transportation, offering alternatives to buses and subways by running on rails, which allows for higher passenger capacities and smoother, more comfortable rides. Trams are popular for their ability to integrate well with mixed-traffic environments and contribute to reducing road congestion and emissions.',\n",
              "     'refusal': '',\n",
              "     'tool_calls': None},\n",
              "    'finish_reason': 'stop',\n",
              "    'logprobs': None}],\n",
              "  'usage': {'prompt_tokens': 64,\n",
              "   'completion_tokens': 181,\n",
              "   'total_tokens': 245},\n",
              "  'service_tier': None,\n",
              "  'system_fingerprint': '',\n",
              "  'cached': False}}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resp = local_function(context)\n",
        "resp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deploy AI service"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Store AI service with previously created custom software specification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "meta_props = {\n",
        "    client.repository.AIServiceMetaNames.NAME: \"Model Gateway AI service with SDK\",\n",
        "    client.repository.AIServiceMetaNames.SOFTWARE_SPEC_ID: software_specification_id,\n",
        "}\n",
        "\n",
        "stored_ai_service_details = client.repository.store_ai_service(\n",
        "    deployable_ai_service, meta_props\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ff3aa9de-f49e-4dd6-b5c2-5b11303d75b4'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ai_service_id = client.repository.get_ai_service_id(stored_ai_service_details)\n",
        "ai_service_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create online deployment of AI service."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "######################################################################################\n",
            "\n",
            "Synchronous deployment creation for id: 'ff3aa9de-f49e-4dd6-b5c2-5b11303d75b4' started\n",
            "\n",
            "######################################################################################\n",
            "\n",
            "\n",
            "initializing\n",
            "Note: online_url and serving_urls are deprecated and will be removed in a future release. Use inference instead.\n",
            ".....\n",
            "ready\n",
            "\n",
            "\n",
            "-----------------------------------------------------------------------------------------------\n",
            "Successfully finished deployment creation, deployment_id='77a3021c-f0e9-4d4b-b3f9-cc50cce81ddd'\n",
            "-----------------------------------------------------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "meta_props = {\n",
        "    client.deployments.ConfigurationMetaNames.NAME: \"AI service with SDK\",\n",
        "    client.deployments.ConfigurationMetaNames.ONLINE: {},\n",
        "}\n",
        "\n",
        "deployment_details = client.deployments.create(ai_service_id, meta_props)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Obtain the `deployment_id` of the previously created deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "deployment_id = client.deployments.get_id(deployment_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Execute the AI service"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "question = \"Summarize core values of IBM\"\n",
        "\n",
        "deployments_results = client.deployments.run_ai_service(\n",
        "    deployment_id, {\"prompt\": question}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"cached\": false,\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"1. Innovation: IBM continuously strives to create, invent, and innovate, fostering a culture that encourages groundbreaking ideas and technologies.\\n\\n2. Trust & Transparency: IBM values honesty, integrity, and openness, building trust with clients, employees, and stakeholders.\\n\\n3. Diversity & Inclusion: IBM commits to embracing diverse perspectives, cultures, and ideas to drive creativity and innovation, ensuring an inclusive work environment.\\n\\n4. Client Focus: IBM prioritizes meeting client needs, delivering superior quality solutions, and establishing long-term relationships built on trust and value.\\n\\n5. Social Responsibility: IBM is dedicated to using its expertise and resources for the greater good, contributing positively to society and the environment.\\n\\n6. Collaboration: IBM values teamwork, cooperation, and knowledge-sharing, fostering partnerships and collaborations across industries and borders.\\n\\n7. Excellence: IBM is committed to delivering high-quality work, setting the highest standards in its processes, and continuously improving.\\n\\n8. Ethics & Compliance: IBM upholds ethical conduct and adheres to legal and regulatory requirements, ensuring responsible business practices.\",\n",
            "        \"refusal\": \"\",\n",
            "        \"role\": \"assistant\",\n",
            "        \"tool_calls\": null\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1749217870,\n",
            "  \"id\": \"chatcmpl-4c8ab2a2079a756b47cbd44e76879596\",\n",
            "  \"model\": \"ibm/granite-3-3-8b-instruct\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"service_tier\": null,\n",
            "  \"system_fingerprint\": \"\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 278,\n",
            "    \"prompt_tokens\": 65,\n",
            "    \"total_tokens\": 343\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "print(json.dumps(deployments_results, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"create-models-ai-service-load-balancing\"></a>\n",
        "\n",
        "## Create models and deploy them as an AI service with load balancing\n",
        "In this section we will create models with the same alias using Model Gateway and deploy them as an AI service in order to perform load balancing between them.\n",
        "\n",
        "**Note:** This sample notebook creates three providers using watsonx.ai. It's worth pointing out that Model Gateway can also load balance between other providers, such as AWS Bedrock or NVIDIA NIM, as well as between different datacenters. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create models using Model Gateway with the same alias on different providers\n",
        "In this sample we will use the `meta-llama/llama-4-maverick-17b-128e-instruct-fp8`, `meta-llama/llama-3-2-3b-instruct`, and `meta-llama/llama-3-3-70b-instruct` models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_alias = \"load-balancing-llama-models\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create provider for `meta-llama/llama-4-maverick-17b-128e-instruct-fp8` model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "llama_4_model = \"meta-llama/llama-4-maverick-17b-128e-instruct-fp8\"\n",
        "\n",
        "watsonx_ai_provider_1_details = gateway.providers.create(\n",
        "    provider=\"watsonxai\",\n",
        "    name=\"watsonx-ai-provider-1\",\n",
        "    data={\n",
        "        \"apikey\": client.credentials.api_key,\n",
        "        \"auth_url\": client.service_instance._href_definitions.get_iam_token_url(),\n",
        "        \"base_url\": client.credentials.url,\n",
        "        \"project_id\": project_id,\n",
        "    },\n",
        ")\n",
        "\n",
        "watsonx_ai_provider_1_id = gateway.providers.get_id(watsonx_ai_provider_1_details)\n",
        "\n",
        "llama_4_model_details = gateway.models.create(\n",
        "    provider_id=watsonx_ai_provider_1_id,\n",
        "    model=llama_4_model,\n",
        "    alias=model_alias,\n",
        ")\n",
        "\n",
        "llama_4_model_id = gateway.models.get_id(llama_4_model_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create provider for `meta-llama/llama-3-2-3b-instruct` model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "llama_3_2_model = \"meta-llama/llama-3-2-3b-instruct\"\n",
        "\n",
        "watsonx_ai_provider_2_details = gateway.providers.create(\n",
        "    provider=\"watsonxai\",\n",
        "    name=\"watsonx-ai-provider-2\",\n",
        "    data={\n",
        "        \"apikey\": client.credentials.api_key,\n",
        "        \"auth_url\": client.service_instance._href_definitions.get_iam_token_url(),\n",
        "        \"base_url\": client.credentials.url,\n",
        "        \"project_id\": project_id,\n",
        "    },\n",
        ")\n",
        "\n",
        "watsonx_ai_provider_2_id = gateway.providers.get_id(watsonx_ai_provider_2_details)\n",
        "\n",
        "llama_3_2_model_details = gateway.models.create(\n",
        "    provider_id=watsonx_ai_provider_2_id,\n",
        "    model=llama_3_2_model,\n",
        "    alias=model_alias,\n",
        ")\n",
        "\n",
        "llama_3_2_model_id = gateway.models.get_id(llama_3_2_model_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create provider for `meta-llama/llama-3-3-70b-instruct` model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "llama_3_3_model = \"meta-llama/llama-3-3-70b-instruct\"\n",
        "\n",
        "watsonx_ai_provider_3_details = gateway.providers.create(\n",
        "    provider=\"watsonxai\",\n",
        "    name=\"watsonx-ai-provider-3\",\n",
        "    data={\n",
        "        \"apikey\": client.credentials.api_key,\n",
        "        \"auth_url\": client.service_instance._href_definitions.get_iam_token_url(),\n",
        "        \"base_url\": client.credentials.url,\n",
        "        \"project_id\": project_id,\n",
        "    },\n",
        ")\n",
        "\n",
        "watsonx_ai_provider_3_id = gateway.providers.get_id(watsonx_ai_provider_3_details)\n",
        "\n",
        "llama_3_3_model_details = gateway.models.create(\n",
        "    provider_id=watsonx_ai_provider_3_id,\n",
        "    model=llama_3_3_model,\n",
        "    alias=model_alias,\n",
        ")\n",
        "\n",
        "llama_3_3_model_id = gateway.models.get_id(llama_3_3_model_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### List available providers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>NAME</th>\n",
              "      <th>TYPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>127b5d2b-8600-45c9-a14d-95b7dbb29946</td>\n",
              "      <td>watsonx-ai-provider</td>\n",
              "      <td>watsonxai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9c55610d-6762-4ab5-80b2-847e4b22d5fa</td>\n",
              "      <td>watsonx-ai-provider-1</td>\n",
              "      <td>watsonxai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fa403325-822d-4681-90fb-4ca323ce5ec6</td>\n",
              "      <td>watsonx-ai-provider-2</td>\n",
              "      <td>watsonxai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a96ca22d-0d28-4203-a206-48a2bb0730da</td>\n",
              "      <td>watsonx-ai-provider-3</td>\n",
              "      <td>watsonxai</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     ID                   NAME       TYPE\n",
              "0  127b5d2b-8600-45c9-a14d-95b7dbb29946    watsonx-ai-provider  watsonxai\n",
              "1  9c55610d-6762-4ab5-80b2-847e4b22d5fa  watsonx-ai-provider-1  watsonxai\n",
              "2  fa403325-822d-4681-90fb-4ca323ce5ec6  watsonx-ai-provider-2  watsonxai\n",
              "3  a96ca22d-0d28-4203-a206-48a2bb0730da  watsonx-ai-provider-3  watsonxai"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gateway.providers.list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create AI service\n",
        "\n",
        "Prepare function which will be deployed using AI service. Please specify the default parameters that will be passed to the function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def deployable_load_balancing_ai_service(context, url=credentials.url, model_alias=model_alias, **kwargs): # fmt: skip\n",
        "    from ibm_watsonx_ai import APIClient, Credentials\n",
        "    from ibm_watsonx_ai.gateway import Gateway\n",
        "\n",
        "    api_client = APIClient(\n",
        "        credentials=Credentials(url=url, token=context.generate_token()),\n",
        "        space_id=context.get_space_id(),\n",
        "    )\n",
        "\n",
        "    gateway = Gateway(api_client=api_client)\n",
        "\n",
        "    def generate(context) -> dict:\n",
        "        api_client.set_token(context.get_token())\n",
        "\n",
        "        payload = context.get_json()\n",
        "        prompt = payload[\"prompt\"]\n",
        "\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        response = gateway.chat.completions.create(model=model_alias, messages=messages)\n",
        "\n",
        "        return {\"body\": response}\n",
        "\n",
        "    return generate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing AI service's function locally\n",
        "\n",
        "Create AI service function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.deployments import RuntimeContext\n",
        "\n",
        "context = RuntimeContext(api_client=client)\n",
        "local_load_balancing_function = deployable_load_balancing_ai_service(context=context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare request payload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "context.request_payload_json = {\"prompt\": \"Explain what IBM is\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Execute the function locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'meta-llama/llama-4-maverick-17b-128e-instruct-fp8': 11,\n",
              "         'meta-llama/llama-3-2-3b-instruct': 10,\n",
              "         'meta-llama/llama-3-3-70b-instruct': 4})"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import asyncio\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "async def send_requests(function, context):\n",
        "    tasks: list[asyncio.Future] = []\n",
        "    for _ in range(25):\n",
        "        task = asyncio.to_thread(function, context)\n",
        "        tasks.append(task)\n",
        "        await asyncio.sleep(0.2)\n",
        "\n",
        "    return await asyncio.gather(*tasks)\n",
        "\n",
        "\n",
        "loop = asyncio.get_event_loop()\n",
        "responses = await loop.create_task(\n",
        "    send_requests(function=local_load_balancing_function, context=context)\n",
        ")\n",
        "\n",
        "Counter(map(lambda x: x[\"body\"][\"model\"], responses))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As demonstrated, out of 25 requests sent to Model Gateway:\n",
        "- 11 of them were handled by `meta-llama/llama-4-maverick-17b-128e-instruct-fp8`,\n",
        "- 10 of them were handled by `meta-llama/llama-3-2-3b-instruct`,\n",
        "- 4 of them were handled by `meta-llama/llama-3-3-70b-instruct`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deploy AI service"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Store AI service with previously created custom software specification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "meta_props = {\n",
        "    client.repository.AIServiceMetaNames.NAME: \"Model Gateway load balancing AI service with SDK\",\n",
        "    client.repository.AIServiceMetaNames.SOFTWARE_SPEC_ID: software_specification_id,\n",
        "}\n",
        "\n",
        "stored_ai_service_details = client.repository.store_ai_service(\n",
        "    deployable_load_balancing_ai_service, meta_props\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'b3cb6d0b-40d7-40b9-87f6-6c2311c23a99'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ai_service_id = client.repository.get_ai_service_id(stored_ai_service_details)\n",
        "ai_service_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create online deployment of AI service."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "######################################################################################\n",
            "\n",
            "Synchronous deployment creation for id: 'b3cb6d0b-40d7-40b9-87f6-6c2311c23a99' started\n",
            "\n",
            "######################################################################################\n",
            "\n",
            "\n",
            "initializing\n",
            "Note: online_url and serving_urls are deprecated and will be removed in a future release. Use inference instead.\n",
            ".....\n",
            "ready\n",
            "\n",
            "\n",
            "-----------------------------------------------------------------------------------------------\n",
            "Successfully finished deployment creation, deployment_id='45ed11c4-fda4-4a74-aac1-a4102db39946'\n",
            "-----------------------------------------------------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "meta_props = {\n",
        "    client.deployments.ConfigurationMetaNames.NAME: \"Load balancing AI service with SDK\",\n",
        "    client.deployments.ConfigurationMetaNames.ONLINE: {},\n",
        "}\n",
        "\n",
        "deployment_details = client.deployments.create(ai_service_id, meta_props)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Obtain the `deployment_id` of the previously created deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "deployment_id = client.deployments.get_id(deployment_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Execute the AI service\n",
        "In the following cell there are 25 requests send to the AI service in asynchronous mode. Between each request there is a 0.2 second delay in order to avoid `429 Too Many Requests` errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'meta-llama/llama-4-maverick-17b-128e-instruct-fp8': 13,\n",
              "         'meta-llama/llama-3-2-3b-instruct': 9,\n",
              "         'meta-llama/llama-3-3-70b-instruct': 3})"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "async def send_requests(question):\n",
        "    tasks: list[asyncio.Future] = []\n",
        "    for _ in range(25):\n",
        "        task = asyncio.to_thread(\n",
        "            client.deployments.run_ai_service, deployment_id, {\"prompt\": question}\n",
        "        )\n",
        "        tasks.append(task)\n",
        "        await asyncio.sleep(0.2)\n",
        "\n",
        "    return await asyncio.gather(*tasks)\n",
        "\n",
        "\n",
        "loop = asyncio.get_event_loop()\n",
        "responses = await loop.create_task(\n",
        "    send_requests(question=\"Explain to me what is a dog in cat language\")\n",
        ")\n",
        "\n",
        "Counter(map(lambda x: x[\"model\"], responses))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As demonstrated, out of 25 requests sent to AI Service:\n",
        "- 13 of them were handled by `meta-llama/llama-4-maverick-17b-128e-instruct-fp8`,\n",
        "- 9 of them were handled by `meta-llama/llama-3-2-3b-instruct`,\n",
        "- 3 of them were handled by `meta-llama/llama-3-3-70b-instruct`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"summary\"></a>\n",
        "## Summary and next steps\n",
        "\n",
        "You successfully completed this notebook!\n",
        "\n",
        "You learned how to create and deploy a load-balancing AI service with Model Gateway using `ibm_watsonx_ai` SDK.\n",
        "\n",
        "Check out our _<a href=\"https://ibm.github.io/watsonx-ai-python-sdk/samples.html\" target=\"_blank\" rel=\"noopener no referrer\">Online Documentation</a>_ for more samples, tutorials, documentation, how-tos, and blog posts. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Author\n",
        "\n",
        "**Rafał Chrzanowski**, Software Engineer Intern at watsonx.ai."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright © 2025 IBM. This notebook and its source code are released under the terms of the MIT License."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "watsonx-ai-samples-py-311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
