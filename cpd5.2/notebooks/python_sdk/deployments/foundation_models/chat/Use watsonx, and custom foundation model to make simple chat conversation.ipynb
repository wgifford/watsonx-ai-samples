{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "![image](https://raw.githubusercontent.com/IBM/watsonx-ai-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
        "# Use watsonx, and custom foundation model to make simple chat conversation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### Disclaimers\n",
        "\n",
        "- Use only Projects and Spaces that are available in watsonx context.\n",
        "- To enable chat support, the custom model content (`tokenizer_config.json`) must include a chat template.\n",
        "- Chat support is limited to the models that use software spec: `watsonx-cfm-caikit-1.1`.\n",
        "\n",
        "## Notebook content\n",
        "\n",
        "This notebook provides a detailed demonstration of the steps and code required to showcase chat support for custom foundation models.\n",
        "\n",
        "Some familiarity with Python is helpful. This notebook uses Python 3.12.\n",
        "\n",
        "\n",
        "## Learning goal\n",
        "\n",
        "The purpose of this notebook is to demonstrate how to chat with custom foundation models.\n",
        "\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "This notebook contains the following parts:\n",
        "\n",
        "- [Setup](#setup)\n",
        "- [Foundation Models on watsonx](#models)\n",
        "- [Work with chat messages](#chat)\n",
        "- [Summary](#summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"setup\"></a>\n",
        "## Set up the environment\n",
        "\n",
        "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
        "\n",
        "-  Contact with your Cloud Pak for Data administrator and ask them for your account credentials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "%pip install -U ibm-watsonx-ai | tail -n 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Define credentials\n",
        "\n",
        "Authenticate the watsonx.ai Runtime service on IBM Cloud Pak for Data. You need to provide the **admin's** `username` and the platform `url`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "username = \"PASTE YOUR USERNAME HERE\"\n",
        "url = \"PASTE THE PLATFORM URL HERE\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the **admin's** `api_key` to authenticate watsonx.ai Runtime services:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "from ibm_watsonx_ai import Credentials\n",
        "\n",
        "credentials = Credentials(\n",
        "    username=username,\n",
        "    api_key=getpass.getpass(\"Enter your watsonx.ai API key and hit enter: \"),\n",
        "    url=url,\n",
        "    instance_id=\"openshift\",\n",
        "    version=\"5.2\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively you can use the **admin's** `password`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "from ibm_watsonx_ai import Credentials\n",
        "\n",
        "if \"credentials\" not in locals() or not credentials.api_key:\n",
        "    credentials = Credentials(\n",
        "        username=username,\n",
        "        password=getpass.getpass(\"Enter your watsonx.ai password and hit enter: \"),\n",
        "        url=url,\n",
        "        instance_id=\"openshift\",\n",
        "        version=\"5.2\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Working with projects\n",
        "\n",
        "First of all, you need to create a project that will be used for your work. If you do not have project already created follow bellow steps.\n",
        "\n",
        "- Open IBM Cloud Pak main page\n",
        "- Click all projects\n",
        "- Create an empty project\n",
        "- Copy `project_id` from url and paste it below\n",
        "\n",
        "**Action**: Assign project ID below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    project_id = os.environ[\"PROJECT_ID\"]\n",
        "except KeyError:\n",
        "    project_id = input(\"Please enter your project_id (hit enter): \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create `APIClient` instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai import APIClient\n",
        "\n",
        "client = APIClient(credentials, project_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"models\"></a>\n",
        "## Set up the Custom Foundation Model on `watsonx.ai`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Store the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Specify software specification. Note that only `watsonx-cfm-caikit-1.1` is valid for Chat with BYOM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sw_spec_id = client.software_specifications.get_id_by_name(\"watsonx-cfm-caikit-1.1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Specify the `model_id` of the model you will use for the chat with tools. The model has to be available on your CPD instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_id = \"deepseek-r1-distill-llama-8b\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There is also a possibility to list available custom models with their specifications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.foundation_models_manager import FoundationModelsManager\n",
        "\n",
        "fm_manager = FoundationModelsManager(client)\n",
        "fm_manager.get_custom_model_specs()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Publish the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metadata = {\n",
        "    client.repository.ModelMetaNames.NAME: \"Custom Deepseek FM\",\n",
        "    client.repository.ModelMetaNames.SOFTWARE_SPEC_ID: sw_spec_id,\n",
        "    client.repository.ModelMetaNames.TYPE: client.repository.ModelAssetTypes.CUSTOM_FOUNDATION_MODEL_1_0,\n",
        "}\n",
        "\n",
        "model_details = client.repository.store_model(\n",
        "    model=model_id,\n",
        "    meta_props=metadata,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deploy the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Specify hardware specification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "hw_spec_id = client.hardware_specifications.get_id_by_name(\"WX-S\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get `stored_model_id` from `model_detais` and specify `deployment_metadata`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stored_model_id = client.repository.get_model_id(model_details)\n",
        "\n",
        "deployment_metadata = {\n",
        "    client.deployments.ConfigurationMetaNames.NAME: \"Deployment of custom model\",\n",
        "    client.deployments.ConfigurationMetaNames.HARDWARE_SPEC: {\"id\": hw_spec_id},\n",
        "    client.deployments.ConfigurationMetaNames.ONLINE: {},\n",
        "    client.deployments.ConfigurationMetaNames.SERVING_NAME: \"custom_fm\",\n",
        "    client.deployments.ConfigurationMetaNames.DESCRIPTION: \"Deploy of custom deepseek model\",\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "deployment_details = client.deployments.create(\n",
        "    artifact_id=stored_model_id,\n",
        "    meta_props=deployment_metadata,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get `deployment_id` from `deployment_details`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "deployment_id = client.deployments.get_id(deployment_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define the model parameters\n",
        "\n",
        "You might need to adjust model `parameters` depending on the model you use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| PARAMETER         | TYPE                                   | EXAMPLE VALUE                |\n",
            "+===================+========================================+==============================+\n",
            "| frequency_penalty | float, NoneType                        | 0.5                          |\n",
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| logprobs          | bool, NoneType                         | True                         |\n",
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| top_logprobs      | int, NoneType                          | 3                            |\n",
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| presence_penalty  | float, NoneType                        | 0.3                          |\n",
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| response_format   | dict, TextChatResponseFormat, NoneType | {'type': 'json_object'}      |\n",
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| temperature       | float, NoneType                        | 0.7                          |\n",
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| max_tokens        | int, NoneType                          | 100                          |\n",
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| time_limit        | int, NoneType                          | 600000                       |\n",
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| top_p             | float, NoneType                        | 0.9                          |\n",
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| n                 | int, NoneType                          | 1                            |\n",
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| logit_bias        | dict, NoneType                         | {'1003': -100, '1004': -100} |\n",
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| seed              | int, NoneType                          | 41                           |\n",
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| stop              | list, NoneType                         | ['this', 'the']              |\n",
            "+-------------------+----------------------------------------+------------------------------+\n"
          ]
        }
      ],
      "source": [
        "from ibm_watsonx_ai.foundation_models.schema import TextChatParameters\n",
        "\n",
        "TextChatParameters.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "params = TextChatParameters(temperature=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize the model\n",
        "\n",
        "Initialize the `ModelInference` class with the previously set parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.foundation_models import ModelInference\n",
        "\n",
        "model = ModelInference(deployment_id=deployment_id, api_client=client, params=params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"chat\"></a>\n",
        "## Work with chat messages "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Work with a simple chat message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"What is 1 + 1\"}]\n",
        "\n",
        "simple_chat_response = model.chat(messages=messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I need to find the sum of 1 and 1.\n",
            "\n",
            "First, I recognize that adding two numbers together involves combining their values.\n",
            "\n",
            "Since both numbers being added are 1, I can simply count two objects, each representing one of the numbers.\n",
            "\n",
            "By counting them, I determine that the total is 2.\n",
            "\n",
            "Therefore, 1 plus 1 equals 2.\n",
            "</think>\n",
            "\n",
            "Sure! Let's solve the problem step by step.\n",
            "\n",
            "**Problem:** What is \\(1 + 1\\)?\n",
            "\n",
            "**Solution:**\n",
            "\n",
            "To find the sum of 1 and 1, follow these simple steps:\n",
            "\n",
            "1. **Start with the first number:** 1.\n",
            "   \n",
            "2. **Add the second number to it:** \\(1 + 1\\).\n",
            "\n",
            "3. **Combine them:** When you add 1 and 1 together, you're essentially counting two items or quantities.\n",
            "\n",
            "4. **Calculate the result:** \\(1 + 1 = 2\\).\n",
            "\n",
            "Therefore, the final answer is \\(\\boxed{2}\\).\n"
          ]
        }
      ],
      "source": [
        "print(simple_chat_response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Work with a simple chat message using chat_stream"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"What IBM mainly does?\"}]\n",
        "\n",
        "simple_chat_stream_response = model.chat_stream(messages=messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Okay, so I'm trying to figure out what IBM mainly does. I've heard the name IBM before—it's one of those big tech companies, right? But I'm not exactly sure about the specifics. Let me think about what I know and try to piece it together.\n",
            "\n",
            "First off, IBM stands for International Business Machines. The name sounds old-fashioned, like from the 50s or 60s. I think they were big back in the days of mainframe computers. But now, in the age of personal computers and the internet, what do they do? I remember hearing that IBM made the first personal computer, the PC, which was a big deal in the 1980s. That must have been their entry into the consumer market.\n",
            "\n",
            "So, they make computers and related technology. But is that all? I believe they also deal with software. I think IBM has developed a lot of software, maybe even some operating systems. Wait, wasn't there something called DOS? I think IBM had a version of DOS which was used a lot in the early days of PCs. So, they not only sell hardware but also software that runs on it.\n",
            "\n",
            "Beyond computers, I think IBM is involved in other technologies. Maybe cloud computing? I've heard of IBM Cloud, which provides cloud services. That makes sense because every big tech company these days offers some form of cloud services. It's a way to provide computing power and storage over the internet, which is pretty essential for businesses nowadays.\n",
            "\n",
            "Artificial Intelligence also comes to mind. IBM is known for Watson, their AI system. Watson is famous for beating human Jeopardy champions, right? So they're involved in developing AI technologies that can process huge amounts of data and solve complex problems. That must be a significant part of their business, especially with the rise of AI in industry and healthcare.\n",
            "\n",
            "IBM seems to be a conglomerate, meaning they offer products and services across various sectors. I think they have IT services, so they might help other companies with their technology needs. They probably offer consulting services, helping businesses integrate technology into their operations. Security is another area—maybe they provide cybersecurity solutions as well.\n",
            "\n",
            "Research and development must be a big part of what IBM does. They probably invest a lot into creating new technologies, staying ahead of trends like blockchain, quantum computing, and more. This keeps them at the forefront of innovation, which is important for staying competitive.\n",
            "\n",
            "Thinking about their structure, IBM is a multinational company with a presence all over the world. They probably have divisions or subsidiaries focusing on different areas. For example, IBM Software might handle their software products, IBM Cloud for their cloud services, and so on. This diversification across different technologies allows them to cater to a wide range of clients.\n",
            "\n",
            "I'm also trying to recall if IBM has been involved in hardware beyond personal computers. They make mainframes, which are large computers used by businesses for heavy-duty tasks.Servers too—probably for hosting and data processing. And maybe storage solutions under the IBM Storage line.\n",
            "\n",
            "When I think about their impact, IBM has been a major player in the tech industry, shaping how businesses and even consumers interact with technology. Their influence extends beyond technology into various fields like finance, healthcare, and education. For example, payment systems like credit cards might have something to do with IBM, or maybe they've developed software used in healthcare systems.\n",
            "\n",
            "Looking into their business model, IBM likely uses a combination of selling hardware, software, and services, along with subscription models through IBM Cloud. This multi-pronged approach helps them generate a steady income across different segments. They probably work with a variety of clients, from small businesses to large enterprises, providing tailored solutions to meet specific needs.\n",
            "\n",
            "Wait, but I'm a bit fuzzy on some specifics. For instance, did IBM create the first PC? I think so, but I'm not 100% sure. And while they certainly have a presence in AI with Watson, I wonder how much they focus on AI compared to other areas like cloud services. Also, their role in IT services—do they provide end-to-end solutions for businesses, integrating everything from hardware to software to data analytics?\n",
            "\n",
            "Another thought: cybersecurity is a major concern for all big companies. So, IBM probably offers services to protect their clients' data, maybe through their own cybersecurity division. That makes sense as a big part of their offerings, especially with the increasing number of cyber threats.\n",
            "\n",
            "In summary, IBM seems to be a diversified tech company that produces a range of hardware products, including PCs and mainframes, develops various software for different platforms, offers cloud services, and provides IT solutions and consulting. They're involved in cutting-edge fields like AI and quantum computing, ensuring they remain at the leading edge of technology. Their global presence means they cater to a broad market, making them influential and a key player in the tech industry.\n",
            "\n",
            "I might be missing some details or mixing up some aspects, but overall, IBM's main activities revolve around providing technology solutions, innovating in AI, cloud, and other key areas, and supporting clients across"
          ]
        }
      ],
      "source": [
        "for chunk in simple_chat_stream_response:\n",
        "    if chunk[\"choices\"]:\n",
        "        print(chunk[\"choices\"][0][\"delta\"].get(\"content\", \"\"), end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Work with an advanced chat message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [{\"type\": \"text\", \"text\": \"Who won the world series in 2020?\"}],\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [{\"type\": \"text\", \"text\": \"Where was it played?\"}],\n",
        "    },\n",
        "]\n",
        "\n",
        "advanced_chat_response = model.chat(messages=messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alright, so the user just asked where the 2020 World Series was played. Let me break this down.\n",
            "\n",
            "First, in 2020, there was some uncertainty because of the ongoing COVID-19 pandemic. Major League Baseball had to make some tough decisions to keep the season going. They decided to have all the games played at one venue to minimize travel and reduce exposure risks.\n",
            "\n",
            "Now, the home field for the World Series is usually determined by the arrangement of the teams. Since the World Series is between two teams, often the series is alternately hosted by each team. But in 2020, they broke this tradition. They chose the Los Angeles Dodgers' home stadium, Dodger Stadium, as the only venue for all the games.\n",
            "\n",
            "So, the user might not be aware that the World Series wasn't held at different venues due to the pandemic. They might think it's standard to move around, but in this special case, it was all in LA.\n",
            "\n",
            "I should make sure to mention why it was held in LA specifically, highlighting the pandemic safety measures. Also, mentioning that it was the first time the World Series was held entirely at one venue might add some historical context that the user might find useful.\n",
            "\n",
            "Putting it all together, the response should clarify the location, explain the reasons behind it, and provide any relevant historical notes without overwhelming the user with too much information. Keep it clear and concise.\n",
            "</think>\n",
            "\n",
            "In 2020, the World Series was held entirely at **Dodger Stadium** in Los Angeles, California. Due to the COVID-19 pandemic, there were no away games for the World Series, and all games were played at the home of the Los Angeles Dodgers, ensuring minimal travel and reduced exposure risks for players and staff. This was the first time in World Series history that it was held at a single venue.\n"
          ]
        }
      ],
      "source": [
        "print(advanced_chat_response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"summary\"></a>\n",
        "## Summary and next steps\n",
        "\n",
        "You successfully completed this notebook!\n",
        "\n",
        "You learned how to chat with custom foundation models and watsonx.ai.\n",
        "\n",
        "Check out our _<a href=\"https://ibm.github.io/watsonx-ai-python-sdk/samples.html\" target=\"_blank\" rel=\"noopener no referrer\">Online Documentation</a>_ for more samples, tutorials, documentation, how-tos, and blog posts. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Author\n",
        "\n",
        "**Karol Zmorski**, Software Engineer at watsonx.ai."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright © 2025 IBM. This notebook and its source code are released under the terms of the MIT License."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "note_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
