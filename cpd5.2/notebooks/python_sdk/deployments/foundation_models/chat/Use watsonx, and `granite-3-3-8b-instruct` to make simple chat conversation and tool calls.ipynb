{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "![image](https://raw.githubusercontent.com/IBM/watsonx-ai-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
        "# Use watsonx, and `ibm/granite-3-3-8b-instruct` to make simple chat conversation and tool calls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### Disclaimers\n",
        "\n",
        "- Use only Projects and Spaces that are available in watsonx context.\n",
        "\n",
        "\n",
        "## Notebook content\n",
        "\n",
        "This notebook provides a detailed demonstration of the steps and code required to showcase support for Chat models, including the integration of tools and watsonx.ai models.\n",
        "\n",
        "Some familiarity with Python is helpful. This notebook uses Python 3.12.\n",
        "\n",
        "\n",
        "## Learning goal\n",
        "\n",
        "The purpose of this notebook is to demonstrate how to use Chat models, e.g. `ibm/granite-3-3-8b-instruct` for using tools.\n",
        "\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "This notebook contains the following parts:\n",
        "\n",
        "- [Setup](#setup)\n",
        "- [Foundation Models on watsonx](#models)\n",
        "- [Work with chat messages](#chat)\n",
        "- [Summary](#summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"setup\"></a>\n",
        "## Set up the environment\n",
        "\n",
        "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
        "\n",
        "-  Contact with your Cloud Pak for Data administrator and ask them for your account credentials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1A\u001b[2KSuccessfully installed PyYAML-6.0.2 annotated-types-0.7.0 anyio-4.9.0 certifi-2025.4.26 charset-normalizer-3.4.2 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 ibm-cos-sdk-2.14.1 ibm-cos-sdk-core-2.14.1 ibm-cos-sdk-s3transfer-2.14.1 ibm-watsonx-ai-1.3.23 idna-3.10 jmespath-1.0.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.63 langchain_ibm-0.3.11 langsmith-0.3.45 lomond-0.3.3 numpy-2.2.6 orjson-3.10.18 packaging-24.2 pandas-2.2.3 pydantic-2.11.5 pydantic-core-2.33.2 pytz-2025.2 requests-2.32.2 requests-toolbelt-1.0.0 sniffio-1.3.1 tabulate-0.9.0 tenacity-9.1.2 typing-extensions-4.14.0 typing-inspection-0.4.1 tzdata-2025.2 urllib3-2.4.0 zstandard-0.23.0\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /Users/rafalchrzanowski/.pyenv/versions/3.12.9/envs/watsonx-ai-samples-py-312/lib/python3.12/site-packages (from anyio->httpx<0.29,>=0.27->ibm_watsonx_ai) (4.14.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install -U \"langchain_ibm>=0.3,<0.4\" | tail -n 1\n",
        "%pip install -U ibm_watsonx_ai | tail -n 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Define credentials\n",
        "\n",
        "Authenticate the watsonx.ai Runtime service on IBM Cloud Pak for Data. You need to provide the **admin's** `username` and the platform `url`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "username = \"PASTE YOUR USERNAME HERE\"\n",
        "url = \"PASTE THE PLATFORM URL HERE\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the **admin's** `api_key` to authenticate watsonx.ai Runtime services:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "from ibm_watsonx_ai import Credentials\n",
        "\n",
        "credentials = Credentials(\n",
        "    username=username,\n",
        "    api_key=getpass.getpass(\"Enter your watsonx.ai API key and hit enter: \"),\n",
        "    url=url,\n",
        "    instance_id=\"openshift\",\n",
        "    version=\"5.2\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively you can use the **admin's** `password`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "from ibm_watsonx_ai import Credentials\n",
        "\n",
        "if \"credentials\" not in locals() or not credentials.api_key:\n",
        "    credentials = Credentials(\n",
        "        username=username,\n",
        "        password=getpass.getpass(\"Enter your watsonx.ai password and hit enter: \"),\n",
        "        url=url,\n",
        "        instance_id=\"openshift\",\n",
        "        version=\"5.2\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Working with projects\n",
        "\n",
        "First of all, you need to create a project that will be used for your work. If you do not have a project created already, follow the steps below:\n",
        "\n",
        "- Open IBM Cloud Pak main page\n",
        "- Click all projects\n",
        "- Create an empty project\n",
        "- Copy `project_id` from url and paste it below\n",
        "\n",
        "**Action**: Assign project ID below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    project_id = os.environ[\"PROJECT_ID\"]\n",
        "except KeyError:\n",
        "    project_id = input(\"Please enter your project_id (hit enter): \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create `APIClient` instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai import APIClient\n",
        "\n",
        "client = APIClient(credentials, project_id=project_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"models\"></a>\n",
        "## Set up the Foundation Model on `watsonx.ai`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Specify chat model\n",
        "\n",
        "This notebook uses chat model `ibm/granite-3-3-8b-instruct`, which has to be available on your Cloud Pak for Data environment for this notebook to run successfully.  \n",
        "If this model is not available on your Cloud Pak for Data environment, you can specify any other available chat model.  \n",
        "You can list available chat models by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ibm/granite-3-3-8b-instruct\n",
            "meta-llama/llama-3-3-70b-instruct\n",
            "mistralai/mistral-small-3-1-24b-instruct-2503\n"
          ]
        }
      ],
      "source": [
        "if len(client.foundation_models.ChatModels):\n",
        "    print(*client.foundation_models.ChatModels, sep=\"\\n\")\n",
        "else:\n",
        "    print(\n",
        "        \"Chat models are missing in this environment. Install chat models to proceed.\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_id = client.foundation_models.ChatModels.GRANITE_3_3_8B_INSTRUCT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define the model parameters\n",
        "\n",
        "You might need to adjust model `parameters` depending on the model you use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| PARAMETER         | TYPE                                   | EXAMPLE VALUE                |\n",
            "+===================+========================================+==============================+\n",
            "| frequency_penalty | float, NoneType                        | 0.5                          |\n",
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| logprobs          | bool, NoneType                         | True                         |\n",
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| top_logprobs      | int, NoneType                          | 3                            |\n",
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| presence_penalty  | float, NoneType                        | 0.3                          |\n",
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| response_format   | dict, TextChatResponseFormat, NoneType | {'type': 'json_object'}      |\n",
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| temperature       | float, NoneType                        | 0.7                          |\n",
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| max_tokens        | int, NoneType                          | 100                          |\n",
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| time_limit        | int, NoneType                          | 600000                       |\n",
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| top_p             | float, NoneType                        | 0.9                          |\n",
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| n                 | int, NoneType                          | 1                            |\n",
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| logit_bias        | dict, NoneType                         | {'1003': -100, '1004': -100} |\n",
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| seed              | int, NoneType                          | 41                           |\n",
            "+-------------------+----------------------------------------+------------------------------+\n",
            "| stop              | list, NoneType                         | ['this', 'the']              |\n",
            "+-------------------+----------------------------------------+------------------------------+\n"
          ]
        }
      ],
      "source": [
        "from ibm_watsonx_ai.foundation_models.schema import TextChatParameters\n",
        "\n",
        "TextChatParameters.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "params = TextChatParameters(temperature=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize the model\n",
        "\n",
        "Initialize the `ModelInference` class with the previously set parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.foundation_models import ModelInference\n",
        "\n",
        "model = ModelInference(\n",
        "    model_id=model_id, credentials=credentials, project_id=project_id, params=params\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"chat\"></a>\n",
        "## Work with chat messages "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Work with a simple chat message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"What is 1 + 1\"}]\n",
        "\n",
        "simple_chat_response = model.chat(messages=messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 + 1 equals 2.\n"
          ]
        }
      ],
      "source": [
        "print(simple_chat_response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Work with a simple chat message using chat_stream"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"What IBM mainly does?\"}]\n",
        "\n",
        "simple_chat_stream_response = model.chat_stream(messages=messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IBM integrates technology and expertise, providing business applications, infrastructure, and consulting services to clients globally. They emphasize areas like AI, cloud computing, hybrid computing, and data analytics. Notably, IBM was instrumental in developing the ORDL (Universal Automatic Computing Machine) and later contributed significantly to the personal computer revolution. \n",
            "\n",
            "Their product portfolio includes hardware (at one time, IBM was a leading PC manufacturer), software (like their Watson AI and Red Hat division), and infrastructure services. IBM also prioritizes research, operating 19 research facilities worldwide with focuses on vital fields such as semiconductors, nano-tech, quantum computing, blockchain, and the IoT (Internet of Things). \n",
            "\n",
            "In essence, IBM serves as both a technology innovator and a service provider, assisting businesses with their digital transformations while continuously pushing the frontiers of technological research."
          ]
        }
      ],
      "source": [
        "for chunk in simple_chat_stream_response:\n",
        "    if chunk[\"choices\"]:\n",
        "        print(chunk[\"choices\"][0][\"delta\"].get(\"content\", \"\"), end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Work with an advanced chat message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [{\"type\": \"text\", \"text\": \"Who won the world series in 2020?\"}],\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [{\"type\": \"text\", \"text\": \"Where was it played?\"}],\n",
        "    },\n",
        "]\n",
        "\n",
        "advanced_chat_response = model.chat(messages=messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 2020 World Series was played at the Globe Life Field in Arlington, Texas. This was the first time the World Series was held in a neutral site, with no home-field advantage for the participating teams.\n"
          ]
        }
      ],
      "source": [
        "print(advanced_chat_response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Work with chat messages using `tools` and `tool_choice`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_current_weather(location: str, unit: str = \"celsius\") -> dict:\n",
        "    \"\"\"\n",
        "    Get the current weather in a given location.\n",
        "\n",
        "    Parameters:\n",
        "    - location (str): The city and state, e.g., \"San Francisco, CA\".\n",
        "    - unit (str): The unit for temperature, either \"celsius\" or \"fahrenheit\". Defaults to \"celsius\".\n",
        "\n",
        "    Returns:\n",
        "    - dict: A dictionary containing the current weather details.\n",
        "    \"\"\"\n",
        "    weather_data = {\n",
        "        \"location\": location,\n",
        "        \"temperature\": 20,\n",
        "        \"unit\": unit,\n",
        "        \"description\": \"Partly cloudy\",\n",
        "    }\n",
        "    return weather_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Converting raw Python function to correct tool schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    {\n",
            "        \"type\": \"function\",\n",
            "        \"function\": {\n",
            "            \"name\": \"get_current_weather\",\n",
            "            \"description\": \"Get the current weather in a given location. Parameters:\\n- location (str): The city and state, e.g., \\\"San Francisco, CA\\\".\\n- unit (str): The unit for temperature, either \\\"celsius\\\" or \\\"fahrenheit\\\". Defaults to \\\"celsius\\\".\",\n",
            "            \"parameters\": {\n",
            "                \"properties\": {\n",
            "                    \"location\": {\n",
            "                        \"type\": \"string\"\n",
            "                    },\n",
            "                    \"unit\": {\n",
            "                        \"default\": \"celsius\",\n",
            "                        \"type\": \"string\"\n",
            "                    }\n",
            "                },\n",
            "                \"required\": [\n",
            "                    \"location\"\n",
            "                ],\n",
            "                \"type\": \"object\"\n",
            "            }\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from langchain_ibm.chat_models import convert_to_openai_tool\n",
        "\n",
        "formatted_tools = [convert_to_openai_tool(get_current_weather)]\n",
        "print(json.dumps(formatted_tools, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"What's the weather like in Boston today?\"},\n",
        "]\n",
        "\n",
        "tool_choice = {\"type\": \"function\", \"function\": {\"name\": \"get_current_weather\"}}\n",
        "\n",
        "tool_response = model.chat(\n",
        "    messages=messages, tools=formatted_tools, tool_choice=tool_choice\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"role\": \"assistant\",\n",
            "    \"content\": \"\",\n",
            "    \"tool_calls\": [\n",
            "        {\n",
            "            \"id\": \"chatcmpl-tool-bc023d18b56749c69c34e3e8967d2d68\",\n",
            "            \"type\": \"function\",\n",
            "            \"function\": {\n",
            "                \"name\": \"get_current_weather\",\n",
            "                \"arguments\": \"{\\n  \\\"location\\\": \\\"Boston, MA\\\",\\n  \\\"unit\\\": \\\"fahrenheit\\\"\\n}\"\n",
            "            }\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(json.dumps(tool_response[\"choices\"][0][\"message\"], indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Work with chat messages using `tools` and `tool_choice_option`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_numbers(a: float, b: float) -> float:\n",
        "    \"\"\"\n",
        "    Adds two numbers.\n",
        "\n",
        "    Parameters:\n",
        "    - a (float): The first number.\n",
        "    - b (float): The second number.\n",
        "\n",
        "    Returns:\n",
        "    - float: The result of a + b.\n",
        "    \"\"\"\n",
        "    return a + b\n",
        "\n",
        "\n",
        "def multiply_numbers(a: float, b: float) -> float:\n",
        "    \"\"\"\n",
        "    Multiplies two numbers.\n",
        "\n",
        "    Parameters:\n",
        "    - a (float): The first number.\n",
        "    - b (float): The second number.\n",
        "\n",
        "    Returns:\n",
        "    - float: The result of a * b.\n",
        "    \"\"\"\n",
        "    return a * b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Converting raw python function to correct tool schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    {\n",
            "        \"type\": \"function\",\n",
            "        \"function\": {\n",
            "            \"name\": \"add_numbers\",\n",
            "            \"description\": \"Adds two numbers. Parameters:\\n- a (float): The first number.\\n- b (float): The second number.\",\n",
            "            \"parameters\": {\n",
            "                \"properties\": {\n",
            "                    \"a\": {\n",
            "                        \"type\": \"number\"\n",
            "                    },\n",
            "                    \"b\": {\n",
            "                        \"type\": \"number\"\n",
            "                    }\n",
            "                },\n",
            "                \"required\": [\n",
            "                    \"a\",\n",
            "                    \"b\"\n",
            "                ],\n",
            "                \"type\": \"object\"\n",
            "            }\n",
            "        }\n",
            "    },\n",
            "    {\n",
            "        \"type\": \"function\",\n",
            "        \"function\": {\n",
            "            \"name\": \"multiply_numbers\",\n",
            "            \"description\": \"Multiplies two numbers. Parameters:\\n- a (float): The first number.\\n- b (float): The second number.\",\n",
            "            \"parameters\": {\n",
            "                \"properties\": {\n",
            "                    \"a\": {\n",
            "                        \"type\": \"number\"\n",
            "                    },\n",
            "                    \"b\": {\n",
            "                        \"type\": \"number\"\n",
            "                    }\n",
            "                },\n",
            "                \"required\": [\n",
            "                    \"a\",\n",
            "                    \"b\"\n",
            "                ],\n",
            "                \"type\": \"object\"\n",
            "            }\n",
            "        }\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "tool_choice_option = \"auto\"\n",
        "\n",
        "formatted_tools = [\n",
        "    convert_to_openai_tool(tool) for tool in [add_numbers, multiply_numbers]\n",
        "]\n",
        "\n",
        "print(json.dumps(formatted_tools, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"role\": \"assistant\",\n",
            "    \"tool_calls\": [\n",
            "        {\n",
            "            \"id\": \"chatcmpl-tool-aa024a892309416cad702b6d3bc750ad\",\n",
            "            \"type\": \"function\",\n",
            "            \"function\": {\n",
            "                \"name\": \"add_numbers\",\n",
            "                \"arguments\": \"{\\\"a\\\": 5, \\\"b\\\": 6}\"\n",
            "            }\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"What is 5 + 6?\"},\n",
        "]\n",
        "\n",
        "tools_response = model.chat(\n",
        "    messages=messages, tools=formatted_tools, tool_choice_option=tool_choice_option\n",
        ")\n",
        "\n",
        "print(json.dumps(tools_response[\"choices\"][0][\"message\"], indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"role\": \"assistant\",\n",
            "    \"tool_calls\": [\n",
            "        {\n",
            "            \"id\": \"chatcmpl-tool-2326e8dff55c4e80b0474756bc98767a\",\n",
            "            \"type\": \"function\",\n",
            "            \"function\": {\n",
            "                \"name\": \"multiply_numbers\",\n",
            "                \"arguments\": \"{\\\"a\\\": 5, \\\"b\\\": 6}\"\n",
            "            }\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"What is 5 * 6?\"},\n",
        "]\n",
        "\n",
        "tools_response_2 = model.chat(\n",
        "    messages=messages, tools=formatted_tools, tool_choice_option=tool_choice_option\n",
        ")\n",
        "\n",
        "print(json.dumps(tools_response_2[\"choices\"][0][\"message\"], indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Execute tool calls\n",
        "\n",
        "We organize the two functions into a dictionary where keys represent the function name, and values are the function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "names_to_functions = {\n",
        "    \"add_numbers\": add_numbers,\n",
        "    \"multiply_numbers\": multiply_numbers,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing function: `add_numbers`, with parameters: {'a': 5, 'b': 6}\n",
            "Function result: 11\n"
          ]
        }
      ],
      "source": [
        "tool_call = tools_response[\"choices\"][0][\"message\"][\"tool_calls\"]\n",
        "function_name = tool_call[0][\"function\"][\"name\"]\n",
        "function_params = json.loads(tool_call[0][\"function\"][\"arguments\"])\n",
        "print(f\"Executing function: `{function_name}`, with parameters: {function_params}\")\n",
        "\n",
        "function_result = names_to_functions[function_name](**function_params)\n",
        "print(f\"Function result: {function_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing function: `multiply_numbers`, with parameters: {'a': 5, 'b': 6}\n",
            "Function result: 30\n"
          ]
        }
      ],
      "source": [
        "tool_call = tools_response_2[\"choices\"][0][\"message\"][\"tool_calls\"]\n",
        "function_name = tool_call[0][\"function\"][\"name\"]\n",
        "function_params = json.loads(tool_call[0][\"function\"][\"arguments\"])\n",
        "print(f\"Executing function: `{function_name}`, with parameters: {function_params}\")\n",
        "\n",
        "\n",
        "function_result = names_to_functions[function_name](**function_params)\n",
        "print(f\"Function result: {function_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"summary\"></a>\n",
        "## Summary and next steps\n",
        "\n",
        "You successfully completed this notebook!\n",
        "\n",
        "You learned how to work with chat models using tools and watsonx.ai.\n",
        "\n",
        "Check out our _<a href=\"https://ibm.github.io/watsonx-ai-python-sdk/samples.html\" target=\"_blank\" rel=\"noopener no referrer\">Online Documentation</a>_ for more samples, tutorials, documentation, how-tos, and blog posts. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Author\n",
        "\n",
        "**Mateusz Szewczyk**, Software Engineer at watsonx.ai."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright Â© 2024-2025 IBM. This notebook and its source code are released under the terms of the MIT License."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "watsonx-ai-samples-py-312",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
