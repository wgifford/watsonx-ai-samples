{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![image](https://raw.githubusercontent.com/IBM/watsonx-ai-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
        "# Use watsonx, Elasticsearch, and LangChain to answer questions (RAG)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Disclaimers\n",
        "\n",
        "- Use only Projects and Spaces that are available in watsonx context.\n",
        "\n",
        "## Notebook content\n",
        "\n",
        "This notebook contains the steps and code to demonstrate support of Retrieval Augumented Generation in watsonx.ai. It introduces commands for data retrieval, knowledge base building & querying, and model testing.\n",
        "\n",
        "Some familiarity with Python is helpful. This notebook uses Python 3.12.\n",
        "\n",
        "#### About Retrieval Augmented Generation\n",
        "Retrieval Augmented Generation (RAG) is a versatile pattern that can unlock a number of use cases requiring factual recall of information, such as querying a knowledge base in natural language.\n",
        "\n",
        "In its simplest form, RAG requires 3 steps:\n",
        "\n",
        "- Index knowledge base passages (once)\n",
        "- Retrieve relevant passage(s) from knowledge base (for every user query)\n",
        "- Generate a response by feeding retrieved passage into a large language model (for every user query)\n",
        "\n",
        "## Contents\n",
        "\n",
        "This notebook contains the following parts:\n",
        "\n",
        "- [Setup](#setup)\n",
        "- [Data (test) loading](#data)\n",
        "- [Foundation Models on watsonx](#models)\n",
        "- [Basic information how to connect to Elasticsearch](#elastic_conn)\n",
        "- **[Set up ElasticsearchStore (Langchain)](#elasticsearchstore)**\n",
        "    - [Embed and index documents with Elasticsearch](#elasticsearchstore_index)\n",
        "    - [Generate a retrieval-augmented response to a question](#predict)\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"setup\"></a>\n",
        "## Set up the environment\n",
        "\n",
        "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
        "\n",
        "-  Contact with your Cloud Pak for Data administrator and ask them for your account credentials\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Install dependencies\n",
        "**Note:** `ibm-watsonx-ai` documentation can be found <a href=\"https://ibm.github.io/watsonx-ai-python-sdk/index.html\" target=\"_blank\" rel=\"noopener no referrer\">here</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1A\u001b[2KSuccessfully installed PyYAML-6.0.2 SQLAlchemy-2.0.41 annotated-types-0.7.0 anyio-4.9.0 certifi-2025.4.26 charset-normalizer-3.4.2 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.25 langchain-core-0.3.63 langchain-text-splitters-0.3.8 langsmith-0.3.43 orjson-3.10.18 packaging-24.2 pydantic-2.11.5 pydantic-core-2.33.2 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 typing-extensions-4.13.2 typing-inspection-0.4.1 urllib3-2.4.0 zstandard-0.23.0\n",
            "\u001b[1A\u001b[2KSuccessfully installed ibm-cos-sdk-2.14.1 ibm-cos-sdk-core-2.14.1 ibm-cos-sdk-s3transfer-2.14.1 ibm-watsonx-ai-1.3.23 jmespath-1.0.1 langchain_ibm-0.3.11 lomond-0.3.3 numpy-2.2.6 pandas-2.2.3 pytz-2025.2 requests-2.32.2 tabulate-0.9.0 tzdata-2025.2\n",
            "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.6 aiosignal-1.3.2 attrs-25.3.0 dataclasses-json-0.6.7 frozenlist-1.6.0 httpx-sse-0.4.0 langchain-community-0.3.24 marshmallow-3.26.1 multidict-6.4.4 mypy-extensions-1.1.0 propcache-0.3.1 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0 yarl-1.20.0\n",
            "\u001b[1A\u001b[2KSuccessfully installed elastic-transport-8.17.1 elasticsearch-8.18.1 langchain_elasticsearch-0.3.2 simsimd-6.4.7\n",
            "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 Pillow-11.2.1 filelock-3.18.0 fsspec-2025.5.1 hf-xet-1.1.2 huggingface-hub-0.32.3 jinja2-3.1.6 joblib-1.5.1 langchain-huggingface-0.2.0 mpmath-1.3.0 networkx-3.5 regex-2024.11.6 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.3 sentence-transformers-4.1.0 setuptools-80.9.0 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.21.1 torch-2.7.0 tqdm-4.67.1 transformers-4.52.4\n",
            "Successfully installed humanize-4.12.3\n",
            "\u001b[1A\u001b[2KSuccessfully installed ipywidgets-8.1.7 jupyterlab_widgets-3.0.15 widgetsnbextension-4.0.14\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ],
      "source": [
        "%pip install -U \"langchain>=0.3,<0.4\" | tail -n 1\n",
        "%pip install -U \"langchain_ibm>=0.3,<0.4\" | tail -n 1\n",
        "%pip install -U \"langchain-community>=0.3,<0.4\" | tail -n 1\n",
        "%pip install -U \"langchain_elasticsearch>=0.3,<0.4\" | tail -n 1\n",
        "%pip install -U \"langchain-huggingface>=0.2,<0.3\" | tail -n 1\n",
        "%pip install -U humanize | tail -n 1\n",
        "%pip install -U ipywidgets | tail -n 1\n",
        "%pip install -U wget | tail -n 1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Define credentials\n",
        "\n",
        "Authenticate the watsonx.ai Runtime service on IBM Cloud Pak for Data. You need to provide the **admin's** `username` and the platform `url`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "username = \"PASTE YOUR USERNAME HERE\"\n",
        "url = \"PASTE THE PLATFORM URL HERE\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the **admin's** `api_key` to authenticate watsonx.ai Runtime services:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "from ibm_watsonx_ai import Credentials\n",
        "\n",
        "credentials = Credentials(\n",
        "    username=username,\n",
        "    api_key=getpass.getpass(\"Enter your watsonx.ai API key and hit enter: \"),\n",
        "    url=url,\n",
        "    instance_id=\"openshift\",\n",
        "    version=\"5.2\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively you can use the **admin's** `password`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "from ibm_watsonx_ai import Credentials\n",
        "\n",
        "if \"credentials\" not in locals() or not credentials.api_key:\n",
        "    credentials = Credentials(\n",
        "        username=username,\n",
        "        password=getpass.getpass(\"Enter your watsonx.ai password and hit enter: \"),\n",
        "        url=url,\n",
        "        instance_id=\"openshift\",\n",
        "        version=\"5.2\",\n",
        "    )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Working with projects\n",
        "\n",
        "First of all, you need to create a project that will be used for your work. If you do not have project already created follow bellow steps.\n",
        "\n",
        "- Open IBM Cloud Pak main page\n",
        "- Click all projects\n",
        "- Create an empty project\n",
        "- Copy `project_id` from url and paste it below\n",
        "\n",
        "**Action**: Assign project ID below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    project_id = os.environ[\"PROJECT_ID\"]\n",
        "except KeyError:\n",
        "    project_id = input(\"Please enter your project_id (hit enter): \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create `APIClient` instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai import APIClient\n",
        "\n",
        "client = APIClient(credentials, project_id)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"data\"></a>\n",
        "## Data (test) loading"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download the test dataset. This dataset is used to calculate the metrics score for selected model, defined prompts and parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wget\n",
        "\n",
        "questions_test_filename = \"questions_test.csv\"\n",
        "questions_train_filename = \"questions_train.csv\"\n",
        "questions_test_url = \"https://raw.github.com/IBM/watsonx-ai-samples/master/cpd5.2/data/RAG/questions_test.csv\"\n",
        "questions_train_url = \"https://raw.github.com/IBM/watsonx-ai-samples/master/cpd5.2/data/RAG/questions_train.csv\"\n",
        "\n",
        "if not os.path.isfile(questions_test_filename):\n",
        "    wget.download(questions_test_url, out=questions_test_filename)\n",
        "\n",
        "if not os.path.isfile(questions_train_filename):\n",
        "    wget.download(questions_train_url, out=questions_train_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "filename_test = \"./questions_test.csv\"\n",
        "filename_train = \"./questions_train.csv\"\n",
        "\n",
        "test_data = pd.read_csv(filename_test)\n",
        "train_data = pd.read_csv(filename_train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inspect data sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question</th>\n",
              "      <th>answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1961</td>\n",
              "      <td>where does diffusion occur in the excretory sy...</td>\n",
              "      <td>diffusion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7528</td>\n",
              "      <td>when did the us join world war one</td>\n",
              "      <td>April 6 , 1917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8685</td>\n",
              "      <td>who played wilma in the movie the flintstones</td>\n",
              "      <td>Elizabeth Perkins</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6716</td>\n",
              "      <td>when was the office of the vice president created</td>\n",
              "      <td>1787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2916</td>\n",
              "      <td>where does carbon fixation occur in c4 plants</td>\n",
              "      <td>in the mesophyll cells</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    qid                                           question  \\\n",
              "0  1961  where does diffusion occur in the excretory sy...   \n",
              "1  7528                 when did the us join world war one   \n",
              "2  8685      who played wilma in the movie the flintstones   \n",
              "3  6716  when was the office of the vice president created   \n",
              "4  2916      where does carbon fixation occur in c4 plants   \n",
              "\n",
              "                  answers  \n",
              "0               diffusion  \n",
              "1          April 6 , 1917  \n",
              "2       Elizabeth Perkins  \n",
              "3                    1787  \n",
              "4  in the mesophyll cells  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build up knowledge base\n",
        "\n",
        "The current state-of-the-art in RAG is to create dense vector representations of the knowledge base in order to calculate the semantic similarity to a given user query.\n",
        "\n",
        "We can generate dense vector representations using embedding models. In this notebook, we use <a href=\"https://www.sbert.net/\" target=\"_blank\" rel=\"noopener no referrer\">Sentence Transformers</a> <a href=\"https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\" target=\"_blank\" rel=\"noopener no referrer\">all-MiniLM-L6-v2</a> to embed both the knowledge base passages and user queries. `all-MiniLM-L6-v2` is a performant open-source model that is small enough to run locally.\n",
        "\n",
        "A vector database is optimized for dense vector indexing and retrieval. This notebook uses <a href=\"https://python.langchain.com/docs/integrations/vectorstores/elasticsearch#basic-example\" target=\"_blank\" rel=\"noopener no referrer\">Elasticsearch</a>, a distributed, RESTful search and analytics engine, capable of performing both vector and lexical search. It is built on top of the Apache Lucene library, which offers good speed and performance with all-MiniLM-L6-v2 embedding model."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset we are using is already split into self-contained passages that can be ingested by Elasticsearch. \n",
        "\n",
        "The size of each passage is limited by the embedding model's context window (which is 256 tokens for `all-MiniLM-L6-v2`)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load knowledge base documents\n",
        "\n",
        "Load set of documents used further to build knowledge base. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "knowledge_base_dir = \"./knowledge_base\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_path = f\"{os.getcwd()}/knowledge_base\"\n",
        "if not os.path.isdir(my_path):\n",
        "    os.makedirs(my_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "documents_filename = \"knowledge_base/psgs.tsv\"\n",
        "documents_url = (\n",
        "    \"https://raw.github.com/IBM/watsonx-ai-samples/master/cpd5.2/data/RAG/psgs.tsv\"\n",
        ")\n",
        "\n",
        "if not os.path.isfile(documents_filename):\n",
        "    wget.download(documents_url, out=documents_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "documents = pd.read_csv(f\"{knowledge_base_dir}/psgs.tsv\", sep=\"\\t\", header=0)\n",
        "documents[\"indextext\"] = documents[\"title\"].astype(str) + \"\\n\" + documents[\"text\"]\n",
        "documents = documents[:1000]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create an embedding function\n",
        "\n",
        "Note that you can feed a custom embedding function to be used by Elasticsearch. The performance of Elasticsearch may differ depending on the embedding model used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "emb_func = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"models\"></a>\n",
        "## Foundation Models on watsonx"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Specify model\n",
        "\n",
        "This notebook uses text model `google/flan-ul2`, which has to be available on your Cloud Pak for Data environment for this notebook to run successfully.  \n",
        "You can list available text models by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "google/flan-ul2\n",
            "ibm/granite-guardian-3-2b\n"
          ]
        }
      ],
      "source": [
        "if len(client.foundation_models.TextModels):\n",
        "    print(*client.foundation_models.TextModels, sep=\"\\n\")\n",
        "else:\n",
        "    print(\n",
        "        \"Text models are missing in this environment. Install text models to proceed.\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_id = client.foundation_models.TextModels.FLAN_UL2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining the model parameters\n",
        "We need to provide a set of model parameters that will influence the result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
        "from ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods\n",
        "\n",
        "parameters = {\n",
        "    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
        "    GenParams.MIN_NEW_TOKENS: 1,\n",
        "    GenParams.MAX_NEW_TOKENS: 50,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize the `WatsonxLLM` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_ibm import WatsonxLLM\n",
        "\n",
        "if credentials.get(\"apikey\"):\n",
        "    watsonx_granite = WatsonxLLM(\n",
        "        model_id=model_id.value,\n",
        "        url=credentials.get(\"url\"),\n",
        "        username=credentials.get(\"username\"),\n",
        "        apikey=credentials.get(\"apikey\"),\n",
        "        instance_id=credentials.get(\"instance_id\"),\n",
        "        project_id=project_id,\n",
        "        params=parameters,\n",
        "    )\n",
        "else:\n",
        "    watsonx_granite = WatsonxLLM(\n",
        "        model_id=model_id.value,\n",
        "        url=credentials.get(\"url\"),\n",
        "        username=credentials.get(\"username\"),\n",
        "        password=credentials.get(\"password\"),\n",
        "        instance_id=credentials.get(\"instance_id\"),\n",
        "        project_id=project_id,\n",
        "        params=parameters,\n",
        "    )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"elastic_conn\"></a>\n",
        "## Set up connectivity information to Elasticsearch\n",
        "\n",
        "**This notebook focuses on self-managed cluster using <a href=\"https://cloud.ibm.com/docs/databases-for-elasticsearch?topic=databases-for-elasticsearch-getting-started\" target=\"_blank\" rel=\"noopener no referrer\">IBM Cloud® Databases for Elasticsearch.</a>**\n",
        "\n",
        "The following cell retrieves the Elasticsearch users, password, host and port from the environment if available and prompts you otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    esuser = os.environ[\"ESUSER\"]\n",
        "except KeyError:\n",
        "    esuser = input(\"Please enter your Elasticsearch user name (hit enter): \")\n",
        "\n",
        "try:\n",
        "    espassword = os.environ[\"ESPASSWORD\"]\n",
        "except KeyError:\n",
        "    espassword = getpass.getpass(\n",
        "        \"Please enter your Elasticsearch password (hit enter): \"\n",
        "    )\n",
        "\n",
        "try:\n",
        "    eshost = os.environ[\"ESHOST\"]\n",
        "except KeyError:\n",
        "    eshost = input(\"Please enter your Elasticsearch hostname (hit enter): \")\n",
        "\n",
        "try:\n",
        "    esport = os.environ[\"ESPORT\"]\n",
        "except KeyError:\n",
        "    esport = input(\"Please enter your Elasticsearch port number (hit enter): \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By default Elasticsearch will start with security features like authentication and TLS enabled. To connect to the Elasticsearch cluster you’ll need to configure the Python Elasticsearch client to use HTTPS with the generated CA certificate in order to make requests successfully. Details can be found <a href=\"https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/connecting.html#connect-self-managed-new\" target=\"_blank\" rel=\"noopener no referrer\">here</a>. In this notebook certificate fingerprints will be used for authentication. \n",
        "\n",
        "**Verifying HTTPS with certificate fingerprints (Python 3.10 or later)** If you don’t have access to the generated CA file from Elasticsearch you can use the following script to output the root CA fingerprint of the Elasticsearch instance with openssl s_client <a href=\"https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/connecting.html#_verifying_https_with_certificate_fingerprints_python_3_10_or_later\" target=\"_blank\" rel=\"noopener no referrer\"> (docs)</a>:\n",
        "\n",
        "\n",
        "The following cell retrieves the fingerprint information using a shell command and stores it in variable `ssl_assert_fingerprint`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'91:A6:EC:18:AC:0C:35:EB:F9:B9:B3:57:F8:9E:2D:4F:EE:3C:A4:F0:73:60:17:75:27:0C:38:94:11:51:91:33'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "es_ssl_fingerprint = !openssl s_client -connect $eshost:$esport  -showcerts </dev/null 2>/dev/null | openssl x509 -fingerprint -sha256 -noout -in /dev/stdin\n",
        "es_ssl_fingerprint = es_ssl_fingerprint[0].split(\"=\")[1]\n",
        "es_ssl_fingerprint"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"elasticsearchstore\"></a>\n",
        "## Set up ElasticsearchStore connector from Langchain\n",
        "\n",
        "\n",
        "We first create a regular Elasticsearch Python client connection. Then we pass it into LangChain's ElasticsearchStore wrapper together with the WatsonX model based embedding function.\n",
        "\n",
        "Consult the LangChain documentation For more information about <a href=\"https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.elasticsearch.ElasticsearchStore.html\" target=\"_blank\" rel=\"noopener no referrer\">ElasticsearchStore</a> connector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_elasticsearch import ElasticsearchStore\n",
        "from langchain_elasticsearch.client import create_elasticsearch_client\n",
        "\n",
        "es_connection = create_elasticsearch_client(\n",
        "    f\"https://{esuser}:{espassword}@{eshost}:{esport}\",\n",
        "    username=esuser,\n",
        "    password=espassword,\n",
        "    params={\"request_timeout\": None, \"ssl_assert_fingerprint\": es_ssl_fingerprint},\n",
        ")\n",
        "\n",
        "knowledge_base = ElasticsearchStore(\n",
        "    es_connection=es_connection,\n",
        "    index_name=\"test_index\",\n",
        "    embedding=emb_func,\n",
        "    strategy=ElasticsearchStore.ApproxRetrievalStrategy(),\n",
        "    distance_strategy=\"DOT_PRODUCT\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"elasticsearchstore_index\"></a>\n",
        "### Embed and index documents with Elasticsearch\n",
        "\n",
        "**Note: Could take several minutes if you don't have pre-built indices**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "if es_connection.indices.exists(index=\"test_index\"):\n",
        "    es_connection.indices.delete(index=\"test_index\")\n",
        "\n",
        "knowledge_base.add_texts(\n",
        "    texts=documents.indextext.tolist(),\n",
        "    metadatas=[\n",
        "        {\"title\": title, \"id\": doc_id}\n",
        "        for (title, doc_id) in zip(documents.title, documents.id)\n",
        "    ],  # filter on these!\n",
        "    index_name=\"test_index\",\n",
        "    ids=[str(i) for i in documents.id],  # unique for each doc\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's take a look in Elasticsearch what the LangChain wrapper has created. First we display the newly created index (\"tables\" in Elasticsearch are always called \"index\"). Note the field `vector` of type `dense_vector` with `dot_product` similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'test_index': {'aliases': {},\n",
              "  'mappings': {'properties': {'metadata': {'properties': {'id': {'type': 'long'},\n",
              "      'title': {'type': 'text',\n",
              "       'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}}},\n",
              "    'text': {'type': 'text',\n",
              "     'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}},\n",
              "    'vector': {'type': 'dense_vector',\n",
              "     'dims': 384,\n",
              "     'index': True,\n",
              "     'similarity': 'dot_product',\n",
              "     'index_options': {'type': 'int8_hnsw',\n",
              "      'm': 16,\n",
              "      'ef_construction': 100}}}},\n",
              "  'settings': {'index': {'routing': {'allocation': {'include': {'_tier_preference': 'data_content'}}},\n",
              "    'allocation': {'max_retries': '15'},\n",
              "    'number_of_shards': '1',\n",
              "    'provided_name': 'test_index',\n",
              "    'creation_date': '1748846908180',\n",
              "    'unassigned': {'node_left': {'delayed_timeout': '60m'}},\n",
              "    'number_of_replicas': '1',\n",
              "    'uuid': 'IsBoPDF0Ry2zoLF8BdPfFA',\n",
              "    'version': {'created': '8512000'}}}}}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dict(es_connection.indices.get(index=\"test_index\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verify the number of documents loaded into the Elasticsearch index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc_count = es_connection.count(index=\"test_index\")[\"count\"]\n",
        "doc_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's retrieve a random document as a sample. Note the embedding in the vector field, that was generated with the WatsonX embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "dict(es_connection.get(index=\"test_index\", id=random.randrange(len(documents))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display the total size and indexing time of the new index in Elasticsearch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index size:    9.8 MB\n",
            "Indexing time: 0 minutes\n"
          ]
        }
      ],
      "source": [
        "import humanize\n",
        "\n",
        "index_stats = (\n",
        "    es_connection.indices.stats(index=\"test_index\").get(\"_all\").get(\"primaries\")\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"Index size:   \",\n",
        "    humanize.naturalsize(index_stats.get(\"store\").get(\"size_in_bytes\")),\n",
        ")\n",
        "print(\n",
        "    \"Indexing time:\",\n",
        "    humanize.precisedelta(\n",
        "        index_stats.get(\"indexing\").get(\"index_time_in_millis\") / 1000,\n",
        "        minimum_unit=\"minutes\",\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"predict\"></a>\n",
        "## Generate a retrieval-augmented response to a question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`RetrievalQA` is a chain to do question answering.\n",
        "\n",
        "**Hint:** To use Chain interface from LangChain with watsonx.ai models you must call `model.to_langchain()` method. \n",
        "\n",
        "It returns `WatsonxLLM` wrapper compatible with LangChain CustomLLM specification."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Select questions\n",
        "\n",
        "The prompts we will use to test the RAG flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "questions_and_answers = {\n",
        "    \"names of founding fathers of the united states?\": \"Thomas Jefferson::James Madison::John Jay::George Washington::John Adams::Benjamin Franklin::Alexander Hamilton\",\n",
        "    \"who played in the super bowl in 2013?\": \"Baltimore Ravens::San Francisco 49ers\",\n",
        "    \"when did bucharest become the capital of romania?\": \"1862\",\n",
        "}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Retrieve relevant context\n",
        "\n",
        "Fetch paragraphs similar to the question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=watsonx_granite,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=knowledge_base.as_retriever(),\n",
        "    return_source_documents=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = [qa.invoke({\"query\": question}) for question in questions_and_answers.keys()]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get the set of chunks for one of the questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=========\n",
            "Question =  names of founding fathers of the united states?\n",
            "Answer =  John Adams , Benjamin Franklin , Alexander Hamilton , John Jay , Thomas Jefferson , James Madison , and George Washington\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Thomas Jefferson::James Madison::John Jay::George Washington::John Adams::Benjamin Franklin::Alexander Hamilton\n",
            "\n",
            "\n",
            "Source documents:\n",
            "Founding Fathers of the United States\n",
            "^ Burstein , Andrew . `` Politics and Personalities : Garry Wills takes a new look at a forgotten founder , slavery and the shaping of America '' , Chicago Tribune ( November 09 , 2003 ) : `` Forgotten founders such as Pickering and Morris made as many waves as those whose faces stare out from our currency . '' ^ Jump up to : Rafael , Ray . The Complete Idiot 's Guide to the Founding Fathers : And the Birth of Our Nation ( Penguin , 2011 ) . Jump up ^ `` Founding Fathers : Virginia '' . FindLaw Constitutional Law Center . 2008 . Retrieved 2008 - 11 - 14 . Jump up ^ Schwartz , Laurens R. Jews and the American Revolution : Haym Solomon and Others , Jefferson , North Carolina : McFarland & Co. , 1987 . Jump up ^ Kendall , Joshua . The Forgotten Founding Father : Noah Webster 's Obsession and the Creation of an American Culture ( Penguin 2011 ) . Jump up ^ Wright , R.E. ( 1996 ) . `` Thomas Willing ( 1731 - 1821 ) : Philadelphia Financier and Forgotten Founding Father '' . Pennsylvania History . 63 ( 4 ) : 525 -- 560 . doi : 10.2307 / 27773931 ( inactive 2017 - 01 - 15 ) . JSTOR 27773931 . Jump up ^ `` A Patriot of Early New England '' , New York Times ( December 20 , 1931 )\n",
            "Founding Fathers of the United States\n",
            "President of Congress Peyton Randolph New Hampshire John Sullivan Nathaniel Folsom Massachusetts Bay Thomas Cushing Samuel Adams John Adams Robert Treat Paine Rhode Island Stephen Hopkins Samuel Ward Connecticut Eliphalet Dyer Roger Sherman Silas Deane New York Isaac Low John Alsop John Jay James Duane Philip Livingston William Floyd Henry Wisner Simon Boerum New Jersey James Kinsey William Livingston Stephen Crane Richard Smith John De Hart Pennsylvania Joseph Galloway John Dickinson Charles Humphreys Thomas Mifflin Edward Biddle John Morton George Ross The Lower Counties Caesar Rodney Thomas McKean George Read Maryland Matthew Tilghman Thomas Johnson , Junr William Paca Samuel Chase Virginia Richard Henry Lee George Washington Patrick Henry , Junr Richard Bland Benjamin Harrison Edmund Pendleton North Carolina William Hooper Joseph Hewes Richard Caswell South Carolina Henry Middleton Thomas Lynch Christopher Gadsden John Rutledge Edward Rutledge See also Virginia Association First Continental Congress Carpenters ' Hall Declaration and Resolves of the First Continental Congress Retrieved from `` https://en.wikipedia.org/w/index.php?title=Founding_Fathers_of_the_United_States&oldid=815247535 '' Categories : Age of Enlightenment American Revolution Articles about multiple people Patriots in the American Revolution Political leaders of the American Revolution National founders Hidden categories : Webarchive template wayback links Pages with DOIs inactive since 2017 Use mdy dates from April 2011 Talk Read Contents About Wikipedia Wikiquote Bân - lâm - gú Башҡортса Bikol Central Български Brezhoneg Català Čeština Cymraeg Deutsch Ελληνικά Español Esperanto فارسی Français 한국어 Հայերեն हिन्दी Ido Bahasa Indonesia Interlingua Íslenska Italiano עברית Latina Lietuvių Magyar Bahasa Melayu Nederlands 日本 語 Norsk Polski Português Română\n",
            "Founding Fathers of the United States\n",
            "Founding Fathers of the United States - wikipedia Founding Fathers of the United States Jump to : navigation , search Declaration of Independence , a painting by John Trumbull depicting the Committee of Five presenting their draft to the Congress on June 28 , 1776 Signature page of Treaty of Paris ( 1783 ) ; the treaty was negotiated by John Adams , Benjamin Franklin and John Jay . The Founding Fathers of the United States were those individuals of the Thirteen Colonies in North America who led the American Revolution against the authority of the British Crown in word and deed and contributed to the establishment of the United States of America . Historian Richard B. Morris in 1973 identified the following seven figures as the key Founding Fathers : John Adams , Benjamin Franklin , Alexander Hamilton , John Jay , Thomas Jefferson , James Madison , and George Washington . Adams , Jefferson , and Franklin were members of the Committee of Five that drafted the Declaration of Independence . Hamilton , Madison , and Jay were authors of The Federalist Papers , advocating ratification of the Constitution . The constitutions drafted by Jay and Adams for their respective states of New York ( 1777 ) and Massachusetts ( 1780 ) were heavily relied upon when creating language for the US Constitution Jay , Adams and Franklin negotiated the Treaty of Paris ( 1783 ) that would end the American Revolutionary War . Washington was Commander -\n",
            "Founding Fathers of the United States\n",
            "Prior to , and during the 19th century , they were referred to as simply the `` Fathers '' . The term has been used to describe the founders and first settlers of the original royal colonies . Contents ( hide ) 1 Background 2 Interesting facts and commonalities 2.1 Education 2.1. 1 Colleges attended 2.1. 2 Advanced degrees and apprenticeships 2.1. 2.1 Doctors of medicine 2.1. 2.2 Theology 2.1. 2.3 Legal apprenticeships 2.1. 3 Self - taught or little formal education 2.2 Demographics 2.3 Political experience 2.4 Occupations and finances 2.5 Religion 2.6 Ownership of slaves and position on slavery 2.7 Attendance at conventions 2.8 Spouses and children 2.9 Charters of freedom and historical documents of the United States 2.10 Post-constitution life 2.11 Youth and longevity 2.12 Founders who were not signatories or delegates 3 Legacy 3.1 Institutions formed by Founders 3.2 Scholarship on the Founders 3.2. 1 Living historians whose focus is the Founding Fathers 3.2. 2 Noted collections of the Founding Fathers 3.3 In stage and film 3.4 Children 's books 4 See also 5 Notes 6 References 7 External links Background ( edit ) The Albany Congress of 1754 was a conference attended by seven colonies , which presaged later efforts at cooperation . The Stamp Act Congress of 1765 included representatives from nine colonies . The First Continental Congress met briefly in Philadelphia , Pennsylvania in 1774 , consisting of fifty - six delegates from twelve of the thirteen colonies ( excluding Georgia ) that\n",
            "\n",
            "\n",
            "=========\n",
            "Question =  who played in the super bowl in 2013?\n",
            "Answer =  Baltimore Ravens\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Baltimore Ravens::San Francisco 49ers\n",
            "\n",
            "\n",
            "Source documents:\n",
            "Super Bowl XLVII\n",
            "responded to the claim on Twitter in jest , tweeting `` There is no conspiracy . I pulled the plug . '' Box score ( edit ) Super Bowl XLVII : Baltimore Ravens 34 , San Francisco 49ers 31 Total Ravens ( AFC ) 7 14 7 6 34 49ers ( NFC ) 17 8 31 at Mercedes - Benz Superdome in New Orleans , Louisiana Date : February 3 , 2013 Game time : 5 : 31 p.m. CST Game weather : Played indoors ( dome stadium ) Game attendance : 71,024 Referee : Jerome Boger TV announcers ( CBS ) : Jim Nantz , Phil Simms , Steve Tasker , Solomon Wilcots Gamebook ( hide ) Scoring summary Quarter Time Drive Team Scoring information Score Plays Yards TOP BAL SF 10 : 36 6 51 2 : 29 BAL Anquan Boldin 13 - yard touchdown reception from Joe Flacco , Justin Tucker kick good 7 0 3 : 58 12 62 6 : 38 SF 36 - yard field goal by David Akers 7 7 : 10 10 75 4 : 43 BAL Dennis Pitta 1 - yard touchdown reception from Flacco , Tucker kick good 14 1 : 45 56 0 : 22 BAL Jacoby Jones 56 - yard touchdown reception from Flacco , Tucker kick good 21 0 : 00 8 71 1 : 45 SF 27 - yard field goal by Akers 21 6 14 : 49 -- -- -- BAL J. Jones 108 -\n",
            "Super Bowl XLVII\n",
            "for the 2012 season . The Ravens defeated the 49ers by the score of 34 -- 31 , handing the 49ers their first Super Bowl loss in franchise history . The game was played on February 3 , 2013 , at Mercedes - Benz Superdome in New Orleans , Louisiana . This was the tenth Super Bowl to be played in New Orleans , equaling Miami 's record of ten in an individual city . For the first time in Super Bowl history , the game featured two brothers coaching against each other -- Jim and John Harbaugh , head coaches of the San Francisco 49ers and Baltimore Ravens , respectively -- earning it the nickname Harbaugh Bowl . In addition , Super Bowl XLVII was the first to feature two teams that had undefeated records in previous Super Bowl games ( Baltimore , 1 -- 0 ; San Francisco , 5 -- 0 ) . The 49ers , who posted a regular - season record of 11 -- 4 -- 1 , entered the game seeking their sixth Super Bowl win in team history ( and first since Super Bowl XXIX at the end of the 1994 season ) , which would have tied the Pittsburgh Steelers for the most by a franchise . The Ravens , who posted a 10 -- 6 regular - season record , made their second Super Bowl appearance in 12 years , having previously won Super Bowl XXXV . Ray Lewis , the\n",
            "Super Bowl XLVII\n",
            "preview : A minute - by - minute breakdown '' . USA Today . Retrieved February 2 , 2013 . Jump up ^ `` Beyonce half time performance '' . NFL.Com . February 4 , 2013 . Retrieved February 5 , 2013 . Jump up ^ `` Beyonce wows at half - time show '' . BBC News . February 4 , 2013 . Retrieved February 5 , 2013 . Jump up ^ `` Beyonce Draws Estimated 104 Million to Super Bowl Halftime '' . ^ Jump up to : `` Play - by - Play '' . ESPN . February 3 , 2013 . Retrieved February 4 , 2013 . Jump up ^ Inman , Cam ( February 3 , 2013 ) . `` Super Bowl 2013 : San Francisco 49ers ' furious comeback falls short in 34 -- 31 loss to Baltimore Ravens -- San Jose Mercury News '' . San Jose Mercury News . Retrieved February 4 , 2013 . ^ Jump up to : `` Jacoby Jones returns kick 108 yards '' . ESPN.com . February 4 , 2013 . Retrieved April 24 , 2016 . Jump up ^ `` Watch Baltimore Ravens vs. Denver Broncos ( 01 / 12 / 2013 ) '' . NFL . Retrieved February 4 , 2013 . ^ Jump up to : Rosenthal , Gregg ( February 3 , 2013 ) . `` Jacoby Jones ' 108 - yard return TD a Super Bowl record '' . NFL . Retrieved\n",
            "Super Bowl XLVII\n",
            "MVP Award '' . Forbes.com . February 4 , 2013 . Retrieved February 6 , 2013 . Jump up ^ Heitner , Darren ( April 18 , 2013 ) . `` Is It Worth Spending $4 Million On A Super Bowl Commercial ? '' . Forbes . Retrieved February 4 , 2013 . Jump up ^ Collins , Scott ( February 5 , 2013 ) . `` Super Bowl ratings dip slightly from last year '' . Los Angeles Times . Retrieved February 5 , 2013 . ^ Jump up to : `` New Orleans to host 10th Super Bowl in 2013 '' . ESPN.com . Associated Press . May 19 , 2009 . Retrieved January 14 , 2011 . Jump up ^ Ally Burguieres Designs Official NFL Beads with Courtyard by Marriott for SuperBowl -- WGNO -- YouTube on YouTube Jump up ^ Wilner , Barry ( January 21 , 2013 ) . `` Ravens dominate Pats , set up ' Harbaugh Bowl ' '' . NBC Sports . Associated Press . Retrieved January 21 , 2013 . Jump up ^ Brinson , Will . `` Sorting the Sunday Pile , Divisional Round : Harbaugh Bowl still lives '' . CBSSports.com . CBS Interactive . Retrieved January 21 , 2013 . Jump up ^ Schwab , Frank . `` HarBowl ! Harbaugh brothers Jim and John to square off in Super Bowl '' . Yahoo ! Sports . Retrieved January 21 , 2003 . Jump up ^ `` The\n",
            "\n",
            "\n",
            "=========\n",
            "Question =  when did bucharest become the capital of romania?\n",
            "Answer =  1862\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  1862\n",
            "\n",
            "\n",
            "Source documents:\n",
            "Bucharest\n",
            "EU ) Density 9,237 / km ( 23,920 / sq mi ) Metro 2,412,530 Demonym ( s ) Bucharester ( en ) bucureștean , bucureșteancă ( ro ) Time zone UTC + 2 ( EET ) Summer ( DST ) UTC + 3 ( EEST ) Postal code 0xxxxx Area code ( s ) + 40 x1 Car plate prefix GDP ( Nominal ) € 47 billion - Per capita PPP € 40,400 -- Per capita € 20,000 Website pmb.ro Romanian law stipulates that Bucharest has a special administrative status which is equal to that of a County ; Bucharest metropolitan area is a proposed project . Bucharest ( / ˈb ( j ) uː kərɛst / ; Romanian : București ( bukuˈreʃtj ) ( listen ) ) is the capital and largest city of Romania , as well as its cultural , industrial , and financial centre . It is located in the southeast of the country , at 44 ° 25 ′ 57 '' N 26 ° 06 ′ 14 '' E ﻿ / ﻿ 44.43250 ° N 26.10389 ° E ﻿ / 44.43250 ; 26.10389 Coordinates : 44 ° 25 ′ 57 '' N 26 ° 06 ′ 14 '' E ﻿ / ﻿ 44.43250 ° N 26.10389 ° E ﻿ / 44.43250 ; 26.10389 , on the banks of the Dâmbovița River , less than 60 km ( 37.3 mi ) north of the Danube River and the Bulgarian border . Bucharest was first mentioned in\n",
            "Bucharest\n",
            "Bucharest - wikipedia Bucharest This article contains too many pictures , charts or diagrams for its overall length . Please help to improve this article by removing or adjusting the sandwiching of text between two images and indiscriminate galleries in accordance with the Manual of Style on use of images . ( Learn how and when to remove this template message ) Capital city in None , Romania Bucharest București Capital city From top , left to right : Central University Library Palace of the Parliament Arcul de Triumf Romanian Athenaeum Modernist skyscrapers CEC Palace Royal Palace of Bucharest Flag Coat of arms Nickname ( s ) : Micul Paris ( The Little Paris ) , Paris of the East Motto ( s ) : Patria și dreptul meu ( The Homeland and my right ) Bucharest Location of Bucharest in Romania Show map of Romania Bucharest Bucharest ( Europe ) Show map of Europe Coordinates : 44 ° 25 ′ 57 '' N 26 ° 6 ′ 14 '' E ﻿ / ﻿ 44.43250 ° N 26.10389 ° E ﻿ / 44.43250 ; 26.10389 Country Romania County None First attested 1459 Government Mayor Gabriela Firea ( PSD ) Prefect Speranţa Cliseru Area Capital city 228 km ( 88 sq mi ) Urban 285 km ( 110 sq mi ) Elevation 55.8 -- 91.5 m ( 183.1 -- 300.2 ft ) Population ( 2011 ) Capital city 1,883,425 Estimate ( 2016 ) 2,106,144 Rank 1st in Romania ( 6th in\n",
            "Bucharest\n",
            "destroying a third of the city . Ottoman massacre of Greek irregulars in Bucharest ( August , 1821 ) In 1862 , after Wallachia and Moldavia were united to form the Principality of Romania , Bucharest became the new nation 's capital city . In 1881 , it became the political centre of the newly proclaimed Kingdom of Romania under King Carol I. During the second half of the 19th century , the city 's population increased dramatically , and a new period of urban development began . During this period , gas lighting , horse - drawn trams , and limited electrification were introduced . The Dâmbovița River was also massively channelled in 1883 , thus putting a stop to previously endemic floods like the 1865 flooding of Bucharest . The Fortifications of Bucharest were built . The extravagant architecture and cosmopolitan high culture of this period won Bucharest the nickname of `` Little Paris '' ( Micul Paris ) of the east , with Calea Victoriei as its Champs - Élysées . I.C. Brătianu Boulevard in the 1930s Between 6 December 1916 and November 1918 , the city was occupied by German forces as a result of the Battle of Bucharest , with the official capital temporarily moved to Iași , in the Moldavia region . After World War I , Bucharest became the capital of Greater Romania . In the interwar years , Bucharest 's urban development continued , with the city gaining an average of 30,000\n",
            "Bucharest\n",
            "documents in 1459 . It became the capital of Romania in 1862 and is the centre of Romanian media , culture , and art . Its architecture is a mix of historical ( neo-classical ) , interbellum ( Bauhaus and art deco ) , communist - era and modern . In the period between the two World Wars , the city 's elegant architecture and the sophistication of its elite earned Bucharest the nickname of `` Little Paris '' ( Micul Paris ) . Although buildings and districts in the historic city centre were heavily damaged or destroyed by war , earthquakes , and above all Nicolae Ceaușescu 's program of systematization , many survived . In recent years , the city has been experiencing an economic and cultural boom . In 2016 , the historical city centre was listed as `` endangered '' by the World Monuments Watch . According to the 2011 census , 1,883,425 inhabitants live within the city limits , a decrease from the 2002 census . Adding the satellite towns around the urban area , the proposed metropolitan area of Bucharest would have a population of 2.27 million people . According to Eurostat , Bucharest has a functional urban area of 2,412,530 residents ( as of 2015 ) . Bucharest is the sixth - largest city in the European Union by population within city limits , after London , Berlin , Madrid , Rome , and Paris . Economically , Bucharest is the most prosperous\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for idx, result in enumerate(results):\n",
        "    print(\"=========\")\n",
        "    print(\"Question = \", result[\"query\"])\n",
        "    print(\"Answer = \", result[\"result\"])\n",
        "    print(\n",
        "        \"Expected Answer(s) (may not be appear with exact wording in the dataset) = \",\n",
        "        questions_and_answers[result[\"query\"]],\n",
        "    )\n",
        "    print(\"\\n\")\n",
        "    print(\"Source documents:\")\n",
        "    print(*(x.page_content for x in result[\"source_documents\"]), sep=\"\\n\")\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"summary\"></a>\n",
        "## Summary and next steps\n",
        "\n",
        "You successfully completed this notebook!\n",
        " \n",
        "Check out our _<a href=\"https://ibm.github.io/watsonx-ai-python-sdk/samples.html\" target=\"_blank\" rel=\"noopener no referrer\">Online Documentation</a>_ for more samples, tutorials, documentation, how-tos, and blog posts. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright © 2023-2025 IBM. This notebook and its source code are released under the terms of the MIT License."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "watsonx-ai-samples-py-312",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
