{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![image](https://raw.githubusercontent.com/IBM/watsonx-ai-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
        "# Use watsonx and Chroma to answer questions (RAG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### Disclaimers\n",
        "\n",
        "- Use only Projects and Spaces that are available in watsonx context.\n",
        "\n",
        "## Notebook content\n",
        "\n",
        "This notebook contains the steps and code to demonstrate support of Retrieval Augumented Generation in watsonx.ai. It introduces commands for data retrieval, knowledge base building & querying, and model testing.\n",
        "\n",
        "Some familiarity with Python is helpful. This notebook uses Python 3.12.\n",
        "\n",
        "#### About Retrieval Augmented Generation\n",
        "Retrieval Augmented Generation (RAG) is a versatile pattern that can unlock a number of use cases requiring factual recall of information, such as querying a knowledge base in natural language.\n",
        "\n",
        "In its simplest form, RAG requires 3 steps:\n",
        "\n",
        "- Index knowledge base passages (once)\n",
        "- Retrieve relevant passage(s) from knowledge base (for every user query)\n",
        "- Generate a response by feeding retrieved passage into a large language model (for every user query)\n",
        "\n",
        "## Contents\n",
        "\n",
        "This notebook contains the following parts:\n",
        "\n",
        "- [Setup](#setup)\n",
        "- [Data (test) loading](#data)\n",
        "- [Foundation Models on watsonx](#models)\n",
        "- [Generate a retrieval-augmented response to a question](#predict)\n",
        "- [Calculate rougeL metric](#score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"setup\"></a>\n",
        "## Set up the environment\n",
        "\n",
        "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
        "\n",
        "-  Contact with your Cloud Pak for Data administrator and ask them for your account credentials\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Install dependencies\n",
        "**Note:** `ibm-watsonx-ai` documentation can be found <a href=\"https://ibm.github.io/watsonx-ai-python-sdk/index.html\" target=\"_blank\" rel=\"noopener no referrer\">here</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1A\u001b[2KSuccessfully installed anyio-4.9.0 backoff-2.2.1 certifi-2025.4.26 charset-normalizer-3.4.2 chromadb-0.3.27 click-8.2.1 clickhouse-connect-0.8.17 coloredlogs-15.0.1 distro-1.9.0 duckdb-1.3.0 fastapi-0.85.1 filelock-3.18.0 flatbuffers-25.2.10 fsspec-2025.5.1 h11-0.16.0 hf-xet-1.1.2 hnswlib-0.8.0 httptools-0.6.4 huggingface-hub-0.32.3 humanfriendly-10.0 idna-3.10 lz4-4.4.4 mpmath-1.3.0 numpy-2.2.6 onnxruntime-1.22.0 overrides-7.7.0 pandas-2.2.3 posthog-4.2.0 protobuf-6.31.1 pulsar-client-3.7.0 pydantic-1.9.0 python-dotenv-1.1.0 pytz-2025.2 pyyaml-6.0.2 requests-2.32.3 sniffio-1.3.1 starlette-0.20.4 sympy-1.14.0 tokenizers-0.21.1 tqdm-4.67.1 typing-extensions-4.13.2 tzdata-2025.2 urllib3-2.4.0 uvicorn-0.34.2 uvloop-0.21.0 watchfiles-1.0.5 websockets-15.0.1 zstandard-0.23.0\n",
            "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 Pillow-11.2.1 jinja2-3.1.6 joblib-1.5.1 networkx-3.5 regex-2024.11.6 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.3 sentence_transformers-4.1.0 setuptools-80.9.0 threadpoolctl-3.6.0 torch-2.7.0 transformers-4.52.4\n",
            "Successfully installed wget-3.2\n",
            "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.4 aiosignal-1.3.2 attrs-25.3.0 datasets-3.6.0 dill-0.3.8 evaluate-0.4.3 frozenlist-1.6.0 fsspec-2025.3.0 multidict-6.4.4 multiprocess-0.70.16 propcache-0.3.1 pyarrow-20.0.0 xxhash-3.5.0 yarl-1.20.0\n",
            "\u001b[1A\u001b[2KSuccessfully installed ipywidgets-8.1.7 jupyterlab_widgets-3.0.15 widgetsnbextension-4.0.14\n",
            "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.0 nltk-3.9.1 rouge-score-0.1.2\n",
            "\u001b[1A\u001b[2KSuccessfully installed httpcore-1.0.9 httpx-0.28.1 ibm-cos-sdk-2.14.1 ibm-cos-sdk-core-2.14.1 ibm-cos-sdk-s3transfer-2.14.1 ibm-watsonx-ai-1.3.23 jmespath-1.0.1 lomond-0.3.3 requests-2.32.2 tabulate-0.9.0\n"
          ]
        }
      ],
      "source": [
        "%pip install -U \"chromadb==0.3.27\" | tail -n 1\n",
        "%pip install -U sentence_transformers | tail -n 1\n",
        "%pip install -U wget | tail -n 1\n",
        "%pip install -U evaluate | tail -n 1\n",
        "%pip install -U ipywidgets | tail -n 1\n",
        "%pip install -U rouge-score | tail -n 1\n",
        "%pip install -U ibm-watsonx-ai | tail -n 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "except ImportError:\n",
        "    raise ImportError(\n",
        "        \"Could not import sentence_transformers: Please install sentence-transformers package.\"\n",
        "    )\n",
        "\n",
        "try:\n",
        "    import chromadb\n",
        "    from chromadb.api.types import EmbeddingFunction\n",
        "except ImportError:\n",
        "    raise ImportError(\"Could not import chromadb: Please install chromadb package.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### Define credentials\n",
        "\n",
        "Authenticate the watsonx.ai Runtime service on IBM Cloud Pak for Data. You need to provide the **admin's** `username` and the platform `url`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "username = \"PASTE YOUR USERNAME HERE\"\n",
        "url = \"PASTE THE PLATFORM URL HERE\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the **admin's** `api_key` to authenticate watsonx.ai Runtime services:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "from ibm_watsonx_ai import Credentials\n",
        "\n",
        "credentials = Credentials(\n",
        "    username=username,\n",
        "    api_key=getpass.getpass(\"Enter your watsonx.ai API key and hit enter: \"),\n",
        "    url=url,\n",
        "    instance_id=\"openshift\",\n",
        "    version=\"5.2\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively you can use the **admin's** `password`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "from ibm_watsonx_ai import Credentials\n",
        "\n",
        "if \"credentials\" not in locals() or not credentials.api_key:\n",
        "    credentials = Credentials(\n",
        "        username=username,\n",
        "        password=getpass.getpass(\"Enter your watsonx.ai password and hit enter: \"),\n",
        "        url=url,\n",
        "        instance_id=\"openshift\",\n",
        "        version=\"5.2\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Working with projects\n",
        "\n",
        "First of all, you need to create a project that will be used for your work. If you do not have project already created follow bellow steps.\n",
        "\n",
        "- Open IBM Cloud Pak main page\n",
        "- Click all projects\n",
        "- Create an empty project\n",
        "- Copy `project_id` from url and paste it below\n",
        "\n",
        "**Action**: Assign project ID below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    project_id = os.environ[\"PROJECT_ID\"]\n",
        "except KeyError:\n",
        "    project_id = input(\"Please enter your project_id (hit enter): \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create `APIClient` instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai import APIClient\n",
        "\n",
        "client = APIClient(credentials, project_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"data\"></a>\n",
        "## Data (test) loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Download the test dataset. This dataset is used to calculate the metrics score for selected model, defined prompts and parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import wget\n",
        "\n",
        "questions_test_filename = \"questions_test.csv\"\n",
        "questions_train_filename = \"questions_train.csv\"\n",
        "questions_test_url = \"https://raw.github.com/IBM/watsonx-ai-samples/master/cpd5.2/data/RAG/questions_test.csv\"\n",
        "questions_train_url = \"https://raw.github.com/IBM/watsonx-ai-samples/master/cpd5.2/data/RAG/questions_train.csv\"\n",
        "\n",
        "if not os.path.isfile(questions_test_filename):\n",
        "    wget.download(questions_test_url, out=questions_test_filename)\n",
        "\n",
        "if not os.path.isfile(questions_train_filename):\n",
        "    wget.download(questions_train_url, out=questions_train_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "filename_test = \"./questions_test.csv\"\n",
        "filename_train = \"./questions_train.csv\"\n",
        "\n",
        "test_data = pd.read_csv(filename_test)\n",
        "train_data = pd.read_csv(filename_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Inspect data sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question</th>\n",
              "      <th>answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1961</td>\n",
              "      <td>where does diffusion occur in the excretory sy...</td>\n",
              "      <td>diffusion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7528</td>\n",
              "      <td>when did the us join world war one</td>\n",
              "      <td>April 6 , 1917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8685</td>\n",
              "      <td>who played wilma in the movie the flintstones</td>\n",
              "      <td>Elizabeth Perkins</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6716</td>\n",
              "      <td>when was the office of the vice president created</td>\n",
              "      <td>1787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2916</td>\n",
              "      <td>where does carbon fixation occur in c4 plants</td>\n",
              "      <td>in the mesophyll cells</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    qid                                           question  \\\n",
              "0  1961  where does diffusion occur in the excretory sy...   \n",
              "1  7528                 when did the us join world war one   \n",
              "2  8685      who played wilma in the movie the flintstones   \n",
              "3  6716  when was the office of the vice president created   \n",
              "4  2916      where does carbon fixation occur in c4 plants   \n",
              "\n",
              "                  answers  \n",
              "0               diffusion  \n",
              "1          April 6 , 1917  \n",
              "2       Elizabeth Perkins  \n",
              "3                    1787  \n",
              "4  in the mesophyll cells  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Build up knowledge base\n",
        "\n",
        "The current state-of-the-art in RAG is to create dense vector representations of the knowledge base in order to calculate the semantic similarity to a given user query.\n",
        "\n",
        "We can generate dense vector representations using embedding models. In this notebook, we use [SentenceTransformers](https://www.google.com/search?client=safari&rls=en&q=sentencetransformers&ie=UTF-8&oe=UTF-8) [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) to embed both the knowledge base passages and user queries. `all-MiniLM-L6-v2` is a performant open-source model that is small enough to run locally.\n",
        "\n",
        "A vector database is optimized for dense vector indexing and retrieval. This notebook uses [Chroma](https://docs.trychroma.com), a user-friendly open-source vector database, licensed under Apache 2.0, which offers good speed and performance with all-MiniLM-L6-v2 embedding model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "The dataset we are using is already split into self-contained passages that can be ingested by Chroma. \n",
        "\n",
        "The size of each passage is limited by the embedding model's context window (which is 256 tokens for `all-MiniLM-L6-v2`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Load knowledge base documents\n",
        "\n",
        "Load set of documents used further to build knowledge base. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "knowledge_base_dir = \"./knowledge_base\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "my_path = f\"{os.getcwd()}/knowledge_base\"\n",
        "if not os.path.isdir(my_path):\n",
        "    os.makedirs(my_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "documents_filename = \"knowledge_base/psgs.tsv\"\n",
        "documents_url = (\n",
        "    \"https://raw.github.com/IBM/watsonx-ai-samples/master/cpd5.2/data/RAG/psgs.tsv\"\n",
        ")\n",
        "\n",
        "if not os.path.isfile(documents_filename):\n",
        "    wget.download(documents_url, out=documents_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "documents = pd.read_csv(f\"{knowledge_base_dir}/psgs.tsv\", sep=\"\\t\", header=0)\n",
        "documents[\"indextext\"] = documents[\"title\"].astype(str) + \"\\n\" + documents[\"text\"]\n",
        "documents = documents[:517]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Create an embedding function\n",
        "\n",
        "Note that you can feed a custom embedding function to be used by chromadb. The performance of chromadb may differ depending on the embedding model used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "class MiniLML6V2EmbeddingFunction(EmbeddingFunction):\n",
        "    MODEL = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "    def __call__(self, texts):\n",
        "        return MiniLML6V2EmbeddingFunction.MODEL.encode(texts).tolist()\n",
        "\n",
        "\n",
        "emb_func = MiniLML6V2EmbeddingFunction()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Set up Chroma upsert\n",
        "\n",
        "Upserting a document means update the document even if it exists in the database. Otherwise re-inserting a document throws an error. This is useful for experimentation purpose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from typing import Optional, Iterable\n",
        "\n",
        "\n",
        "class ChromaWithUpsert:\n",
        "    def __init__(\n",
        "        self,\n",
        "        name: Optional[str] = \"watsonx_rag_collection\",\n",
        "        persist_directory: Optional[str] = None,\n",
        "        embedding_function: Optional[EmbeddingFunction] = None,\n",
        "        collection_metadata: Optional[dict] = None,\n",
        "    ):\n",
        "        self._client_settings = chromadb.config.Settings()\n",
        "        if persist_directory is not None:\n",
        "            self._client_settings = chromadb.config.Settings(\n",
        "                chroma_db_impl=\"duckdb+parquet\",\n",
        "                persist_directory=persist_directory,\n",
        "            )\n",
        "        self._client = chromadb.Client(self._client_settings)\n",
        "        self._embedding_function = embedding_function\n",
        "        self._persist_directory = persist_directory\n",
        "        self._name = name\n",
        "        self._collection = self._client.get_or_create_collection(\n",
        "            name=self._name,\n",
        "            embedding_function=(\n",
        "                self._embedding_function\n",
        "                if self._embedding_function is not None\n",
        "                else None\n",
        "            ),\n",
        "            metadata=collection_metadata,\n",
        "        )\n",
        "\n",
        "    def upsert_texts(\n",
        "        self,\n",
        "        texts: Iterable[str],\n",
        "        metadata: Optional[list[dict]] = None,\n",
        "        ids: Optional[list[str]] = None,\n",
        "        **kwargs,\n",
        "    ) -> list[str]:\n",
        "        \"\"\"Run more texts through the embeddings and add to the vectorstore.\n",
        "        Args:\n",
        "            :param texts (Iterable[str]): Texts to add to the vectorstore.\n",
        "            :param metadatas (Optional[list[dict]], optional): Optional list of metadatas.\n",
        "            :param ids (Optional[list[str]], optional): Optional list of IDs.\n",
        "            :param metadata: Optional[list[dict]] - optional metadata (such as title, etc.)\n",
        "        Returns:\n",
        "            list[str]: List of IDs of the added texts.\n",
        "        \"\"\"\n",
        "        if ids is None:\n",
        "            import uuid\n",
        "\n",
        "            ids = [str(uuid.uuid1()) for _ in texts]\n",
        "        self._collection.upsert(metadatas=metadata, documents=texts, ids=ids)\n",
        "        return ids\n",
        "\n",
        "    def is_empty(self):\n",
        "        return self._collection.count() == 0\n",
        "\n",
        "    def persist(self):\n",
        "        self._client.persist()\n",
        "\n",
        "    def query(self, query_texts: str, n_results: int = 5):\n",
        "        \"\"\"\n",
        "        Returns the closests vector to the question vector\n",
        "        :param query_texts: the question\n",
        "        :param n_results: number of results to generate\n",
        "        :return: the closest result to the given question\n",
        "        \"\"\"\n",
        "        return self._collection.query(query_texts=query_texts, n_results=n_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Embed and index documents with Chroma\n",
        "\n",
        "**Note: Could take several minutes if you don't have pre-built indices**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 155 ms, sys: 49.5 ms, total: 204 ms\n",
            "Wall time: 863 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "chroma = ChromaWithUpsert(\n",
        "    name=f\"nq910_minilm6v2\",\n",
        "    embedding_function=emb_func,  # you can have something here using /embed endpoint\n",
        "    persist_directory=knowledge_base_dir,\n",
        ")\n",
        "\n",
        "if chroma.is_empty():\n",
        "    _ = chroma.upsert_texts(\n",
        "        texts=documents.indextext.tolist(),\n",
        "        # we handle tokenization, embedding, and indexing automatically. You can skip that and add your own embeddings as well\n",
        "        metadata=[\n",
        "            {'title': title, 'id': id}\n",
        "            for title, id in zip(documents.title, documents.id)\n",
        "        ],  # filter on these!\n",
        "        ids=[str(i) for i in documents.id],  # unique for each doc\n",
        "    )\n",
        "    chroma.persist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"models\"></a>\n",
        "## Foundation Models on watsonx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### Specify model\n",
        "\n",
        "This notebook uses text model `google/flan-ul2`, which has to be available on your Cloud Pak for Data environment for this notebook to run successfully.  \n",
        "You can list available text models by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "google/flan-ul2\n",
            "ibm/granite-guardian-3-2b\n"
          ]
        }
      ],
      "source": [
        "if len(client.foundation_models.TextModels):\n",
        "    print(*client.foundation_models.TextModels, sep=\"\\n\")\n",
        "else:\n",
        "    print(\n",
        "        \"Text models are missing in this environment. Install text models to proceed.\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "model_id = client.foundation_models.TextModels.FLAN_UL2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Defining the model parameters\n",
        "We need to provide a set of model parameters that will influence the result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
        "from ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods\n",
        "\n",
        "parameters = {\n",
        "    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
        "    GenParams.MIN_NEW_TOKENS: 1,\n",
        "    GenParams.MAX_NEW_TOKENS: 50,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Initialize the `ModelInference` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.foundation_models import ModelInference\n",
        "\n",
        "model = ModelInference(\n",
        "    model_id=model_id, params=parameters, credentials=credentials, project_id=project_id\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"predict\"></a>\n",
        "## Generate a retrieval-augmented response to a question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Select questions\n",
        "\n",
        "Get questions from the previously loaded test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "when do abby and luka get back together?\n",
            "what does dc stand for in washigton dc?\n",
            "where was agatha christie s crooked house filmed?\n",
            "where did the song god bless america originate?\n",
            "when does daylight savings time end in colorado?\n",
            "who did the steelers play in the playoffs last year?\n",
            "most road maps are what kind of map?\n",
            "who plays captian hook in once upon a time?\n",
            "when is the last time mayon volcano erupted?\n",
            "who does finn wolf hard play in stranger things?\n",
            "who plays scott granger on young and restless?\n",
            "who did the original power rangers theme song?\n",
            "who is going to be in the world cup final?\n",
            "who does the voice of brian on family guy?\n",
            "who holds the 3 point record in nba?\n",
            "when did the food stamp card come out?\n",
            "who is the goddess of the moon in greek mythology?\n",
            "who won the 2015 great british baking show?\n",
            "which team has the most ncaa tournament appearances?\n",
            "who is the original singer of where is the love?\n",
            "what is the seatbelt compliancy rate in texas?\n",
            "when did fresh prince of bel air start?\n",
            "what is the record for wins in major league baseball?\n",
            "who sings lead on please let me wonder?\n",
            "who was the first person to be legally executed using an electric chair?\n",
            "who founded missions on the west coast of america?\n",
            "when did how to train a dragon come out?\n",
            "in 2011 what was the dominant source of energy in the world?\n",
            "crossword clue 19th century novelist who created barsetshire?\n",
            "n. the social class between the lower and upper classes?\n",
            "where do calluses on your feet come from?\n",
            "who is though she be but little she is fierce about?\n",
            "who played the title character he-man in the 1987 live action movie masters of the universe?\n",
            "what is the most densely populated state in the country?\n",
            "how much did chelsea sell de bruyne to wolfsburg?\n",
            "what cover-up is the movie the post about?\n",
            "who was the lead actor in movie toile ek prem katha?\n",
            "aurangzeb road in the heart of new delhi was re named after which personality?\n",
            "who played hercules wife in the 2014 movie?\n",
            "names of founding fathers of the united states?\n"
          ]
        }
      ],
      "source": [
        "question_texts = [q.strip(\"?\") + \"?\" for q in test_data[\"question\"].tolist()]\n",
        "print(\"\\n\".join(question_texts))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Retrieve relevant context\n",
        "\n",
        "Fetch paragraphs similar to the question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "relevant_contexts = []\n",
        "\n",
        "for question_text in question_texts:\n",
        "    relevant_chunks = chroma.query(\n",
        "        query_texts=[question_text],\n",
        "        n_results=5,\n",
        "    )\n",
        "    relevant_contexts.append(relevant_chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Get the set of chunks for one of the questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=========\n",
            "Paragraph index :  180\n",
            "Paragraph :  Brian Cassidy\n",
            "episode , `` Undercover Blue '' , Cassidy is accused of rape by a prostitute while he was undercover almost four years prior . It is revealed that Cassidy was being set up by the woman and her boss to make money off a lawsuit against the NYPD and the charges are dropped . Also in this episode , Munch says that Cassidy paid the price for having a relationship with a prostitute while undercover with Ganzel , as he was demoted from detective to an officer who works nights at a Bronx courthouse . Benson and Cassidy also are forced to reveal their romantic relationship in this episode when Amaro and Munch go to Cassidy 's apartment and find Benson there . In Season 15 , Cassidy and Benson are still romantically involved and move in together . In the episode `` Internal Affairs '' , Cassidy is put undercover by Internal Affairs Bureau Lt. Ed Tucker ( Robert John Burke ) to investigate a dirty precinct , an assignment that very nearly leads to his death at the hands of two of its officers . Tucker promises that if the operation is successful , he will earn his detective shield back . In the episode , `` Rapist Anonymous '' , it is revealed that he has been given back the title of detective , and will be working in Internal Affairs . Cassidy and Benson amicably break up around the time of the episode `` Downloaded Child\n",
            "Distance :  1.3333131074905396\n",
            "=========\n",
            "Paragraph index :  178\n",
            "Paragraph :  Brian Cassidy\n",
            "for thirteen episodes , his character never had much of a chance to develop . Winters wanted to return to the show for a long time , though , and felt the time was right during the thirteenth season finale . Critics were generally negative about Cassidy during the character 's initial tenure on the show , but some were glad to see his return in `` Rhodium Nights '' . Contents ( hide ) 1 Character biography 2 Development 3 Awards and decorations 4 Reception 5 References 5.1 Notes 5.2 Bibliography Character biography ( edit ) Though Cassidy is a dedicated member of the Special Victims Unit , he lacks the emotional maturity to deal with sex crimes and the language to describe them . He views his partner , John Munch ( Richard Belzer ) , as a mentor . Cassidy had a drunken one - night stand with fellow SVU Detective Olivia Benson ( Mariska Hargitay ) , and expressed a desire to pursue a relationship . Benson turns him down , however , citing a policy of not having relationships with coworkers . Years later , Benson expresses regret at the way she handled the situation . This and the stress of the unit wear Cassidy down and , after an outburst in the squad room directed at Benson , Captain Donald Cragen ( Dann Florek ) sends Cassidy to check up on a teenage rape victim Cragen encountered when he worked in Homicide . After\n",
            "Distance :  1.3482677936553955\n",
            "=========\n",
            "Paragraph index :  179\n",
            "Paragraph :  Brian Cassidy\n",
            "she tells him in detail how she had been systematically violated by her abuser and then gang - raped , Cassidy decides he lacks the stomach to deal with sex crimes , and transfers to the NYPD 's Narcotics Division . Munch later laments that he felt abandoned when Cassidy became the latest in a long line of partners who left him . Cassidy returns in the season 13 episode `` Rhodium Nights '' . He has been working undercover for the past three years as a bodyguard for a pimp , Bart Ganzel ( Peter Jacobson ) , his former colleagues at the SVU are investigating , and provides the detectives with information about Ganzel 's prostitution ring . When a prostitute named Carissa Gibson ( Pippa Black ) , who had been dating both Cassidy and Ganzel , is found dead in bed with Cragen , Detective Nick Amaro ( Danny Pino ) believes Cassidy played a role in framing Cragen despite protests from the other SVU detectives . Amaro confronts Cassidy at gunpoint and tries to force information out of him . Cassidy is later shot by a corrupt NYPD police officer after Ganzel discovers Cassidy is working undercover to expose him , and Amaro helps uncover the conspiracy that led to the attack on Cassidy . Cassidy survives , and awakens in the hospital , where Benson tells him she is not the same person she was thirteen years ago and kisses him . In the\n",
            "Distance :  1.378886103630066\n",
            "=========\n",
            "Paragraph index :  494\n",
            "Paragraph :  Send In the Clowns\n",
            "years before the play begins , Desirée was a young , attractive actress , whose passions were the theater and men . She lived her life dramatically , flitting from man to man . Fredrik was one of her many lovers and fell deeply in love with Desirée , but she declined to marry him . The play implies that when they parted Desirée may have been pregnant with his child . A few months before the play begins , Fredrik married a beautiful woman who at 18 years old was much younger than he . In Act One , Fredrik meets Desirée again , and is introduced to her daughter , a precocious adolescent suggestively named Fredrika . Fredrik explains to Desirée that he is now married to the young woman , whom he loves , but who is still a virgin and refuses to have sex with him . Desirée and Fredrik then make love . Act Two begins days later , and Desirée realizes that she truly loves Fredrik . She tells Fredrik that he needs to be rescued from his marriage , and she proposes to him . Fredrik explains to Desirée that he has been swept off the ground and is `` in the air '' in love with his beautiful , young wife , and apologizes for having misled her . Fredrik walks across the room , while Desirée remains sitting on the bed ; as she feels both intense sadness and anger ,\n",
            "Distance :  1.3999148607254028\n",
            "=========\n",
            "Paragraph index :  182\n",
            "Paragraph :  Brian Cassidy\n",
            "come back for a long time but scheduling difficulties never really permitted it , so , with this storyline , with the ( season 13 ) finale and now what we 're doing with the two - hour ( season 14 ) opening movie , it feels like this was the right time to come , so I 'm glad I waited . '' -- Dean Winters , Although Winters previously worked with Dick Wolf on New York Undercover , he credited fellow cast member Richard Belzer with getting him the job on Law & Order : Special Victims Unit . Belzer and Winters had first worked together when Winters guest starred on Homicide : Life on the Street , where Belzer was a regular . Wolf invited Belzer to join the cast of his new Law & Order spin - off after Homicide was cancelled , and Belzer told Wolf he would only join the cast if Winters was his partner on the show . Winters had a role at the same time on the HBO drama Oz and , while the SVU role was initially only supposed to last a few episodes , he was contractually obligated to Oz , and eventually departed SVU completely to focus on Oz . Winters believed that Cassidy was not unintelligent , but simply naive . He voiced early on a desire to executive producer Ted Kotcheff that Cassidy not be made into the `` dumb blonde '' of the unit because\n",
            "Distance :  1.407427191734314\n"
          ]
        }
      ],
      "source": [
        "sample_chunks = relevant_contexts[0]\n",
        "for i, chunk in enumerate(sample_chunks[\"documents\"][0]):\n",
        "    print(\"=========\")\n",
        "    print(\"Paragraph index : \", sample_chunks[\"ids\"][0][i])\n",
        "    print(\"Paragraph : \", chunk)\n",
        "    print(\"Distance : \", sample_chunks[\"distances\"][0][i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Feed the context and the questions to `watsonx.ai` model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def make_prompt(context, question_text):\n",
        "    return f\"Please answer the following.\\n\" + f\"{context}:\\n\\n\" + f\"{question_text}\"\n",
        "\n",
        "\n",
        "prompt_texts = []\n",
        "\n",
        "for relevant_context, question_text in zip(relevant_contexts, question_texts):\n",
        "    context = \"\\n\\n\\n\".join(relevant_context[\"documents\"][0])\n",
        "    prompt_text = make_prompt(context, question_text)\n",
        "    prompt_texts.append(prompt_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Inspect prompt for sample question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please answer the following.\n",
            "Brian Cassidy\n",
            "episode , `` Undercover Blue '' , Cassidy is accused of rape by a prostitute while he was undercover almost four years prior . It is revealed that Cassidy was being set up by the woman and her boss to make money off a lawsuit against the NYPD and the charges are dropped . Also in this episode , Munch says that Cassidy paid the price for having a relationship with a prostitute while undercover with Ganzel , as he was demoted from detective to an officer who works nights at a Bronx courthouse . Benson and Cassidy also are forced to reveal their romantic relationship in this episode when Amaro and Munch go to Cassidy 's apartment and find Benson there . In Season 15 , Cassidy and Benson are still romantically involved and move in together . In the episode `` Internal Affairs '' , Cassidy is put undercover by Internal Affairs Bureau Lt. Ed Tucker ( Robert John Burke ) to investigate a dirty precinct , an assignment that very nearly leads to his death at the hands of two of its officers . Tucker promises that if the operation is successful , he will earn his detective shield back . In the episode , `` Rapist Anonymous '' , it is revealed that he has been given back the title of detective , and will be working in Internal Affairs . Cassidy and Benson amicably break up around the time of the episode `` Downloaded Child\n",
            "\n",
            "\n",
            "Brian Cassidy\n",
            "for thirteen episodes , his character never had much of a chance to develop . Winters wanted to return to the show for a long time , though , and felt the time was right during the thirteenth season finale . Critics were generally negative about Cassidy during the character 's initial tenure on the show , but some were glad to see his return in `` Rhodium Nights '' . Contents ( hide ) 1 Character biography 2 Development 3 Awards and decorations 4 Reception 5 References 5.1 Notes 5.2 Bibliography Character biography ( edit ) Though Cassidy is a dedicated member of the Special Victims Unit , he lacks the emotional maturity to deal with sex crimes and the language to describe them . He views his partner , John Munch ( Richard Belzer ) , as a mentor . Cassidy had a drunken one - night stand with fellow SVU Detective Olivia Benson ( Mariska Hargitay ) , and expressed a desire to pursue a relationship . Benson turns him down , however , citing a policy of not having relationships with coworkers . Years later , Benson expresses regret at the way she handled the situation . This and the stress of the unit wear Cassidy down and , after an outburst in the squad room directed at Benson , Captain Donald Cragen ( Dann Florek ) sends Cassidy to check up on a teenage rape victim Cragen encountered when he worked in Homicide . After\n",
            "\n",
            "\n",
            "Brian Cassidy\n",
            "she tells him in detail how she had been systematically violated by her abuser and then gang - raped , Cassidy decides he lacks the stomach to deal with sex crimes , and transfers to the NYPD 's Narcotics Division . Munch later laments that he felt abandoned when Cassidy became the latest in a long line of partners who left him . Cassidy returns in the season 13 episode `` Rhodium Nights '' . He has been working undercover for the past three years as a bodyguard for a pimp , Bart Ganzel ( Peter Jacobson ) , his former colleagues at the SVU are investigating , and provides the detectives with information about Ganzel 's prostitution ring . When a prostitute named Carissa Gibson ( Pippa Black ) , who had been dating both Cassidy and Ganzel , is found dead in bed with Cragen , Detective Nick Amaro ( Danny Pino ) believes Cassidy played a role in framing Cragen despite protests from the other SVU detectives . Amaro confronts Cassidy at gunpoint and tries to force information out of him . Cassidy is later shot by a corrupt NYPD police officer after Ganzel discovers Cassidy is working undercover to expose him , and Amaro helps uncover the conspiracy that led to the attack on Cassidy . Cassidy survives , and awakens in the hospital , where Benson tells him she is not the same person she was thirteen years ago and kisses him . In the\n",
            "\n",
            "\n",
            "Send In the Clowns\n",
            "years before the play begins , Desirée was a young , attractive actress , whose passions were the theater and men . She lived her life dramatically , flitting from man to man . Fredrik was one of her many lovers and fell deeply in love with Desirée , but she declined to marry him . The play implies that when they parted Desirée may have been pregnant with his child . A few months before the play begins , Fredrik married a beautiful woman who at 18 years old was much younger than he . In Act One , Fredrik meets Desirée again , and is introduced to her daughter , a precocious adolescent suggestively named Fredrika . Fredrik explains to Desirée that he is now married to the young woman , whom he loves , but who is still a virgin and refuses to have sex with him . Desirée and Fredrik then make love . Act Two begins days later , and Desirée realizes that she truly loves Fredrik . She tells Fredrik that he needs to be rescued from his marriage , and she proposes to him . Fredrik explains to Desirée that he has been swept off the ground and is `` in the air '' in love with his beautiful , young wife , and apologizes for having misled her . Fredrik walks across the room , while Desirée remains sitting on the bed ; as she feels both intense sadness and anger ,\n",
            "\n",
            "\n",
            "Brian Cassidy\n",
            "come back for a long time but scheduling difficulties never really permitted it , so , with this storyline , with the ( season 13 ) finale and now what we 're doing with the two - hour ( season 14 ) opening movie , it feels like this was the right time to come , so I 'm glad I waited . '' -- Dean Winters , Although Winters previously worked with Dick Wolf on New York Undercover , he credited fellow cast member Richard Belzer with getting him the job on Law & Order : Special Victims Unit . Belzer and Winters had first worked together when Winters guest starred on Homicide : Life on the Street , where Belzer was a regular . Wolf invited Belzer to join the cast of his new Law & Order spin - off after Homicide was cancelled , and Belzer told Wolf he would only join the cast if Winters was his partner on the show . Winters had a role at the same time on the HBO drama Oz and , while the SVU role was initially only supposed to last a few episodes , he was contractually obligated to Oz , and eventually departed SVU completely to focus on Oz . Winters believed that Cassidy was not unintelligent , but simply naive . He voiced early on a desire to executive producer Ted Kotcheff that Cassidy not be made into the `` dumb blonde '' of the unit because:\n",
            "\n",
            "when do abby and luka get back together?\n"
          ]
        }
      ],
      "source": [
        "print(prompt_texts[0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate a retrieval-augmented response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = [model.generate_text(prompt_text) for prompt_text in prompt_texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question =  when do abby and luka get back together\n",
            "Answer =  season 14\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  season 12\n",
            "\n",
            "\n",
            "Question =  what does dc stand for in washigton dc\n",
            "Answer =  District of Columbia\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  District of Columbia\n",
            "\n",
            "\n",
            "Question =  where was agatha christie s crooked house filmed\n",
            "Answer =  Florence Cathedral\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Tyntesfield , near Bristol\n",
            "\n",
            "\n",
            "Question =  where did the song god bless america originate\n",
            "Answer =  Dolly Parton\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Yaphank , New York\n",
            "\n",
            "\n",
            "Question =  when does daylight savings time end in colorado\n",
            "Answer =  the first Sunday in November\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  first Sunday in November\n",
            "\n",
            "\n",
            "Question =  who did the steelers play in the playoffs last year\n",
            "Answer =  Bengal\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Miami Dolphins::New England Patriots::Kansas City Chiefs\n",
            "\n",
            "\n",
            "Question =  most road maps are what kind of map\n",
            "Answer =  road\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  navigational map\n",
            "\n",
            "\n",
            "Question =  who plays captian hook in once upon a time\n",
            "Answer =  Colin Arthur O'Donoghue\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Colin Arthur O'Donoghue\n",
            "\n",
            "\n",
            "Question =  when is the last time mayon volcano erupted\n",
            "Answer =  2017 - 11 - 05\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  January 25 , 2018\n",
            "\n",
            "\n",
            "Question =  who does finn wolf hard play in stranger things\n",
            "Answer =  Mike Wheeler\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Mike Wheeler\n",
            "\n",
            "\n",
            "Question =  who plays scott granger on young and restless\n",
            "Answer =  Sean Carrigan\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Daniel Hall::Blair Redford\n",
            "\n",
            "\n",
            "Question =  who did the original power rangers theme song\n",
            "Answer =  Tommy James and the Shondells\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Ron Wasserman\n",
            "\n",
            "\n",
            "Question =  who is going to be in the world cup final\n",
            "Answer =  Bengaluru Bulls\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Croatia::France\n",
            "\n",
            "\n",
            "Question =  who does the voice of brian on family guy\n",
            "Answer =  Dean Winters\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Seth MacFarlane\n",
            "\n",
            "\n",
            "Question =  who holds the 3 point record in nba\n",
            "Answer =  Ray Allen\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Ray Allen\n",
            "\n",
            "\n",
            "Question =  when did the food stamp card come out\n",
            "Answer =  Jump up   '' . '' . '' . '' . '' . '' . '' . '' . '' \n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  the late 1990s\n",
            "\n",
            "\n",
            "Question =  who is the goddess of the moon in greek mythology\n",
            "Answer =  Artemis\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Selene\n",
            "\n",
            "\n",
            "Question =  who won the 2015 great british baking show\n",
            "Answer =  Joanne Wheatley\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Nadiya Hussain\n",
            "\n",
            "\n",
            "Question =  which team has the most ncaa tournament appearances\n",
            "Answer =  Thailand\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Kentucky\n",
            "\n",
            "\n",
            "Question =  who is the original singer of where is the love\n",
            "Answer =  Dolly Parton\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Justin Timberlake::The Black Eyed Peas\n",
            "\n",
            "\n",
            "Question =  what is the seatbelt compliancy rate in texas\n",
            "Answer =  85%\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  90 % and higher\n",
            "\n",
            "\n",
            "Question =  when did fresh prince of bel air start\n",
            "Answer =  1990\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  September 10 , 1990\n",
            "\n",
            "\n",
            "Question =  what is the record for wins in major league baseball\n",
            "Answer =  Chris Carter (right-handed hitter)\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  116\n",
            "\n",
            "\n",
            "Question =  who sings lead on please let me wonder\n",
            "Answer =  Lara Fabian\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Brian Wilson\n",
            "\n",
            "\n",
            "Question =  who was the first person to be legally executed using an electric chair\n",
            "Answer =   Jump up to:\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  William Francis Kemmler\n",
            "\n",
            "\n",
            "Question =  who founded missions on the west coast of america\n",
            "Answer =  Jesuits\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Spanish\n",
            "\n",
            "\n",
            "Question =  when did how to train a dragon come out\n",
            "Answer =  2010\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  2010\n",
            "\n",
            "\n",
            "Question =  in 2011 what was the dominant source of energy in the world\n",
            "Answer =  oil\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  coal\n",
            "\n",
            "\n",
            "Question =  crossword clue 19th century novelist who created barsetshire\n",
            "Answer =  Charles Dickens\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Anthony Trollope\n",
            "\n",
            "\n",
            "Question =  n. the social class between the lower and upper classes\n",
            "Answer =  Jump up                        \n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  middle\n",
            "\n",
            "\n",
            "Question =  where do calluses on your feet come from\n",
            "Answer =  friction\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  pressure::repeated friction::other irritation\n",
            "\n",
            "\n",
            "Question =  who is though she be but little she is fierce about\n",
            "Answer =  though she be but little she is fierce\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Hermia\n",
            "\n",
            "\n",
            "Question =  who played the title character he-man in the 1987 live action movie masters of the universe\n",
            "Answer =  Frank Langella\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Dolph Lundgren\n",
            "\n",
            "\n",
            "Question =  what is the most densely populated state in the country\n",
            "Answer =  Massachusetts\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  New Jersey\n",
            "\n",
            "\n",
            "Question =  how much did chelsea sell de bruyne to wolfsburg\n",
            "Answer =   81,820 million\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  £ 18 million\n",
            "\n",
            "\n",
            "Question =  what cover-up is the movie the post about\n",
            "Answer =  the death of a young woman\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  the Pentagon Papers\n",
            "\n",
            "\n",
            "Question =  who was the lead actor in movie toile ek prem katha\n",
            "Answer =  Aryaman\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Akshay Kumar\n",
            "\n",
            "\n",
            "Question =  aurangzeb road in the heart of new delhi was re named after which personality\n",
            "Answer =  Sardar Vallabhbhai Patel\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Dr APJ Abdul Kalam\n",
            "\n",
            "\n",
            "Question =  who played hercules wife in the 2014 movie\n",
            "Answer =  Susan Farrell Egan\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Irina Shayk\n",
            "\n",
            "\n",
            "Question =  names of founding fathers of the united states\n",
            "Answer =  John Adams\n",
            "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Thomas Jefferson::James Madison::John Jay::George Washington::John Adams::Benjamin Franklin::Alexander Hamilton\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i, result in enumerate(results):\n",
        "    print(\"Question = \", test_data.iloc[i][\"question\"])\n",
        "    print(\"Answer = \", result)\n",
        "    print(\n",
        "        \"Expected Answer(s) (may not be appear with exact wording in the dataset) = \",\n",
        "        test_data.iloc[i][\"answers\"],\n",
        "    )\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"score\"></a>\n",
        "## Calculate rougeL metric\n",
        "In this sample notebook `evaluate` module from HuggingFace was used for rougeL calculation."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Rouge Metric"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note:** The Rouge (Recall-Oriented Understudy for Gisting Evaluation) metric is a set of evaluation measures used in natural language processing (NLP) and specifically in text summarization and machine translation tasks. The Rouge metrics are designed to assess the quality of generated summaries or translations by comparing them to one or more reference texts.\n",
        "\n",
        "The main idea behind Rouge is to measure the overlap between the generated summary (or translation) and the reference text(s) in terms of n-grams or longest common subsequences. By calculating recall, precision, and F1 scores based on these overlapping units, Rouge provides a quantitative assessment of the summary's content overlap with the reference(s).\n",
        "\n",
        "Rouge-1 focuses on individual word overlap, Rouge-2 considers pairs of consecutive words, and Rouge-L takes into account the ordering of words and phrases. These metrics provide different perspectives on the similarity between two texts and can be used to evaluate different aspects of summarization or text generation models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'rouge1': np.float64(0.2022916666666667), 'rouge2': np.float64(0.125), 'rougeL': np.float64(0.19819444444444445), 'rougeLsum': np.float64(0.20347222222222222)}\n"
          ]
        }
      ],
      "source": [
        "from evaluate import load\n",
        "\n",
        "rouge = load(\"rouge\")\n",
        "scores = rouge.compute(predictions=results, references=test_data.answers)\n",
        "print(scores)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"summary\"></a>\n",
        "## Summary and next steps\n",
        "\n",
        "You successfully completed this notebook!\n",
        " \n",
        "Check out our _<a href=\"https://ibm.github.io/watsonx-ai-python-sdk/samples.html\" target=\"_blank\" rel=\"noopener no referrer\">Online Documentation</a>_ for more samples, tutorials, documentation, how-tos, and blog posts. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright © 2023-2025 IBM. This notebook and its source code are released under the terms of the MIT License."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "watsonx-ai-samples-py-312",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
