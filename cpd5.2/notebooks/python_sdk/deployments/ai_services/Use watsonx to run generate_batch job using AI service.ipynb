{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b5a632",
   "metadata": {},
   "source": [
    "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
    "\n",
    "# Use watsonx to run `generate_batch` job using AI service\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26112be8",
   "metadata": {},
   "source": [
    "#### Disclaimers\n",
    "\n",
    "- Use only Projects and Spaces that are available in watsonx context.\n",
    "\n",
    "## Notebook content\n",
    "\n",
    "This notebook provides a detailed demonstration of the steps and code required to showcase support for watsonx.ai AI service.\n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
    "\n",
    "## Learning goal\n",
    "\n",
    "The primary objective of this notebook is to illustrate how to utilize watsonx.ai AI services to execute a `generate_batch` job, facilitating the ingestion of documents into a Milvus vector database.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "- [Setup](#setup)\n",
    "- [Set up VectorStore with Milvus credentials](#vectorstore)\n",
    "- [References to input data](#input_data)\n",
    "- [Create AI service](#ai_service)\n",
    "- [Testing AI service's function locally](#testing)\n",
    "- [Deploy AI service](#deploy)\n",
    "- [Example of Executing an AI service](#example)\n",
    "- [Cleanup](#cleanup)\n",
    "- [Summary and next steps](#summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe3ec13",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "\n",
    "## Set up the environment\n",
    "\n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
    "\n",
    "- Contact with your Cloud Pak for Data administrator and ask them for your account credentials\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3525c2",
   "metadata": {},
   "source": [
    "### Install and import the `ibm-watsonx-ai` and dependecies\n",
    "\n",
    "**Note:** `ibm-watsonx-ai` documentation can be found <a href=\"https://ibm.github.io/watsonx-ai-python-sdk/index.html\" target=\"_blank\" rel=\"noopener no referrer\">here</a>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8662f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langchain_community | tail -n 1\n",
    "%pip install -U \"ibm_watsonx_ai>=1.3.20\" | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c2e2a1",
   "metadata": {},
   "source": [
    "### Connect to WML\n",
    "\n",
    "Authenticate the Watson Machine Learning service on IBM Cloud Pak for Data. You need to provide the platform `url`, your `username`, and your `api_key`.\n",
    "\n",
    "- `url` - url which points to your CPD instance.\n",
    "- `username` - username to your CPD instance.\n",
    "- `api_key` - api_key to your CPD instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63b2f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"PASTE YOUR CPD INSTANCE URL HERE\"\n",
    "api_key = \"PASTE YOUR CPD INSTANCE API KEY HERE\"\n",
    "username = \"PASTE YOUR CPD INSTANCE USERNAME HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4892a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai import Credentials\n",
    "\n",
    "credentials = Credentials(\n",
    "    username=username,\n",
    "    api_key=api_key,\n",
    "    url=url,\n",
    "    instance_id=\"openshift\",\n",
    "    version=\"5.2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1498c3fa",
   "metadata": {},
   "source": [
    "Alternatively you can use `username` and `password` to authenticate WML services.\n",
    "\n",
    "```python\n",
    "credentials = Credentials(\n",
    "    username=***,\n",
    "    password=***,\n",
    "    url=***,\n",
    "    instance_id=\"openshift\",\n",
    "    version=\"5.2\"\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a49878",
   "metadata": {},
   "source": [
    "### Working with spaces\n",
    "\n",
    "First, you need to create a space for your work. If you do not have a space already created, you can use `{PLATFORM_URL}/ml-runtime/spaces?context=icp4data` to create one.\n",
    "\n",
    "- Click **New Deployment Space**\n",
    "- Create an empty space\n",
    "- Go to the space `Settings` tab\n",
    "- Copy the `space_id` and paste it below\n",
    "\n",
    "`PLATFORM_URL` is the url which points to your CPD instance.\n",
    "\n",
    "**Tip**: You can also use SDK to prepare the space for your work. Find more information in the [Space Management sample notebook](https://github.ibm.com/WML/watsonx-ai-samples/blob/dev/cpd5.1/notebooks/python_sdk/instance-management/Space%20management.ipynb).\n",
    "\n",
    "**Action**: Assign the space ID below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ead0265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    space_id = os.environ[\"SPACE_ID\"]\n",
    "except KeyError:\n",
    "    space_id = input(\"Please enter your space_id (hit enter): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0db8b5",
   "metadata": {},
   "source": [
    "Create an instance of APIClient with authentication details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7317126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai import APIClient\n",
    "\n",
    "api_client = APIClient(\n",
    "    credentials=credentials, \n",
    "    space_id=space_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d86021",
   "metadata": {},
   "source": [
    "### Create an embedding function for VectorStore\n",
    "\n",
    "Note that you can feed a custom embedding function to be used by Milvus. The performance of Milvus may differ depending on the embedding model used.\n",
    "\n",
    "**Note**: To list available embedding models use:\n",
    "\n",
    "```python\n",
    "api_client.foundation_models.EmbeddingModels.show()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fde6e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.foundation_models import Embeddings\n",
    "\n",
    "embedding_model_id=\"ibm/granite-embedding-107m-multilingual\"\n",
    "\n",
    "embeddings = Embeddings(\n",
    "    model_id=embedding_model_id,\n",
    "    api_client=api_client\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa4cc05",
   "metadata": {},
   "source": [
    "### Set up connectivity information to Milvus\n",
    "\n",
    "<b>This notebook focuses on a self-managed Milvus cluster using <a href=\"https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-adding-milvus-service\" target=\"_blank\" rel=\"noopener no referrer\">IBM watsonx.data.</a></b>\n",
    "\n",
    "The following cell retrieves the Milvus username, password, host, and port from the environment (if available) and prompts you to provide them manually in case of failure.\n",
    "\n",
    "You can provide a connection asset ID to read all required connection data from it. Before doing so, make sure that a connection asset was created in your space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f259cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "milvus_connection_id = input(\"Provide connection asset ID in your space. Skip this, if you wish to type credentials by hand and hit enter: \") or None\n",
    "\n",
    "if milvus_connection_id is None:\n",
    "    try:\n",
    "        username = os.environ[\"USERNAME\"]\n",
    "    except KeyError:\n",
    "        username = input(\"Please enter your Milvus user name and hit enter: \")\n",
    "    try:\n",
    "        password = os.environ[\"PASSWORD\"]\n",
    "    except KeyError:\n",
    "        password = getpass.getpass(\"Please enter your Milvus password and hit enter: \")\n",
    "    try:\n",
    "        host = os.environ[\"HOST\"]\n",
    "    except KeyError:\n",
    "        host = input(\"Please enter your Milvus hostname and hit enter: \")\n",
    "    try:\n",
    "        port = os.environ[\"PORT\"]\n",
    "    except KeyError:\n",
    "        port = input(\"Please enter your Milvus port number and hit enter: \")\n",
    "    try:\n",
    "        ssl = os.environ[\"SSL\"]\n",
    "    except:\n",
    "        ssl = bool(input(\"Please enter ('y'/anything) if your Milvus instance has SSL enabled. Skip if it is not: \"))\n",
    "\n",
    "    # Create connection\n",
    "    milvus_data_source_type_id = api_client.connections.get_datasource_type_uid_by_name(\n",
    "        \"milvus\"\n",
    "    )\n",
    "    details = api_client.connections.create(\n",
    "        {\n",
    "            api_client.connections.ConfigurationMetaNames.NAME: \"Milvus Connection\",\n",
    "            api_client.connections.ConfigurationMetaNames.DESCRIPTION: \"Connection created by the sample notebook\",\n",
    "            api_client.connections.ConfigurationMetaNames.DATASOURCE_TYPE: milvus_data_source_type_id,\n",
    "            api_client.connections.ConfigurationMetaNames.PROPERTIES: {\n",
    "                \"host\": host,\n",
    "                \"port\": port,\n",
    "                \"username\": username,\n",
    "                \"password\": password,\n",
    "                \"ssl\": ssl,\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "\n",
    "    milvus_connection_id = api_client.connections.get_id(details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efea633b",
   "metadata": {},
   "source": [
    "<a id=\"vectorstore\"></a>\n",
    "\n",
    "## Set up VectorStore with Milvus credentials\n",
    "\n",
    "Create a VectorStore class that automatically detects the database type (in our case it will be Milvus) and allows us to add, search and delete documents.\n",
    "\n",
    "It works as a wrapper for LangChain VectorStore classes. You can customize the settings as long as it is supported. Consult the LangChain documentation for more information about <a href=\"https://api.python.langchain.com/en/latest/vectorstores/langchain_community.vectorstores.milvus.Milvus.html\" target=\"_blank\" rel=\"noopener no referrer\">Milvus</a> connector.\n",
    "\n",
    "Provide the name of your Milvus index for subsequent operations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33f600d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_name='example_milvus_index'\n"
     ]
    }
   ],
   "source": [
    "index_name = input(\"Please enter Milvus index name and hit enter: \")\n",
    "\n",
    "print(f\"{index_name=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03e4ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.foundation_models.extensions.rag.vector_stores import VectorStore\n",
    "\n",
    "vector_store = VectorStore(\n",
    "    api_client=api_client, \n",
    "    connection_id=milvus_connection_id, \n",
    "    index_name=index_name, \n",
    "    embeddings=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41474322",
   "metadata": {},
   "source": [
    "Verify if index in Milvus instance is empty.\n",
    "\n",
    "**Note**: If collection is not empty you can use `clear` method on `VectorStore` object:\n",
    "\n",
    "```python\n",
    "vector_store.clear()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81684c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483ec8fd",
   "metadata": {},
   "source": [
    "<a id=\"input_data\"></a>\n",
    "\n",
    "## References to input data\n",
    "\n",
    "This example uses the `ModelInference` description from the [`ibm_watsonx_ai`](https://ibm.github.io/watsonx-ai-python-sdk/fm_model_inference.html) documentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1aee42b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "url = \"https://ibm.github.io/watsonx-ai-python-sdk/fm_model_inference.html\"\n",
    "\n",
    "docs = WebBaseLoader(url).load()\n",
    "model_inference_content = docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7e19a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "document_filename = \"ModelInference.txt\"\n",
    "\n",
    "if not os.path.isfile(document_filename):\n",
    "    with open(document_filename, \"w\") as file:\n",
    "        file.write(model_inference_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3b9052",
   "metadata": {},
   "source": [
    "Upload the input data to the space as a data asset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3995341c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data asset...\n",
      "SUCCESS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ddf93f89-095a-4146-bcb3-3e03f4a9d178'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_asset_details = api_client.data_assets.create(name=document_filename, file_path=document_filename)\n",
    "\n",
    "document_asset_id = api_client.data_assets.get_id(document_asset_details)\n",
    "document_asset_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19188d0",
   "metadata": {},
   "source": [
    "Define a connection to the input data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af54a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.helpers import DataConnection\n",
    "\n",
    "data_connection = DataConnection(data_asset_id=document_asset_id)\n",
    "data_connection.set_client(api_client=api_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cf3587",
   "metadata": {},
   "source": [
    "Create `input_data_references` as a `dict` representation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be35cbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"type\": \"data_asset\",\n",
      "    \"location\": {\n",
      "      \"href\": \"/v2/assets/ddf93f89-095a-4146-bcb3-3e03f4a9d178?space_id=d29cf5c7-428e-46a6-97d2-6ceec613fbc9\",\n",
      "      \"id\": \"ddf93f89-095a-4146-bcb3-3e03f4a9d178\"\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "input_data_references = [\n",
    "  data_connection.to_dict()\n",
    "]\n",
    "\n",
    "print(json.dumps(input_data_references, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516f16fd",
   "metadata": {},
   "source": [
    "<a id=\"ai_service\"></a>\n",
    "\n",
    "## Create AI service\n",
    "\n",
    "Prepare function which will be deployed using AI service.\n",
    "\n",
    "Please specify the default parameters that will be passed to the function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d62868cd23699d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:06:44.939085Z",
     "start_time": "2025-04-23T18:06:44.932153Z"
    }
   },
   "outputs": [],
   "source": [
    "def deployable_ai_service(context, url=None, embedding_model_id=None, milvus_connection_id=None, index_name=None):\n",
    "\n",
    "    from ibm_watsonx_ai import APIClient\n",
    "    from ibm_watsonx_ai import Credentials\n",
    "    from ibm_watsonx_ai.helpers import DataConnection\n",
    "    from ibm_watsonx_ai.foundation_models.embeddings import Embeddings\n",
    "    from ibm_watsonx_ai.foundation_models.extensions.rag.vector_stores import VectorStore\n",
    "    from ibm_watsonx_ai.data_loaders.datasets.documents import DocumentsIterableDataset\n",
    "    from ibm_watsonx_ai.foundation_models.extensions.rag.chunker.langchain_chunker import LangChainChunker\n",
    "    \n",
    "    api_client = APIClient(\n",
    "        credentials=Credentials(url=url, token=context.generate_token(), instance_id=\"openshift\"),\n",
    "        space_id=context.get_space_id(),\n",
    "    )\n",
    "    print(\"Successfully initialized APIClient\")\n",
    "    \n",
    "    embeddings = Embeddings(\n",
    "        model_id=embedding_model_id, \n",
    "        api_client=api_client\n",
    "    )\n",
    "    print(\"Successfully initialized Embeddings\")\n",
    "\n",
    "    def generate_batch(input_data_references: list[dict], output_data_reference: dict | None = None) -> None:\n",
    "        \n",
    "        vector_store = VectorStore(\n",
    "            api_client=api_client, \n",
    "            connection_id=milvus_connection_id, \n",
    "            index_name=index_name, \n",
    "            embeddings=embeddings\n",
    "        )\n",
    "        print(\"Successfully initialized VectorStore\")\n",
    "        \n",
    "        connections = []\n",
    "        \n",
    "        for input_data_reference in input_data_references:\n",
    "            connections.append(DataConnection.from_dict(input_data_reference))\n",
    "    \n",
    "        dataset = DocumentsIterableDataset(\n",
    "            connections=connections, \n",
    "            enable_sampling=False, \n",
    "            api_client=api_client\n",
    "        )\n",
    "        print(\"Successfully initialized DocumentsIterableDataset\")\n",
    "\n",
    "        chunker = LangChainChunker(\n",
    "            chunk_size=512,\n",
    "        )\n",
    "        print(\"Successfully initialized LangChainChunker\")\n",
    "\n",
    "        documents = chunker.split_documents(dataset)\n",
    "        print(\"Successfully splitted documents\")\n",
    "        \n",
    "        vector_store.add_documents(documents)\n",
    "        print(\"Documents added\")\n",
    "        \n",
    "        vector_store_count = vector_store.count()\n",
    "        print(f\"Vector Store count: {vector_store_count}\")\n",
    "\n",
    "    return generate_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7459cf",
   "metadata": {},
   "source": [
    "<a id=\"testing\"></a>\n",
    "\n",
    "## Testing AI service's function locally\n",
    "\n",
    "You can test AI service's function locally. Initialise `RuntimeContext` firstly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04c8184e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initialized APIClient\n",
      "Successfully initialized Embeddings\n"
     ]
    }
   ],
   "source": [
    "from ibm_watsonx_ai.deployments import RuntimeContext\n",
    "\n",
    "context = RuntimeContext(api_client=api_client)\n",
    "\n",
    "generate_batch = deployable_ai_service(\n",
    "    context, \n",
    "    url=credentials[\"url\"], \n",
    "    embedding_model_id=embedding_model_id, \n",
    "    milvus_connection_id=milvus_connection_id, \n",
    "    index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4136b532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initialized VectorStore\n",
      "Successfully initialized DocumentsIterableDataset\n",
      "Successfully initialized LangChainChunker\n",
      "Successfully splitted documents\n",
      "Documents added\n",
      "Vector Store count: 82\n"
     ]
    }
   ],
   "source": [
    "generate_batch(input_data_references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0b1fad",
   "metadata": {},
   "source": [
    "Verify the total number of documents currently stored within the Milvus collection.\n",
    "\n",
    "**Note**: Due to the implementation specifics of Milvus, it is necessary to initialize a new VectorStore instance in order to accurately retrieve the count of indexed elements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "254f3005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store = VectorStore(\n",
    "    api_client=api_client, \n",
    "    connection_id=milvus_connection_id, \n",
    "    index_name=index_name, \n",
    "    embeddings=embeddings\n",
    ")\n",
    "\n",
    "vector_store.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a6e75a",
   "metadata": {},
   "source": [
    "Once the collection accurately reflects the expected number of items, proceed to clear its contents to prepare the environment for subsequent testing activities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f38e11ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.clear()\n",
    "vector_store.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e4987a",
   "metadata": {},
   "source": [
    "<a id=\"deploy\"></a>\n",
    "\n",
    "## Deploy AI service\n",
    "\n",
    "Store AI service with previous created custom software specifications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32a0f85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sw_spec_id='45f12dfe-aa78-5b8d-9f38-0ee223c47309'\n"
     ]
    }
   ],
   "source": [
    "sw_spec_id = api_client.software_specifications.get_id_by_name(\"runtime-24.1-py3.11\")\n",
    "print(f\"{sw_spec_id=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f287cbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"metadata\": {\n",
      "    \"name\": \"AI service with generate_batch\",\n",
      "    \"description\": \"Sample AI service with implemented generate_batch\",\n",
      "    \"space_id\": \"d29cf5c7-428e-46a6-97d2-6ceec613fbc9\",\n",
      "    \"id\": \"f4b23cc2-3b36-4201-adc5-72318dfc39a9\",\n",
      "    \"created_at\": \"2025-05-28T08:02:01Z\",\n",
      "    \"rov\": {\n",
      "      \"member_roles\": {\n",
      "        \"1000330999\": {\n",
      "          \"user_iam_id\": \"1000330999\",\n",
      "          \"roles\": [\n",
      "            \"OWNER\"\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"owner\": \"1000330999\"\n",
      "  },\n",
      "  \"entity\": {\n",
      "    \"software_spec\": {\n",
      "      \"id\": \"45f12dfe-aa78-5b8d-9f38-0ee223c47309\"\n",
      "    },\n",
      "    \"code_type\": \"python\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "meta_props = {\n",
    "    api_client.repository.AIServiceMetaNames.NAME: \"AI service with generate_batch\",\n",
    "    api_client.repository.AIServiceMetaNames.DESCRIPTION: \"Sample AI service with implemented generate_batch\",\n",
    "    api_client.repository.AIServiceMetaNames.SOFTWARE_SPEC_ID: sw_spec_id\n",
    "}\n",
    "stored_ai_service_details = api_client.repository.store_ai_service(deployable_ai_service, meta_props)\n",
    "\n",
    "print(json.dumps(stored_ai_service_details, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03993a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai_service_id='f4b23cc2-3b36-4201-adc5-72318dfc39a9'\n"
     ]
    }
   ],
   "source": [
    "ai_service_id = api_client.repository.get_ai_service_id(stored_ai_service_details)\n",
    "print(f\"{ai_service_id=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fb42f3",
   "metadata": {},
   "source": [
    "Create batch deployment of AI service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0af1e3039124ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "######################################################################################\n",
      "\n",
      "Synchronous deployment creation for id: 'f4b23cc2-3b36-4201-adc5-72318dfc39a9' started\n",
      "\n",
      "######################################################################################\n",
      "\n",
      "\n",
      "ready.\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Successfully finished deployment creation, deployment_id='f3bd2825-7eca-45ed-b598-7aa5e87cf217'\n",
      "-----------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "deployment_id='f3bd2825-7eca-45ed-b598-7aa5e87cf217'\n"
     ]
    }
   ],
   "source": [
    "deployment_details = api_client.deployments.create(\n",
    "    artifact_id=ai_service_id,\n",
    "    meta_props={\n",
    "        api_client.deployments.ConfigurationMetaNames.NAME: \"Vector Store Batch Deployment\",\n",
    "        api_client.deployments.ConfigurationMetaNames.BATCH: {\n",
    "            \"parameters\": {\n",
    "                \"url\": credentials[\"url\"],\n",
    "                \"embedding_model_id\": embedding_model_id,\n",
    "                \"milvus_connection_id\": milvus_connection_id,\n",
    "                \"index_name\": index_name\n",
    "            }\n",
    "        }, \n",
    "        api_client.deployments.ConfigurationMetaNames.HARDWARE_SPEC: {\n",
    "            \"id\": api_client.hardware_specifications.get_id_by_name(\"L\")\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "deployment_id = api_client.deployments.get_id(deployment_details)\n",
    "print(f\"{deployment_id=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13520cda",
   "metadata": {},
   "source": [
    "<a id=\"example\"></a>\n",
    "\n",
    "## Example of executing an AI service\n",
    "\n",
    "Run the following cells to create and run a job with the deployed AI service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f72e1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poll_async_job(wml_client, job_id):\n",
    "    import time\n",
    "\n",
    "    while True:\n",
    "        job_status = wml_client.deployments.get_job_status(job_id)\n",
    "        print(job_status)\n",
    "        state = job_status[\"state\"]\n",
    "        if state == \"completed\" or \"fail\" in state:\n",
    "            return wml_client.deployments.get_job_details(job_id)\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d858b39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_id='b7e944de-5172-44ea-9680-3e2e8580bbfc'\n"
     ]
    }
   ],
   "source": [
    "batch_reference_payload = {\n",
    "    \"input_data_references\": input_data_references,\n",
    "}\n",
    "\n",
    "job_details = api_client.deployments.create_job(deployment_id, batch_reference_payload)\n",
    "job_id = api_client.deployments.get_job_id(job_details)\n",
    "print(f\"{job_id=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0822dc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'completed_at': '', 'running_at': '', 'state': 'queued'}\n",
      "{'completed_at': '', 'running_at': '', 'state': 'queued'}\n",
      "{'completed_at': '', 'running_at': '', 'state': 'queued'}\n",
      "{'completed_at': '', 'running_at': '', 'state': 'queued'}\n",
      "{'completed_at': '', 'running_at': '2025-05-28T08:06:14.912Z', 'state': 'running'}\n",
      "{'completed_at': '', 'running_at': '2025-05-28T08:06:14.912Z', 'state': 'running'}\n",
      "{'completed_at': '', 'running_at': '2025-05-28T08:06:14.912Z', 'state': 'running'}\n",
      "{'completed_at': '', 'running_at': '2025-05-28T08:06:14.912Z', 'state': 'running'}\n",
      "{'completed_at': '2025-05-28T08:06:36.948059Z', 'running_at': '2025-05-28T08:06:14.582494Z', 'state': 'completed'}\n"
     ]
    }
   ],
   "source": [
    "job_details = poll_async_job(api_client, job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847136af",
   "metadata": {},
   "source": [
    "Verify the total number of documents currently stored within the Milvus collection.\n",
    "\n",
    "**Note**: Due to the implementation specifics of Milvus, it is necessary to initialize a new VectorStore instance in order to accurately retrieve the count of indexed elements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff36856a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store = VectorStore(\n",
    "    api_client=api_client, \n",
    "    connection_id=milvus_connection_id, \n",
    "    index_name=index_name, \n",
    "    embeddings=embeddings\n",
    ")\n",
    "\n",
    "vector_store.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57c0c31",
   "metadata": {},
   "source": [
    "<a id=\"cleanup\"></a>\n",
    "\n",
    "## Cleanup\n",
    "\n",
    "Please execute the following commands to clean up and decommission all resources provisioned during the execution of this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ddc15729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete deployment job\n",
    "\n",
    "api_client.deployments.delete_job(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7571bc19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete batch deployment\n",
    "\n",
    "api_client.deployments.delete(deployment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c7308da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete AI service asset\n",
    "\n",
    "api_client.repository.delete(ai_service_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca31ea79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete `ModelInference.txt` asset\n",
    "\n",
    "api_client.data_assets.delete(document_asset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cca5915e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelInference.txt has been deleted.\n"
     ]
    }
   ],
   "source": [
    "# Delete `ModelInference.txt` file locally\n",
    "\n",
    "import os\n",
    "\n",
    "if os.path.exists(document_filename):\n",
    "    os.remove(document_filename)\n",
    "    print(f\"{document_filename} has been deleted.\")\n",
    "else:\n",
    "    print(f\"{document_filename} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687b81b2",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "\n",
    "## Summary and next steps\n",
    "\n",
    "You successfully completed this notebook!\n",
    "\n",
    "You have successfully learned how to design and deploy an AI service utilizing the `generate_batch` functionality, leveraging the capabilities of the `ibm_watsonx_ai` SDK.\n",
    "\n",
    "Check out our _<a href=\"https://ibm.github.io/watsonx-ai-python-sdk/samples.html\" target=\"_blank\" rel=\"noopener no referrer\">Online Documentation</a>_ for more samples, tutorials, documentation, how-tos, and blog posts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19249cc",
   "metadata": {},
   "source": [
    "### Author\n",
    "\n",
    "**Mateusz Szewczyk**, Software Engineer at watsonx.ai.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8072d0b",
   "metadata": {},
   "source": [
    "Copyright © 2025 IBM. This notebook and its source code are released under the terms of the MIT License.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
